{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcO188ALXmS0"
      },
      "source": [
        "# Task 2: Graphs in 3D\n",
        "## 2.3 Meshes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtrHIyIYXrX4"
      },
      "source": [
        "#### 2.3.0 Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UI8AC3yhpfP",
        "outputId": "1dc02f9f-48b0-498c-a217-f96f26a33a3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKpk8LgBYMZf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_max_pool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1U-oWs4YKoZ"
      },
      "source": [
        "#### 2.3.1 GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWdeJV9O1i82",
        "outputId": "cb2d1523-c586-4ddd-acca-b0004cc30b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading http://vision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n",
            "Extracting ModelNet10/ModelNet10.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import ModelNet\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "train_dataset = ModelNet(\n",
        "    root=\"ModelNet10\",\n",
        "    train=True,\n",
        "    pre_transform=T.NormalizeScale()\n",
        ")\n",
        "\n",
        "test_dataset = ModelNet(\n",
        "    root=\"ModelNet10\",\n",
        "    train=False,\n",
        "    pre_transform=T.NormalizeScale()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd6Nyih5YSjx"
      },
      "outputs": [],
      "source": [
        "transform = T.FaceToEdge(remove_faces=False)\n",
        "\n",
        "train_dataset_mesh = []\n",
        "for data in train_dataset:\n",
        "    data.x = torch.arange(data.pos.shape[0], dtype=torch.float).view(-1,1)\n",
        "    train_dataset_mesh.append(transform(data).to(\"cuda\"))\n",
        "\n",
        "test_dataset_mesh = []\n",
        "for data in test_dataset:\n",
        "    data.x = torch.arange(data.pos.shape[0], dtype=torch.float).view(-1,1)\n",
        "    test_dataset_mesh.append(transform(data).to(\"cuda\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNsYx26AYMyv",
        "outputId": "7581c861-484f-4c0c-8bba-e74bb7b152b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:19: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 2\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 3\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 4\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 5\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 6\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 7\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 8\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 9\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 10\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 11\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 12\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 13\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 14\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 15\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 16\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 17\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 18\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 19\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 20\tValidation accuracy: 0.11013215859030837\n",
            "Test accuracy: 0.1222466960352423\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class MeshGNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, num_classes):\n",
        "        super(MeshGNN, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(1, hidden_dim)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, train_data):\n",
        "        x, pos, edge_index, batch = train_data.x, train_data.pos, train_data.edge_index, train_data.batch\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        pooled = global_max_pool(x, batch)\n",
        "        return self.classifier(pooled)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, evalloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for idx, eval_data in enumerate(evalloader):\n",
        "            pred = self(eval_data).max(dim=1)[1]\n",
        "            correct += pred.eq(eval_data.y).sum().item()\n",
        "            total += eval_data.y.shape[0]\n",
        "        return correct / total\n",
        "\n",
        "def use_gnn(seed, hidden_dim, train_set, test_set):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = MeshGNN(hidden_dim=hidden_dim, num_classes=train_dataset.num_classes).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.005, weight_decay=0)\n",
        "\n",
        "    # data\n",
        "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(20):\n",
        "        gnn_model.train()\n",
        "\n",
        "        for idx, train_data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            pred = gnn_model(train_data)\n",
        "            loss = F.cross_entropy(pred, train_data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            gnn_model.eval()\n",
        "            valid_acc = gnn_model.eval_accuracy(test_loader)\n",
        "            print(\"Epoch: {}\\tValidation accuracy: {}\".format(epoch + 1, valid_acc))\n",
        "\n",
        "            if valid_acc > best_test_acc:\n",
        "                best_test_acc = valid_acc\n",
        "\n",
        "    # test\n",
        "    return best_test_acc\n",
        "\n",
        "seed = 114514\n",
        "test_acc = use_gnn(seed=seed,\n",
        "                   hidden_dim=16,\n",
        "                   train_set=train_dataset_mesh,\n",
        "                   test_set=test_dataset_mesh)\n",
        "print(\"Test accuracy: {}\\n\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WMMlBJBYM6u"
      },
      "source": [
        "#### 2.3.2 GNN with coordinates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uDucBISWkl1"
      },
      "source": [
        "Use original edges:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDQyP0_0YQ1P",
        "outputId": "c2cb3adf-88f7-47f2-d249-4601bf049f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\tValidation accuracy: 0.41409691629955947\n",
            "Epoch: 2\tValidation accuracy: 0.6398678414096917\n",
            "Epoch: 3\tValidation accuracy: 0.6519823788546255\n",
            "Epoch: 4\tValidation accuracy: 0.710352422907489\n",
            "Epoch: 5\tValidation accuracy: 0.7125550660792952\n",
            "Epoch: 6\tValidation accuracy: 0.7555066079295154\n",
            "Epoch: 7\tValidation accuracy: 0.7202643171806168\n",
            "Epoch: 8\tValidation accuracy: 0.7257709251101322\n",
            "Epoch: 9\tValidation accuracy: 0.7444933920704846\n",
            "Epoch: 10\tValidation accuracy: 0.762114537444934\n",
            "Epoch: 11\tValidation accuracy: 0.7654185022026432\n",
            "Epoch: 12\tValidation accuracy: 0.7709251101321586\n",
            "Epoch: 13\tValidation accuracy: 0.7544052863436124\n",
            "Epoch: 14\tValidation accuracy: 0.7588105726872246\n",
            "Epoch: 15\tValidation accuracy: 0.75\n",
            "Epoch: 16\tValidation accuracy: 0.7863436123348018\n",
            "Epoch: 17\tValidation accuracy: 0.7775330396475771\n",
            "Epoch: 18\tValidation accuracy: 0.7720264317180616\n",
            "Epoch: 19\tValidation accuracy: 0.789647577092511\n",
            "Epoch: 20\tValidation accuracy: 0.7940528634361234\n",
            "Epoch: 21\tValidation accuracy: 0.788546255506608\n",
            "Epoch: 22\tValidation accuracy: 0.7918502202643172\n",
            "Epoch: 23\tValidation accuracy: 0.8061674008810573\n",
            "Epoch: 24\tValidation accuracy: 0.7533039647577092\n",
            "Epoch: 25\tValidation accuracy: 0.7731277533039648\n",
            "Epoch: 26\tValidation accuracy: 0.7863436123348018\n",
            "Epoch: 27\tValidation accuracy: 0.7720264317180616\n",
            "Epoch: 28\tValidation accuracy: 0.7720264317180616\n",
            "Epoch: 29\tValidation accuracy: 0.8072687224669604\n",
            "Epoch: 30\tValidation accuracy: 0.7830396475770925\n",
            "Epoch: 31\tValidation accuracy: 0.7830396475770925\n",
            "Epoch: 32\tValidation accuracy: 0.7731277533039648\n",
            "Epoch: 33\tValidation accuracy: 0.776431718061674\n",
            "Epoch: 34\tValidation accuracy: 0.7786343612334802\n",
            "Epoch: 35\tValidation accuracy: 0.7830396475770925\n",
            "Epoch: 36\tValidation accuracy: 0.7907488986784141\n",
            "Epoch: 37\tValidation accuracy: 0.7874449339207048\n",
            "Epoch: 38\tValidation accuracy: 0.801762114537445\n",
            "Epoch: 39\tValidation accuracy: 0.7830396475770925\n",
            "Epoch: 40\tValidation accuracy: 0.7819383259911894\n",
            "Epoch: 41\tValidation accuracy: 0.8006607929515418\n",
            "Epoch: 42\tValidation accuracy: 0.775330396475771\n",
            "Epoch: 43\tValidation accuracy: 0.776431718061674\n",
            "Epoch: 44\tValidation accuracy: 0.789647577092511\n",
            "Epoch: 45\tValidation accuracy: 0.8006607929515418\n",
            "Epoch: 46\tValidation accuracy: 0.7455947136563876\n",
            "Epoch: 47\tValidation accuracy: 0.7940528634361234\n",
            "Epoch: 48\tValidation accuracy: 0.7973568281938326\n",
            "Epoch: 49\tValidation accuracy: 0.7929515418502202\n",
            "Epoch: 50\tValidation accuracy: 0.788546255506608\n",
            "Test accuracy: 0.8072687224669604\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class MeshOriginalEdge(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, num_classes):\n",
        "        super(MeshOriginalEdge, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(3, hidden_dim)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, train_data):\n",
        "        pos, edge_index, batch = train_data.pos, train_data.edge_index, train_data.batch\n",
        "        x = self.conv1(pos, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        pooled = global_max_pool(x, batch)\n",
        "        return self.classifier(pooled)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, evalloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for idx, eval_data in enumerate(evalloader):\n",
        "            pred = self(eval_data).max(dim=1)[1]\n",
        "            correct += pred.eq(eval_data.y).sum().item()\n",
        "            total += eval_data.y.shape[0]\n",
        "        return correct / total\n",
        "\n",
        "def use_gnn(seed, hidden_dim, train_set, test_set):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = MeshOriginalEdge(hidden_dim=hidden_dim, num_classes=train_dataset.num_classes).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.005, weight_decay=0)\n",
        "\n",
        "    # data\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(50):\n",
        "        gnn_model.train()\n",
        "\n",
        "        for idx, train_data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            pred = gnn_model(train_data)\n",
        "            loss = F.cross_entropy(pred, train_data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            gnn_model.eval()\n",
        "            valid_acc = gnn_model.eval_accuracy(test_loader)\n",
        "            print(\"Epoch: {}\\tValidation accuracy: {}\".format(epoch + 1, valid_acc))\n",
        "\n",
        "            if valid_acc > best_test_acc:\n",
        "                best_test_acc = valid_acc\n",
        "\n",
        "    # test\n",
        "    return best_test_acc\n",
        "\n",
        "seed = 114514\n",
        "test_acc = use_gnn(seed=seed,\n",
        "                   hidden_dim=32,\n",
        "                   train_set=train_dataset_mesh,\n",
        "                   test_set=test_dataset_mesh)\n",
        "print(\"Test accuracy: {}\\n\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx6nlX0VWtgI"
      },
      "source": [
        "Use dynamically generated edges:    \n",
        "https://github.com/pyg-team/pytorch_geometric/blob/b0053ce1c193ed3c25ce0adb105558000489dacb/examples/dgcnn_classification.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.SamplePoints(1024)\n",
        "train_dataset_dyn_mesh = [transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_dataset_dyn_mesh = [transform(data).to(\"cuda\") for data in test_dataset]"
      ],
      "metadata": {
        "id": "V8TnYRXmDCSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AWRNt_BXWl6",
        "outputId": "8553be29-8654-455f-cb2f-79be5b4ce851"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:18: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\tValidation accuracy: 0.7191629955947136\n",
            "Epoch: 2\tValidation accuracy: 0.7731277533039648\n",
            "Epoch: 3\tValidation accuracy: 0.816079295154185\n",
            "Epoch: 4\tValidation accuracy: 0.8050660792951542\n",
            "Epoch: 5\tValidation accuracy: 0.8149779735682819\n",
            "Epoch: 6\tValidation accuracy: 0.8535242290748899\n",
            "Epoch: 7\tValidation accuracy: 0.8667400881057269\n",
            "Epoch: 8\tValidation accuracy: 0.8535242290748899\n",
            "Epoch: 9\tValidation accuracy: 0.8832599118942731\n",
            "Epoch: 10\tValidation accuracy: 0.8513215859030837\n",
            "Epoch: 11\tValidation accuracy: 0.8777533039647577\n",
            "Epoch: 12\tValidation accuracy: 0.8854625550660793\n",
            "Epoch: 13\tValidation accuracy: 0.8810572687224669\n",
            "Epoch: 14\tValidation accuracy: 0.8711453744493393\n",
            "Epoch: 15\tValidation accuracy: 0.8601321585903083\n",
            "Epoch: 16\tValidation accuracy: 0.8843612334801763\n",
            "Epoch: 17\tValidation accuracy: 0.8876651982378855\n",
            "Epoch: 18\tValidation accuracy: 0.8953744493392071\n",
            "Epoch: 19\tValidation accuracy: 0.8821585903083701\n",
            "Epoch: 20\tValidation accuracy: 0.9107929515418502\n",
            "Epoch: 21\tValidation accuracy: 0.9162995594713657\n",
            "Epoch: 22\tValidation accuracy: 0.9129955947136564\n",
            "Epoch: 23\tValidation accuracy: 0.9085903083700441\n",
            "Epoch: 24\tValidation accuracy: 0.9129955947136564\n",
            "Epoch: 25\tValidation accuracy: 0.9162995594713657\n",
            "Epoch: 26\tValidation accuracy: 0.9162995594713657\n",
            "Epoch: 27\tValidation accuracy: 0.8942731277533039\n",
            "Epoch: 28\tValidation accuracy: 0.8986784140969163\n",
            "Epoch: 29\tValidation accuracy: 0.9074889867841409\n",
            "Epoch: 30\tValidation accuracy: 0.8942731277533039\n",
            "Epoch: 31\tValidation accuracy: 0.9118942731277533\n",
            "Epoch: 32\tValidation accuracy: 0.9162995594713657\n",
            "Epoch: 33\tValidation accuracy: 0.9151982378854625\n",
            "Epoch: 34\tValidation accuracy: 0.8909691629955947\n",
            "Epoch: 35\tValidation accuracy: 0.9118942731277533\n",
            "Epoch: 36\tValidation accuracy: 0.9118942731277533\n",
            "Epoch: 37\tValidation accuracy: 0.8997797356828194\n",
            "Epoch: 38\tValidation accuracy: 0.9174008810572687\n",
            "Epoch: 39\tValidation accuracy: 0.9174008810572687\n",
            "Epoch: 40\tValidation accuracy: 0.9218061674008811\n",
            "Epoch: 41\tValidation accuracy: 0.9096916299559471\n",
            "Epoch: 42\tValidation accuracy: 0.920704845814978\n",
            "Epoch: 43\tValidation accuracy: 0.920704845814978\n",
            "Epoch: 44\tValidation accuracy: 0.9196035242290749\n",
            "Epoch: 45\tValidation accuracy: 0.9107929515418502\n",
            "Epoch: 46\tValidation accuracy: 0.9041850220264317\n",
            "Epoch: 47\tValidation accuracy: 0.9074889867841409\n",
            "Epoch: 48\tValidation accuracy: 0.9251101321585903\n",
            "Epoch: 49\tValidation accuracy: 0.9240088105726872\n",
            "Epoch: 50\tValidation accuracy: 0.9218061674008811\n",
            "Test accuracy: 0.9251101321585903\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.nn import MLP, DynamicEdgeConv\n",
        "\n",
        "class MeshEdgeConv(torch.nn.Module):\n",
        "    def __init__(self, out_channels, k=20, aggr='max'):\n",
        "        super().__init__()\n",
        "        self.conv1 = DynamicEdgeConv(MLP([2 * 3, 64, 64, 64]), k, aggr)\n",
        "        self.conv2 = DynamicEdgeConv(MLP([2 * 64, 128]), k, aggr)\n",
        "        self.lin1 = nn.Linear(128 + 64, 1024)\n",
        "        self.mlp = MLP([1024, 512, 256, out_channels], dropout=0.5, norm=None)\n",
        "\n",
        "    def forward(self, train_data):\n",
        "        pos, batch = train_data.pos, train_data.batch\n",
        "        x1 = self.conv1(pos, batch)\n",
        "        x2 = self.conv2(x1, batch)\n",
        "        out = self.lin1(torch.cat([x1, x2], dim=1))\n",
        "        out = global_max_pool(out, batch)\n",
        "        out = self.mlp(out)\n",
        "        return F.log_softmax(out, dim=1)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, evalloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for idx, eval_data in enumerate(evalloader):\n",
        "            pred = self(eval_data).max(dim=1)[1]\n",
        "            correct += pred.eq(eval_data.y).sum().item()\n",
        "            total += eval_data.y.shape[0]\n",
        "        return correct / total\n",
        "\n",
        "def use_gnn(seed, train_set, test_set):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = MeshEdgeConv(train_dataset.num_classes, k=20).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.001, weight_decay=0)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    # data\n",
        "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(50):\n",
        "        gnn_model.train()\n",
        "\n",
        "        for idx, train_data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            pred = gnn_model(train_data)\n",
        "            loss = F.nll_loss(pred, train_data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            gnn_model.eval()\n",
        "            valid_acc = gnn_model.eval_accuracy(test_loader)\n",
        "            print(\"Epoch: {}\\tValidation accuracy: {}\".format(epoch + 1, valid_acc))\n",
        "\n",
        "            if valid_acc > best_test_acc:\n",
        "                best_test_acc = valid_acc\n",
        "\n",
        "    # test\n",
        "    return best_test_acc\n",
        "\n",
        "seed = 42\n",
        "test_acc = use_gnn(seed=seed,\n",
        "                   train_set=train_dataset_dyn_mesh,\n",
        "                   test_set=test_dataset_dyn_mesh)\n",
        "print(\"Test accuracy: {}\\n\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZMO0jxJYRX6"
      },
      "source": [
        "#### 2.3.3 Rotation-invariant GNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*a. LGR-Net:*    \n",
        "https://github.com/sailor-z/LGR-Net/tree/main"
      ],
      "metadata": {
        "id": "S1BlytF6HcsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.SamplePoints(1024, include_normals=True)\n",
        "rotate_transform = T.Compose([T.RandomRotate(degrees=180, axis=0),\n",
        "                              T.RandomRotate(degrees=180, axis=1),\n",
        "                              T.RandomRotate(degrees=180, axis=2),\n",
        "                              T.SamplePoints(1024, include_normals=True)])\n",
        "\n",
        "train_ori_lgrnet = [transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_ori_lgrnet = [transform(data).to(\"cuda\") for data in test_dataset]\n",
        "train_rot_lgrnet = [rotate_transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_rot_lgrnet = [rotate_transform(data).to(\"cuda\") for data in test_dataset]"
      ],
      "metadata": {
        "id": "nJg7iA2p9new"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def index_points(points, idx):\n",
        "    device = points.device\n",
        "    B = points.shape[0]\n",
        "    view_shape = list(idx.shape)\n",
        "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
        "    repeat_shape = list(idx.shape)\n",
        "    repeat_shape[0] = 1\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device).view(view_shape).repeat(repeat_shape)\n",
        "    new_points = points[batch_indices, idx, :]\n",
        "    return new_points\n",
        "\n",
        "def farthest_point_sample(xyz, npoint):\n",
        "    device = xyz.device\n",
        "    B, N, C = xyz.size()\n",
        "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
        "    distance = torch.ones(B, N).to(device) * 1e10\n",
        "\n",
        "    centroid = torch.mean(xyz, dim=1, keepdim=True) #[B, 1, C]\n",
        "    dist = torch.sum((xyz - centroid) ** 2, -1)\n",
        "    farthest = torch.max(dist, -1)[1]\n",
        "\n",
        "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
        "    for i in range(npoint):\n",
        "        centroids[:, i] = farthest\n",
        "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
        "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
        "        mask = dist < distance\n",
        "        distance[mask] = dist[mask]\n",
        "        farthest = torch.max(distance, -1)[1]\n",
        "    return centroids\n",
        "\n",
        "def knn(x, k):\n",
        "    inner = -2*torch.matmul(x.transpose(2, 1), x)\n",
        "    xx = torch.sum(x**2, dim=1, keepdim=True)\n",
        "    pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "    idx = pairwise_distance.topk(k=k+1, dim=-1)[1][:, :, 1:]\n",
        "    return idx\n",
        "\n",
        "def grouping(x, k=20, idx=None):\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)\n",
        "    device = torch.device('cuda')\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "    idx = idx + idx_base\n",
        "    idx = idx.view(-1)\n",
        "    _, num_dims, _ = x.size()\n",
        "    x = x.transpose(2, 1).contiguous()\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "\n",
        "    return feature.permute(0, 3, 1, 2)\n",
        "\n",
        "def darboux(points, normals, k):\n",
        "    B, C, N = points.size()\n",
        "    idx = knn(points, k)\n",
        "\n",
        "    points_knn = grouping(points, k, idx)\n",
        "    normals_knn = grouping(normals, k, idx)\n",
        "\n",
        "    mid = points_knn - points.unsqueeze(-1)\n",
        "\n",
        "    d = torch.norm(mid, p=2, dim=1)\n",
        "    l1 = torch.norm(normals, p=2, dim=1).unsqueeze(-1)\n",
        "    l2 = torch.norm(normals_knn, p=2, dim=1)\n",
        "\n",
        "    a1 = torch.sum(mid * normals.unsqueeze(-1), dim=1) / (d * l1 + 1e-10)\n",
        "    a2 = torch.sum(mid * normals_knn, dim=1) / (d * l2 + 1e-10)\n",
        "    a3 = torch.sum(normals_knn * normals.unsqueeze(-1), dim=1) / (l2 * l1 + 1e-10)\n",
        "\n",
        "    mid = mid.permute(0, 2, 3, 1).contiguous().view(-1, k, C)\n",
        "    normals_knn = normals_knn.permute(0, 2, 3, 1).contiguous().view(-1, k, C)\n",
        "    normals = normals.permute(0, 2, 1).contiguous().view(-1, 1, C)\n",
        "\n",
        "    v1 = torch.cross(mid, normals.repeat(1, k, 1))\n",
        "    v2 = torch.cross(v1, normals.repeat(1, k, 1))\n",
        "    v3 = torch.cross(mid, normals_knn)\n",
        "    v4 = torch.cross(v3, normals_knn)\n",
        "\n",
        "    d1 = torch.norm(v1, p=2, dim=-1)\n",
        "    d2 = torch.norm(v2, p=2, dim=-1)\n",
        "    d3 = torch.norm(v3, p=2, dim=-1)\n",
        "    d4 = torch.norm(v4, p=2, dim=-1)\n",
        "\n",
        "    a4 = torch.sum(v1 * v3, dim=-1) / (d1 * d3 + 1e-10) #[BN, K]\n",
        "    a4 = a4.view(B, N, k)\n",
        "    a5 = torch.sum(v2 * v4, dim=-1) / (d2 * d4  + 1e-10) #[BN, K]\n",
        "    a5 = a5.view(B, N, k)\n",
        "\n",
        "    a6 = torch.sum(v1 * v4, dim=-1) / (d1 * d4 + 1e-10) #[BN, K]\n",
        "    a6 = a6.view(B, N, k)\n",
        "    a7 = torch.sum(v2 * v3, dim=-1) / (d2 * d3  + 1e-10) #[BN, K]\n",
        "    a7 = a7.view(B, N, k)\n",
        "\n",
        "    a1.unsqueeze_(1)\n",
        "    a2.unsqueeze_(1)\n",
        "    a3.unsqueeze_(1)\n",
        "    a4.unsqueeze_(1)\n",
        "    a5.unsqueeze_(1)\n",
        "    a6.unsqueeze_(1)\n",
        "    a7.unsqueeze_(1)\n",
        "    d.unsqueeze_(1)\n",
        "\n",
        "    return torch.cat([d, a1, a2, a3, a4, a5, a6, a7], dim=1)\n",
        "\n",
        "def get_graph_feature(x, k=20, idx=None):\n",
        "    batch_size = x.size(0)\n",
        "    num_points = x.size(2)\n",
        "    x = x.view(batch_size, -1, num_points)\n",
        "    if idx is None:\n",
        "        idx = knn(x, k=k)\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    idx_base = torch.arange(0, batch_size, device=device).view(-1, 1, 1)*num_points\n",
        "    idx = idx + idx_base\n",
        "    idx = idx.view(-1)\n",
        "    _, num_dims, _ = x.size()\n",
        "    x = x.transpose(2, 1).contiguous()\n",
        "    feature = x.view(batch_size*num_points, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_points, k, num_dims)\n",
        "    x = x.view(batch_size, num_points, 1, num_dims).repeat(1, 1, k, 1)\n",
        "\n",
        "    feature = torch.cat((x, feature - x), dim=3).permute(0, 3, 1, 2)\n",
        "    return feature\n",
        "\n",
        "def global_transform(points, npoints, train, knn):\n",
        "    points = points.permute(0, 2, 1)\n",
        "    idx = farthest_point_sample(points, npoints)\n",
        "    centroids = index_points(points, idx)\n",
        "    U, S, V = torch.svd(centroids)\n",
        "\n",
        "    if train == True:\n",
        "        index = torch.randint(2, (points.size(0), 1, 3)).type(torch.FloatTensor).cuda()\n",
        "        V_ = V * index\n",
        "        V -= 2 * V_\n",
        "    else:\n",
        "        key_p = centroids[:, 0, :].unsqueeze(1)\n",
        "        angle = torch.matmul(key_p, V)\n",
        "        index = torch.le(angle, 0).type(torch.FloatTensor).cuda()\n",
        "        V_ = V * index\n",
        "        V -= 2 * V_\n",
        "\n",
        "    xyz = torch.matmul(points, V).permute(0, 2, 1)\n",
        "\n",
        "    feature = get_graph_feature(xyz, k=knn)\n",
        "    return feature\n",
        "\n",
        "class feature_fusion(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(feature_fusion, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "          nn.Conv2d(1024, 1024, (1, 1), bias=False),\n",
        "          nn.BatchNorm2d(1024),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        att = F.softmax(out, dim=-1)\n",
        "        out = x * att\n",
        "        out = torch.sum(out, dim=-1, keepdim=True)\n",
        "        return out\n",
        "\n",
        "class dar_feat(nn.Module):\n",
        "    def __init__(self, global_feat=True, knn=16, train_idx=True, cv_bias=False):\n",
        "        super(dar_feat, self).__init__()\n",
        "        self.knn = knn\n",
        "        self.train_idx = train_idx\n",
        "        self.cv_bias = cv_bias\n",
        "\n",
        "        self.gb_gconv_1 = nn.Sequential(\n",
        "          nn.Conv2d(6, 64, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.gb_gconv_2 = nn.Sequential(\n",
        "          nn.Conv2d(64, 128, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.gb_gconv_3 = nn.Sequential(\n",
        "          nn.Conv2d(128, 512, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(512),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.gb_gconv_4 = nn.Sequential(\n",
        "          nn.Conv2d(512, 1024, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(1024),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.lc_gconv_1 = nn.Sequential(\n",
        "          nn.Conv2d(8, 64, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(64),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.lc_gconv_2 = nn.Sequential(\n",
        "          nn.Conv2d(64, 128, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(128),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.lc_gconv_3 = nn.Sequential(\n",
        "          nn.Conv2d(128, 512, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(512),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.lc_gconv_4 = nn.Sequential(\n",
        "          nn.Conv2d(512, 1024, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(1024),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "          nn.Conv2d(1024, 2048, (1, 1), bias=self.cv_bias),\n",
        "          nn.BatchNorm2d(2048),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "        )\n",
        "        self.feature_fusion = feature_fusion()\n",
        "\n",
        "        self.global_feat = global_feat\n",
        "\n",
        "    def region_pooling(self, num, x):\n",
        "        _, _, _, k_num = x.size()\n",
        "        group = torch.chunk(x, num, dim=-1)\n",
        "        feature = []\n",
        "        for i in range(num):\n",
        "            feature += [torch.max(group[i], dim=-1, keepdim=False)[0]]\n",
        "        feature = torch.stack(feature).permute(1, 2, 3, 0)\n",
        "        return feature\n",
        "\n",
        "    def forward(self, points, normals):\n",
        "        n_pts = points.size(2)\n",
        "        global_f = global_transform(points, 32, self.train_idx, self.knn)\n",
        "        local_f = darboux(points, normals, self.knn)\n",
        "\n",
        "        l_out = self.lc_gconv_1(local_f)\n",
        "        l_out = self.lc_gconv_2(l_out)\n",
        "        l_out = F.max_pool2d(l_out, (1, self.knn))\n",
        "        l_out = self.lc_gconv_3(l_out)\n",
        "        l_out = self.lc_gconv_4(l_out)\n",
        "\n",
        "        g_out = self.gb_gconv_1(global_f)\n",
        "        g_out = self.gb_gconv_2(g_out)\n",
        "        g_out = F.max_pool2d(g_out, (1, self.knn))\n",
        "        g_out = self.gb_gconv_3(g_out)\n",
        "        g_out = self.gb_gconv_4(g_out)\n",
        "\n",
        "        out = torch.cat([g_out, l_out], dim=-1)\n",
        "        out = self.feature_fusion(out)\n",
        "\n",
        "        out = self.conv(out)\n",
        "        out = F.max_pool2d(out, (n_pts, 1))\n",
        "        out = out.view(-1, 2048)\n",
        "\n",
        "        if self.global_feat:\n",
        "            out = out.view(-1, 2048)\n",
        "            return out\n",
        "        else:\n",
        "            out = out.view(-1, 2048, 1, 1).repeat(1, 1, n_pts, 1)\n",
        "            return torch.cat([out, g_out, l_out], 1)\n",
        "\n",
        "class LGRNet(nn.Module):\n",
        "    def __init__(self, k=10, knn=16, train_idx=True, cv_bias=False):\n",
        "        super(LGRNet, self).__init__()\n",
        "\n",
        "        self.class_nums = k\n",
        "        self.knn = knn\n",
        "        self.cv_bias = cv_bias\n",
        "        self.train_idx = train_idx\n",
        "\n",
        "        self.feat = dar_feat(global_feat=True, knn=self.knn, train_idx=self.train_idx, cv_bias=self.cv_bias)\n",
        "\n",
        "        self.classify = nn.Sequential(\n",
        "          nn.Linear(2048, 512, bias=self.cv_bias),\n",
        "          nn.BatchNorm1d(512),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "          nn.Linear(512, 256),\n",
        "          nn.BatchNorm1d(256),\n",
        "          nn.Dropout(0.5),\n",
        "          nn.LeakyReLU(negative_slope=0.2),\n",
        "          nn.Linear(256, self.class_nums)\n",
        "        )\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                torch.nn.init.xavier_normal_(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    torch.nn.init.constant_(m.bias.data, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                torch.nn.init.xavier_normal_(m.weight.data)\n",
        "                if m.bias is not None:\n",
        "                    torch.nn.init.constant_(m.bias.data, 0)\n",
        "            elif isinstance(m, nn.BatchNorm1d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, train_data):\n",
        "        points, normals = train_data.pos, train_data.normal\n",
        "        points = points.reshape(-1, 1024, 3).transpose(1, 2)\n",
        "        normals = normals.reshape(-1, 1024, 3).transpose(1, 2)\n",
        "        x = self.feat(points, normals)\n",
        "        x = self.classify(x)\n",
        "        return x\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, evalloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for idx, eval_data in enumerate(evalloader):\n",
        "            pred = self(eval_data).max(dim=1)[1]\n",
        "            correct += pred.eq(eval_data.y).sum().item()\n",
        "            total += eval_data.y.shape[0]\n",
        "        return correct / total\n",
        "\n",
        "\n",
        "def use_lgr(seed, train_set, test_set):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    lgrnet_model = LGRNet().to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(lgrnet_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "    # data\n",
        "    train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(20):\n",
        "        lgrnet_model.train()\n",
        "\n",
        "        for idx, train_data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            pred = lgrnet_model(train_data)\n",
        "            loss = F.cross_entropy(pred, train_data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            lgrnet_model.eval()\n",
        "            valid_acc = lgrnet_model.eval_accuracy(test_loader)\n",
        "            print(\"Epoch: {}\\tValidation accuracy: {}\".format(epoch + 1, valid_acc))\n",
        "\n",
        "            if valid_acc > best_test_acc:\n",
        "                best_test_acc = valid_acc\n",
        "\n",
        "    # test\n",
        "    return best_test_acc\n",
        "\n",
        "\n",
        "seed = 42\n",
        "ori_ori_acc = use_lgr(seed=seed,\n",
        "                      train_set=train_ori_lgrnet,\n",
        "                      test_set=test_ori_lgrnet)\n",
        "print(\"Accuracy of original training & original test: {}\\n\".format(ori_ori_acc))\n",
        "\n",
        "ori_rot_acc = use_lgr(seed=seed,\n",
        "                      train_set=train_ori_lgrnet,\n",
        "                      test_set=test_rot_lgrnet)\n",
        "print(\"Accuracy of original training & rotated test: {}\\n\".format(ori_rot_acc))\n",
        "\n",
        "rot_rot_acc = use_lgr(seed=seed,\n",
        "                      train_set=train_rot_lgrnet,\n",
        "                      test_set=test_rot_lgrnet)\n",
        "print(\"Accuracy of rotated training & rotated test: {}\\n\".format(rot_rot_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgR_IIgC3FZK",
        "outputId": "3cd190d8-5855-43f6-c1ef-6f07ccd167a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\tValidation accuracy: 0.6266519823788547\n",
            "Epoch: 2\tValidation accuracy: 0.7257709251101322\n",
            "Epoch: 3\tValidation accuracy: 0.7577092511013216\n",
            "Epoch: 4\tValidation accuracy: 0.7455947136563876\n",
            "Epoch: 5\tValidation accuracy: 0.7720264317180616\n",
            "Epoch: 6\tValidation accuracy: 0.7555066079295154\n",
            "Epoch: 7\tValidation accuracy: 0.7797356828193832\n",
            "Epoch: 8\tValidation accuracy: 0.7984581497797357\n",
            "Epoch: 9\tValidation accuracy: 0.7918502202643172\n",
            "Epoch: 10\tValidation accuracy: 0.7687224669603524\n",
            "Epoch: 11\tValidation accuracy: 0.789647577092511\n",
            "Epoch: 12\tValidation accuracy: 0.7169603524229075\n",
            "Epoch: 13\tValidation accuracy: 0.7819383259911894\n",
            "Epoch: 14\tValidation accuracy: 0.8171806167400881\n",
            "Epoch: 15\tValidation accuracy: 0.8105726872246696\n",
            "Epoch: 16\tValidation accuracy: 0.7951541850220264\n",
            "Epoch: 17\tValidation accuracy: 0.7852422907488987\n",
            "Epoch: 18\tValidation accuracy: 0.7544052863436124\n",
            "Epoch: 19\tValidation accuracy: 0.829295154185022\n",
            "Epoch: 20\tValidation accuracy: 0.8392070484581498\n",
            "Accuracy of original training & original test: 0.8392070484581498\n",
            "\n",
            "Epoch: 1\tValidation accuracy: 0.6310572687224669\n",
            "Epoch: 2\tValidation accuracy: 0.7257709251101322\n",
            "Epoch: 3\tValidation accuracy: 0.7477973568281938\n",
            "Epoch: 4\tValidation accuracy: 0.7577092511013216\n",
            "Epoch: 5\tValidation accuracy: 0.7742290748898678\n",
            "Epoch: 6\tValidation accuracy: 0.748898678414097\n",
            "Epoch: 7\tValidation accuracy: 0.7698237885462555\n",
            "Epoch: 8\tValidation accuracy: 0.788546255506608\n",
            "Epoch: 9\tValidation accuracy: 0.7940528634361234\n",
            "Epoch: 10\tValidation accuracy: 0.7819383259911894\n",
            "Epoch: 11\tValidation accuracy: 0.7841409691629956\n",
            "Epoch: 12\tValidation accuracy: 0.7147577092511013\n",
            "Epoch: 13\tValidation accuracy: 0.7808370044052864\n",
            "Epoch: 14\tValidation accuracy: 0.8050660792951542\n",
            "Epoch: 15\tValidation accuracy: 0.8105726872246696\n",
            "Epoch: 16\tValidation accuracy: 0.7995594713656388\n",
            "Epoch: 17\tValidation accuracy: 0.7808370044052864\n",
            "Epoch: 18\tValidation accuracy: 0.7687224669603524\n",
            "Epoch: 19\tValidation accuracy: 0.8370044052863436\n",
            "Epoch: 20\tValidation accuracy: 0.8325991189427313\n",
            "Accuracy of original training & rotated test: 0.8370044052863436\n",
            "\n",
            "Epoch: 1\tValidation accuracy: 0.6519823788546255\n",
            "Epoch: 2\tValidation accuracy: 0.6762114537444934\n",
            "Epoch: 3\tValidation accuracy: 0.7257709251101322\n",
            "Epoch: 4\tValidation accuracy: 0.6795154185022027\n",
            "Epoch: 5\tValidation accuracy: 0.7544052863436124\n",
            "Epoch: 6\tValidation accuracy: 0.8083700440528634\n",
            "Epoch: 7\tValidation accuracy: 0.776431718061674\n",
            "Epoch: 8\tValidation accuracy: 0.7720264317180616\n",
            "Epoch: 9\tValidation accuracy: 0.8039647577092511\n",
            "Epoch: 10\tValidation accuracy: 0.7841409691629956\n",
            "Epoch: 11\tValidation accuracy: 0.8215859030837004\n",
            "Epoch: 12\tValidation accuracy: 0.7588105726872246\n",
            "Epoch: 13\tValidation accuracy: 0.816079295154185\n",
            "Epoch: 14\tValidation accuracy: 0.7037444933920705\n",
            "Epoch: 15\tValidation accuracy: 0.8116740088105727\n",
            "Epoch: 16\tValidation accuracy: 0.8116740088105727\n",
            "Epoch: 17\tValidation accuracy: 0.8392070484581498\n",
            "Epoch: 18\tValidation accuracy: 0.7389867841409692\n",
            "Epoch: 19\tValidation accuracy: 0.8182819383259912\n",
            "Epoch: 20\tValidation accuracy: 0.762114537444934\n",
            "Accuracy of rotated training & rotated test: 0.8392070484581498\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*b. PointNet:*    \n",
        "https://github.com/fxia22/pointnet.pytorch/tree/master"
      ],
      "metadata": {
        "id": "pBCN6_15HYD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.SamplePoints(1024)\n",
        "rotate_transform = T.Compose([T.RandomRotate(degrees=180, axis=0),\n",
        "                              T.RandomRotate(degrees=180, axis=1),\n",
        "                              T.RandomRotate(degrees=180, axis=2),\n",
        "                              T.SamplePoints(1024)])\n",
        "\n",
        "train_ori_pointnet = [transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_ori_pointnet = [transform(data).to(\"cuda\") for data in test_dataset]\n",
        "train_rot_pointnet = [rotate_transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_rot_pointnet = [rotate_transform(data).to(\"cuda\") for data in test_dataset]"
      ],
      "metadata": {
        "id": "4DSftsKt7bCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class STN3d(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(STN3d, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 9)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        # x = F.relu(self.bn1(self.conv1(x)))\n",
        "        # x = F.relu(self.bn2(self.conv2(x)))\n",
        "        # x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        # x = F.relu(self.bn4(self.fc1(x)))\n",
        "        # x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = torch.tensor([[1,0,0,0,1,0,0,0,1]], dtype=torch.float32).repeat(batchsize, 1).to(\"cuda\")\n",
        "        x = x + iden\n",
        "        x = x.view(-1, 3, 3)\n",
        "        return x\n",
        "\n",
        "class PointNetfeat(nn.Module):\n",
        "    def __init__(self, global_feat = True, feature_transform=False):\n",
        "        super(PointNetfeat, self).__init__()\n",
        "        self.stn = STN3d()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.global_feat = global_feat\n",
        "        self.feature_transform = feature_transform\n",
        "        # if self.feature_transform:\n",
        "        #     self.fstn = STNkd(k=64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        n_pts = x.size()[2]\n",
        "        trans = self.stn(x)\n",
        "        x = x.transpose(2, 1)\n",
        "        x = torch.bmm(x, trans)\n",
        "        x = x.transpose(2, 1)\n",
        "        # x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.conv1(x))\n",
        "\n",
        "        if self.feature_transform:\n",
        "            trans_feat = self.fstn(x)\n",
        "            x = x.transpose(2,1)\n",
        "            x = torch.bmm(x, trans_feat)\n",
        "            x = x.transpose(2,1)\n",
        "        else:\n",
        "            trans_feat = None\n",
        "\n",
        "        pointfeat = x\n",
        "        # x = F.relu(self.bn2(self.conv2(x)))\n",
        "        # x = self.bn3(self.conv3(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "        if self.global_feat:\n",
        "            return x, trans, trans_feat\n",
        "        else:\n",
        "            x = x.view(-1, 1024, 1).repeat(1, 1, n_pts)\n",
        "            return torch.cat([x, pointfeat], 1), trans, trans_feat\n",
        "\n",
        "class PointNetCls(nn.Module):\n",
        "    def __init__(self, k, num_points, feature_transform=False):\n",
        "        super(PointNetCls, self).__init__()\n",
        "        self.feature_transform = feature_transform\n",
        "        self.feat = PointNetfeat(global_feat=True, feature_transform=feature_transform)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, k)\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "        self.bn1 = nn.BatchNorm1d(512)\n",
        "        self.bn2 = nn.BatchNorm1d(256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.num_points = num_points\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, trans, trans_feat = self.feat(x)\n",
        "        # x = F.relu(self.bn1(self.fc1(x)))\n",
        "        # x = F.relu(self.bn2(self.dropout(self.fc2(x))))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.dropout(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        # return F.log_softmax(x, dim=1), trans, trans_feat\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, evalloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for idx, eval_data in enumerate(evalloader):\n",
        "            pred = self(eval_data.pos.reshape(-1,self.num_points,3).transpose(1,2)).max(dim=1)[1]\n",
        "            correct += pred.eq(eval_data.y).sum().item()\n",
        "            total += eval_data.y.shape[0]\n",
        "        return correct / total\n",
        "\n",
        "\n",
        "def use_pointnet(seed, num_points, train_set, test_set):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    pointnet_model = PointNetCls(k=train_dataset.num_classes, num_points=num_points).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(pointnet_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "\n",
        "    # data\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(50):\n",
        "        pointnet_model.train()\n",
        "\n",
        "        for idx, train_data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            pred = pointnet_model(train_data.pos.reshape(-1,num_points,3).transpose(1,2))\n",
        "            loss = F.nll_loss(pred, train_data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            pointnet_model.eval()\n",
        "            valid_acc = pointnet_model.eval_accuracy(test_loader)\n",
        "            print(\"Epoch: {}\\tValidation accuracy: {}\".format(epoch + 1, valid_acc))\n",
        "\n",
        "            if valid_acc > best_test_acc:\n",
        "                best_test_acc = valid_acc\n",
        "\n",
        "    # test\n",
        "    return best_test_acc\n",
        "\n",
        "seed = 42\n",
        "num_points = 1024\n",
        "ori_ori_acc = use_pointnet(seed=seed,\n",
        "                           num_points=num_points,\n",
        "                           train_set=train_ori_pointnet,\n",
        "                           test_set=test_ori_pointnet)\n",
        "print(\"Accuracy of original training & original test: {}\\n\".format(ori_ori_acc))\n",
        "\n",
        "ori_rot_acc = use_pointnet(seed=seed,\n",
        "                           num_points=num_points,\n",
        "                           train_set=train_ori_pointnet,\n",
        "                           test_set=test_rot_pointnet)\n",
        "print(\"Accuracy of original training & rotated test: {}\\n\".format(ori_rot_acc))\n",
        "\n",
        "rot_rot_acc = use_pointnet(seed=seed,\n",
        "                           num_points=num_points,\n",
        "                           train_set=train_rot_pointnet,\n",
        "                           test_set=test_rot_pointnet)\n",
        "print(\"Accuracy of rotated training & rotated test: {}\\n\".format(rot_rot_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H-ON_1oCXSq",
        "outputId": "effafe0a-8361-4503-9947-bab49a4781cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\tValidation accuracy: 0.6288546255506607\n",
            "Epoch: 2\tValidation accuracy: 0.73568281938326\n",
            "Epoch: 3\tValidation accuracy: 0.789647577092511\n",
            "Epoch: 4\tValidation accuracy: 0.7918502202643172\n",
            "Epoch: 5\tValidation accuracy: 0.7863436123348018\n",
            "Epoch: 6\tValidation accuracy: 0.829295154185022\n",
            "Epoch: 7\tValidation accuracy: 0.8325991189427313\n",
            "Epoch: 8\tValidation accuracy: 0.8314977973568282\n",
            "Epoch: 9\tValidation accuracy: 0.8568281938325991\n",
            "Epoch: 10\tValidation accuracy: 0.8502202643171806\n",
            "Epoch: 11\tValidation accuracy: 0.8381057268722467\n",
            "Epoch: 12\tValidation accuracy: 0.8634361233480177\n",
            "Epoch: 13\tValidation accuracy: 0.8634361233480177\n",
            "Epoch: 14\tValidation accuracy: 0.8744493392070485\n",
            "Epoch: 15\tValidation accuracy: 0.8392070484581498\n",
            "Epoch: 16\tValidation accuracy: 0.8667400881057269\n",
            "Epoch: 17\tValidation accuracy: 0.8590308370044053\n",
            "Epoch: 18\tValidation accuracy: 0.8270925110132159\n",
            "Epoch: 19\tValidation accuracy: 0.8667400881057269\n",
            "Epoch: 20\tValidation accuracy: 0.8425110132158591\n",
            "Epoch: 21\tValidation accuracy: 0.8425110132158591\n",
            "Epoch: 22\tValidation accuracy: 0.8722466960352423\n",
            "Epoch: 23\tValidation accuracy: 0.8678414096916299\n",
            "Epoch: 24\tValidation accuracy: 0.8832599118942731\n",
            "Epoch: 25\tValidation accuracy: 0.8909691629955947\n",
            "Epoch: 26\tValidation accuracy: 0.8821585903083701\n",
            "Epoch: 27\tValidation accuracy: 0.8810572687224669\n",
            "Epoch: 28\tValidation accuracy: 0.8854625550660793\n",
            "Epoch: 29\tValidation accuracy: 0.8766519823788547\n",
            "Epoch: 30\tValidation accuracy: 0.8469162995594713\n",
            "Epoch: 31\tValidation accuracy: 0.8843612334801763\n",
            "Epoch: 32\tValidation accuracy: 0.8898678414096917\n",
            "Epoch: 33\tValidation accuracy: 0.8634361233480177\n",
            "Epoch: 34\tValidation accuracy: 0.8865638766519823\n",
            "Epoch: 35\tValidation accuracy: 0.8656387665198237\n",
            "Epoch: 36\tValidation accuracy: 0.8975770925110133\n",
            "Epoch: 37\tValidation accuracy: 0.8568281938325991\n",
            "Epoch: 38\tValidation accuracy: 0.8689427312775331\n",
            "Epoch: 39\tValidation accuracy: 0.8854625550660793\n",
            "Epoch: 40\tValidation accuracy: 0.8876651982378855\n",
            "Epoch: 41\tValidation accuracy: 0.8678414096916299\n",
            "Epoch: 42\tValidation accuracy: 0.8634361233480177\n",
            "Epoch: 43\tValidation accuracy: 0.8810572687224669\n",
            "Epoch: 44\tValidation accuracy: 0.8931718061674009\n",
            "Epoch: 45\tValidation accuracy: 0.8821585903083701\n",
            "Epoch: 46\tValidation accuracy: 0.9008810572687225\n",
            "Epoch: 47\tValidation accuracy: 0.8788546255506607\n",
            "Epoch: 48\tValidation accuracy: 0.8832599118942731\n",
            "Epoch: 49\tValidation accuracy: 0.8975770925110133\n",
            "Epoch: 50\tValidation accuracy: 0.8887665198237885\n",
            "Accuracy of original training & original test: 0.9008810572687225\n",
            "\n",
            "Epoch: 1\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 2\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 3\tValidation accuracy: 0.13105726872246695\n",
            "Epoch: 4\tValidation accuracy: 0.1277533039647577\n",
            "Epoch: 5\tValidation accuracy: 0.12555066079295155\n",
            "Epoch: 6\tValidation accuracy: 0.11674008810572688\n",
            "Epoch: 7\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 8\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 9\tValidation accuracy: 0.1277533039647577\n",
            "Epoch: 10\tValidation accuracy: 0.1211453744493392\n",
            "Epoch: 11\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 12\tValidation accuracy: 0.1145374449339207\n",
            "Epoch: 13\tValidation accuracy: 0.13215859030837004\n",
            "Epoch: 14\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 15\tValidation accuracy: 0.10792951541850221\n",
            "Epoch: 16\tValidation accuracy: 0.1288546255506608\n",
            "Epoch: 17\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 18\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 19\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 20\tValidation accuracy: 0.11674008810572688\n",
            "Epoch: 21\tValidation accuracy: 0.10022026431718062\n",
            "Epoch: 22\tValidation accuracy: 0.10572687224669604\n",
            "Epoch: 23\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 24\tValidation accuracy: 0.1354625550660793\n",
            "Epoch: 25\tValidation accuracy: 0.10352422907488987\n",
            "Epoch: 26\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 27\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 28\tValidation accuracy: 0.13105726872246695\n",
            "Epoch: 29\tValidation accuracy: 0.09140969162995595\n",
            "Epoch: 30\tValidation accuracy: 0.10022026431718062\n",
            "Epoch: 31\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 32\tValidation accuracy: 0.1145374449339207\n",
            "Epoch: 33\tValidation accuracy: 0.11233480176211454\n",
            "Epoch: 34\tValidation accuracy: 0.1343612334801762\n",
            "Epoch: 35\tValidation accuracy: 0.11894273127753303\n",
            "Epoch: 36\tValidation accuracy: 0.10242290748898679\n",
            "Epoch: 37\tValidation accuracy: 0.09911894273127753\n",
            "Epoch: 38\tValidation accuracy: 0.11674008810572688\n",
            "Epoch: 39\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 40\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 41\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 42\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 43\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 44\tValidation accuracy: 0.10352422907488987\n",
            "Epoch: 45\tValidation accuracy: 0.11674008810572688\n",
            "Epoch: 46\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 47\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 48\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 49\tValidation accuracy: 0.12444933920704845\n",
            "Epoch: 50\tValidation accuracy: 0.11123348017621146\n",
            "Accuracy of original training & rotated test: 0.1354625550660793\n",
            "\n",
            "Epoch: 1\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 2\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 3\tValidation accuracy: 0.16519823788546256\n",
            "Epoch: 4\tValidation accuracy: 0.16299559471365638\n",
            "Epoch: 5\tValidation accuracy: 0.1828193832599119\n",
            "Epoch: 6\tValidation accuracy: 0.1905286343612335\n",
            "Epoch: 7\tValidation accuracy: 0.24118942731277532\n",
            "Epoch: 8\tValidation accuracy: 0.24669603524229075\n",
            "Epoch: 9\tValidation accuracy: 0.22466960352422907\n",
            "Epoch: 10\tValidation accuracy: 0.26762114537444937\n",
            "Epoch: 11\tValidation accuracy: 0.29845814977973567\n",
            "Epoch: 12\tValidation accuracy: 0.32268722466960353\n",
            "Epoch: 13\tValidation accuracy: 0.2687224669603524\n",
            "Epoch: 14\tValidation accuracy: 0.3381057268722467\n",
            "Epoch: 15\tValidation accuracy: 0.3590308370044053\n",
            "Epoch: 16\tValidation accuracy: 0.42070484581497797\n",
            "Epoch: 17\tValidation accuracy: 0.44162995594713655\n",
            "Epoch: 18\tValidation accuracy: 0.4944933920704846\n",
            "Epoch: 19\tValidation accuracy: 0.4856828193832599\n",
            "Epoch: 20\tValidation accuracy: 0.4944933920704846\n",
            "Epoch: 21\tValidation accuracy: 0.4790748898678414\n",
            "Epoch: 22\tValidation accuracy: 0.5044052863436124\n",
            "Epoch: 23\tValidation accuracy: 0.5110132158590308\n",
            "Epoch: 24\tValidation accuracy: 0.5077092511013216\n",
            "Epoch: 25\tValidation accuracy: 0.5308370044052864\n",
            "Epoch: 26\tValidation accuracy: 0.5352422907488987\n",
            "Epoch: 27\tValidation accuracy: 0.5495594713656388\n",
            "Epoch: 28\tValidation accuracy: 0.5462555066079295\n",
            "Epoch: 29\tValidation accuracy: 0.539647577092511\n",
            "Epoch: 30\tValidation accuracy: 0.5429515418502202\n",
            "Epoch: 31\tValidation accuracy: 0.5506607929515418\n",
            "Epoch: 32\tValidation accuracy: 0.5297356828193832\n",
            "Epoch: 33\tValidation accuracy: 0.552863436123348\n",
            "Epoch: 34\tValidation accuracy: 0.5605726872246696\n",
            "Epoch: 35\tValidation accuracy: 0.5374449339207048\n",
            "Epoch: 36\tValidation accuracy: 0.5759911894273128\n",
            "Epoch: 37\tValidation accuracy: 0.5462555066079295\n",
            "Epoch: 38\tValidation accuracy: 0.5429515418502202\n",
            "Epoch: 39\tValidation accuracy: 0.5594713656387665\n",
            "Epoch: 40\tValidation accuracy: 0.539647577092511\n",
            "Epoch: 41\tValidation accuracy: 0.5837004405286343\n",
            "Epoch: 42\tValidation accuracy: 0.5825991189427313\n",
            "Epoch: 43\tValidation accuracy: 0.5539647577092511\n",
            "Epoch: 44\tValidation accuracy: 0.5627753303964758\n",
            "Epoch: 45\tValidation accuracy: 0.5572687224669604\n",
            "Epoch: 46\tValidation accuracy: 0.5737885462555066\n",
            "Epoch: 47\tValidation accuracy: 0.5914096916299559\n",
            "Epoch: 48\tValidation accuracy: 0.5892070484581498\n",
            "Epoch: 49\tValidation accuracy: 0.5825991189427313\n",
            "Epoch: 50\tValidation accuracy: 0.5550660792951542\n",
            "Accuracy of rotated training & rotated test: 0.5914096916299559\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*c. Use original edges:*"
      ],
      "metadata": {
        "id": "-B40J8SH8ohi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.FaceToEdge(remove_faces=False)\n",
        "rotate_transform = T.Compose([T.RandomRotate(degrees=180, axis=0),\n",
        "                              T.RandomRotate(degrees=180, axis=1),\n",
        "                              T.RandomRotate(degrees=180, axis=2),\n",
        "                              T.FaceToEdge(remove_faces=False)])\n",
        "\n",
        "train_ori_edges = [transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_ori_edges = [transform(data).to(\"cuda\") for data in test_dataset]\n",
        "train_rot_edges = [rotate_transform(data).to(\"cuda\") for data in train_dataset]\n",
        "test_rot_edges = [rotate_transform(data).to(\"cuda\") for data in test_dataset]"
      ],
      "metadata": {
        "id": "gm32hzr741s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MeshOriginalEdge(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, num_classes):\n",
        "        super(MeshOriginalEdge, self).__init__()\n",
        "        self.conv1 = pyg_nn.GCNConv(3, hidden_dim)\n",
        "        self.conv2 = pyg_nn.GCNConv(hidden_dim, hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, train_data):\n",
        "        pos, edge_index, batch = train_data.pos, train_data.edge_index, train_data.batch\n",
        "        x = self.conv1(pos, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        pooled = global_max_pool(x, batch)\n",
        "        return self.classifier(pooled)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_accuracy(self, evalloader):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for idx, eval_data in enumerate(evalloader):\n",
        "            pred = self(eval_data).max(dim=1)[1]\n",
        "            correct += pred.eq(eval_data.y).sum().item()\n",
        "            total += eval_data.y.shape[0]\n",
        "        return correct / total\n",
        "\n",
        "\n",
        "def use_edges(seed, hidden_dim, train_set, test_set):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = MeshOriginalEdge(hidden_dim=hidden_dim, num_classes=train_dataset.num_classes).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.005, weight_decay=0)\n",
        "\n",
        "    # data\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
        "\n",
        "    # train\n",
        "    best_test_acc = 0\n",
        "    for epoch in range(50):\n",
        "        gnn_model.train()\n",
        "\n",
        "        for idx, train_data in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            pred = gnn_model(train_data)\n",
        "            loss = F.cross_entropy(pred, train_data.y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 1 == 0:\n",
        "            gnn_model.eval()\n",
        "            valid_acc = gnn_model.eval_accuracy(test_loader)\n",
        "            print(\"Epoch: {}\\tValidation accuracy: {}\".format(epoch + 1, valid_acc))\n",
        "\n",
        "            if valid_acc > best_test_acc:\n",
        "                best_test_acc = valid_acc\n",
        "\n",
        "    # test\n",
        "    return best_test_acc\n",
        "\n",
        "\n",
        "seed = 114514\n",
        "ori_ori_acc = use_edges(seed=seed,\n",
        "                        hidden_dim=32,\n",
        "                        train_set=train_ori_edges,\n",
        "                        test_set=test_ori_edges)\n",
        "print(\"Accuracy of original training & original test: {}\\n\".format(ori_ori_acc))\n",
        "\n",
        "ori_rot_acc = use_edges(seed=seed,\n",
        "                        hidden_dim=32,\n",
        "                        train_set=train_ori_edges,\n",
        "                        test_set=test_rot_edges)\n",
        "print(\"Accuracy of original training & rotated test: {}\\n\".format(ori_rot_acc))\n",
        "\n",
        "rot_rot_acc = use_edges(seed=seed,\n",
        "                        hidden_dim=32,\n",
        "                        train_set=train_rot_edges,\n",
        "                        test_set=test_rot_edges)\n",
        "print(\"Accuracy of rotated training & rotated test: {}\\n\".format(rot_rot_acc))"
      ],
      "metadata": {
        "id": "Z67PM1iJEo7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9225a96f-3a69-4705-8a1e-da73e463c4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/warnings.py:19: UserWarning: The usage of `scatter(reduce='max')` can be accelerated via the 'torch-scatter' package, but it was not found\n",
            "  warnings.warn(message)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\tValidation accuracy: 0.41409691629955947\n",
            "Epoch: 2\tValidation accuracy: 0.6398678414096917\n",
            "Epoch: 3\tValidation accuracy: 0.6519823788546255\n",
            "Epoch: 4\tValidation accuracy: 0.710352422907489\n",
            "Epoch: 5\tValidation accuracy: 0.7136563876651982\n",
            "Epoch: 6\tValidation accuracy: 0.7555066079295154\n",
            "Epoch: 7\tValidation accuracy: 0.7180616740088106\n",
            "Epoch: 8\tValidation accuracy: 0.724669603524229\n",
            "Epoch: 9\tValidation accuracy: 0.7455947136563876\n",
            "Epoch: 10\tValidation accuracy: 0.763215859030837\n",
            "Epoch: 11\tValidation accuracy: 0.7687224669603524\n",
            "Epoch: 12\tValidation accuracy: 0.7709251101321586\n",
            "Epoch: 13\tValidation accuracy: 0.7533039647577092\n",
            "Epoch: 14\tValidation accuracy: 0.7588105726872246\n",
            "Epoch: 15\tValidation accuracy: 0.7533039647577092\n",
            "Epoch: 16\tValidation accuracy: 0.7852422907488987\n",
            "Epoch: 17\tValidation accuracy: 0.7775330396475771\n",
            "Epoch: 18\tValidation accuracy: 0.7687224669603524\n",
            "Epoch: 19\tValidation accuracy: 0.7918502202643172\n",
            "Epoch: 20\tValidation accuracy: 0.7951541850220264\n",
            "Epoch: 21\tValidation accuracy: 0.7852422907488987\n",
            "Epoch: 22\tValidation accuracy: 0.7874449339207048\n",
            "Epoch: 23\tValidation accuracy: 0.7984581497797357\n",
            "Epoch: 24\tValidation accuracy: 0.7522026431718062\n",
            "Epoch: 25\tValidation accuracy: 0.7687224669603524\n",
            "Epoch: 26\tValidation accuracy: 0.789647577092511\n",
            "Epoch: 27\tValidation accuracy: 0.7709251101321586\n",
            "Epoch: 28\tValidation accuracy: 0.7698237885462555\n",
            "Epoch: 29\tValidation accuracy: 0.8050660792951542\n",
            "Epoch: 30\tValidation accuracy: 0.7852422907488987\n",
            "Epoch: 31\tValidation accuracy: 0.7808370044052864\n",
            "Epoch: 32\tValidation accuracy: 0.775330396475771\n",
            "Epoch: 33\tValidation accuracy: 0.7808370044052864\n",
            "Epoch: 34\tValidation accuracy: 0.776431718061674\n",
            "Epoch: 35\tValidation accuracy: 0.7874449339207048\n",
            "Epoch: 36\tValidation accuracy: 0.789647577092511\n",
            "Epoch: 37\tValidation accuracy: 0.7863436123348018\n",
            "Epoch: 38\tValidation accuracy: 0.801762114537445\n",
            "Epoch: 39\tValidation accuracy: 0.7797356828193832\n",
            "Epoch: 40\tValidation accuracy: 0.7841409691629956\n",
            "Epoch: 41\tValidation accuracy: 0.8039647577092511\n",
            "Epoch: 42\tValidation accuracy: 0.7808370044052864\n",
            "Epoch: 43\tValidation accuracy: 0.7775330396475771\n",
            "Epoch: 44\tValidation accuracy: 0.7918502202643172\n",
            "Epoch: 45\tValidation accuracy: 0.8072687224669604\n",
            "Epoch: 46\tValidation accuracy: 0.7577092511013216\n",
            "Epoch: 47\tValidation accuracy: 0.7995594713656388\n",
            "Epoch: 48\tValidation accuracy: 0.8006607929515418\n",
            "Epoch: 49\tValidation accuracy: 0.8006607929515418\n",
            "Epoch: 50\tValidation accuracy: 0.7918502202643172\n",
            "Accuracy of original training & original test: 0.8072687224669604\n",
            "\n",
            "Epoch: 1\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 2\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 3\tValidation accuracy: 0.1211453744493392\n",
            "Epoch: 4\tValidation accuracy: 0.1211453744493392\n",
            "Epoch: 5\tValidation accuracy: 0.1277533039647577\n",
            "Epoch: 6\tValidation accuracy: 0.1277533039647577\n",
            "Epoch: 7\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 8\tValidation accuracy: 0.11674008810572688\n",
            "Epoch: 9\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 10\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 11\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 12\tValidation accuracy: 0.1145374449339207\n",
            "Epoch: 13\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 14\tValidation accuracy: 0.1277533039647577\n",
            "Epoch: 15\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 16\tValidation accuracy: 0.11784140969162996\n",
            "Epoch: 17\tValidation accuracy: 0.11894273127753303\n",
            "Epoch: 18\tValidation accuracy: 0.1145374449339207\n",
            "Epoch: 19\tValidation accuracy: 0.1288546255506608\n",
            "Epoch: 20\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 21\tValidation accuracy: 0.12444933920704845\n",
            "Epoch: 22\tValidation accuracy: 0.11784140969162996\n",
            "Epoch: 23\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 24\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 25\tValidation accuracy: 0.11784140969162996\n",
            "Epoch: 26\tValidation accuracy: 0.11894273127753303\n",
            "Epoch: 27\tValidation accuracy: 0.13105726872246695\n",
            "Epoch: 28\tValidation accuracy: 0.12665198237885464\n",
            "Epoch: 29\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 30\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 31\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 32\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 33\tValidation accuracy: 0.1145374449339207\n",
            "Epoch: 34\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 35\tValidation accuracy: 0.11123348017621146\n",
            "Epoch: 36\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 37\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 38\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 39\tValidation accuracy: 0.11343612334801761\n",
            "Epoch: 40\tValidation accuracy: 0.1211453744493392\n",
            "Epoch: 41\tValidation accuracy: 0.12004405286343613\n",
            "Epoch: 42\tValidation accuracy: 0.1145374449339207\n",
            "Epoch: 43\tValidation accuracy: 0.12334801762114538\n",
            "Epoch: 44\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 45\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 46\tValidation accuracy: 0.1222466960352423\n",
            "Epoch: 47\tValidation accuracy: 0.12444933920704845\n",
            "Epoch: 48\tValidation accuracy: 0.11563876651982379\n",
            "Epoch: 49\tValidation accuracy: 0.11894273127753303\n",
            "Epoch: 50\tValidation accuracy: 0.12555066079295155\n",
            "Accuracy of original training & rotated test: 0.13105726872246695\n",
            "\n",
            "Epoch: 1\tValidation accuracy: 0.11013215859030837\n",
            "Epoch: 2\tValidation accuracy: 0.15088105726872247\n",
            "Epoch: 3\tValidation accuracy: 0.13876651982378854\n",
            "Epoch: 4\tValidation accuracy: 0.17841409691629956\n",
            "Epoch: 5\tValidation accuracy: 0.15418502202643172\n",
            "Epoch: 6\tValidation accuracy: 0.1751101321585903\n",
            "Epoch: 7\tValidation accuracy: 0.1817180616740088\n",
            "Epoch: 8\tValidation accuracy: 0.20044052863436124\n",
            "Epoch: 9\tValidation accuracy: 0.22356828193832598\n",
            "Epoch: 10\tValidation accuracy: 0.21696035242290748\n",
            "Epoch: 11\tValidation accuracy: 0.22797356828193832\n",
            "Epoch: 12\tValidation accuracy: 0.24118942731277532\n",
            "Epoch: 13\tValidation accuracy: 0.2522026431718062\n",
            "Epoch: 14\tValidation accuracy: 0.2588105726872247\n",
            "Epoch: 15\tValidation accuracy: 0.2599118942731278\n",
            "Epoch: 16\tValidation accuracy: 0.263215859030837\n",
            "Epoch: 17\tValidation accuracy: 0.2841409691629956\n",
            "Epoch: 18\tValidation accuracy: 0.2665198237885463\n",
            "Epoch: 19\tValidation accuracy: 0.26762114537444937\n",
            "Epoch: 20\tValidation accuracy: 0.2621145374449339\n",
            "Epoch: 21\tValidation accuracy: 0.2709251101321586\n",
            "Epoch: 22\tValidation accuracy: 0.2610132158590308\n",
            "Epoch: 23\tValidation accuracy: 0.27973568281938327\n",
            "Epoch: 24\tValidation accuracy: 0.2610132158590308\n",
            "Epoch: 25\tValidation accuracy: 0.28634361233480177\n",
            "Epoch: 26\tValidation accuracy: 0.2654185022026432\n",
            "Epoch: 27\tValidation accuracy: 0.2566079295154185\n",
            "Epoch: 28\tValidation accuracy: 0.24669603524229075\n",
            "Epoch: 29\tValidation accuracy: 0.29515418502202645\n",
            "Epoch: 30\tValidation accuracy: 0.30837004405286345\n",
            "Epoch: 31\tValidation accuracy: 0.27973568281938327\n",
            "Epoch: 32\tValidation accuracy: 0.27973568281938327\n",
            "Epoch: 33\tValidation accuracy: 0.27312775330396477\n",
            "Epoch: 34\tValidation accuracy: 0.2830396475770925\n",
            "Epoch: 35\tValidation accuracy: 0.31828193832599116\n",
            "Epoch: 36\tValidation accuracy: 0.31828193832599116\n",
            "Epoch: 37\tValidation accuracy: 0.24559471365638766\n",
            "Epoch: 38\tValidation accuracy: 0.29405286343612336\n",
            "Epoch: 39\tValidation accuracy: 0.2918502202643172\n",
            "Epoch: 40\tValidation accuracy: 0.30837004405286345\n",
            "Epoch: 41\tValidation accuracy: 0.263215859030837\n",
            "Epoch: 42\tValidation accuracy: 0.28634361233480177\n",
            "Epoch: 43\tValidation accuracy: 0.28854625550660795\n",
            "Epoch: 44\tValidation accuracy: 0.2852422907488987\n",
            "Epoch: 45\tValidation accuracy: 0.30506607929515417\n",
            "Epoch: 46\tValidation accuracy: 0.30176211453744495\n",
            "Epoch: 47\tValidation accuracy: 0.2973568281938326\n",
            "Epoch: 48\tValidation accuracy: 0.30837004405286345\n",
            "Epoch: 49\tValidation accuracy: 0.30506607929515417\n",
            "Epoch: 50\tValidation accuracy: 0.29405286343612336\n",
            "Accuracy of rotated training & rotated test: 0.31828193832599116\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Release GPU"
      ],
      "metadata": {
        "id": "bqtIFIMZcPXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "CO1kq9-7b9rT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}