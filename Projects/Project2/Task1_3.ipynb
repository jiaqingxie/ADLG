{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjJDkSXXjy8W"
      },
      "source": [
        "# Task 1: Knowledge Graphs\n",
        "## 1.3 FB15k-237"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5RdZusrmQp0"
      },
      "source": [
        "#### 1.3.0 Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x31Xk8lVmRjc",
        "outputId": "3e10b547-636d-4f43-a580-20377957569d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting info-nce-pytorch\n",
            "  Downloading info_nce_pytorch-0.1.4-py3-none-any.whl (4.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from info-nce-pytorch) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->info-nce-pytorch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->info-nce-pytorch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->info-nce-pytorch) (1.3.0)\n",
            "Installing collected packages: info-nce-pytorch\n",
            "Successfully installed info-nce-pytorch-0.1.4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "!pip install info-nce-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKIykEhLmYq9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GAE\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.init as init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GL-z3tjln5g"
      },
      "source": [
        "#### 1.3.1 Data exploration and baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-IJPvcBOYfd"
      },
      "source": [
        "*a. Data exploration*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxURA97quDRY"
      },
      "source": [
        "Explore the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G97mE9Wyjx4W",
        "outputId": "e0d607f9-0c83-416c-d140-0bc1a5c8d366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/train.txt\n",
            "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/valid.txt\n",
            "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/FB15k-237/test.txt\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: FB15k_237()\n",
            "Data: Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541)\n",
            "\n",
            "Number of nodes: 14541\n",
            "Number of edges: 272115\n",
            "Average node degree: 18.71\n",
            "Contains isolated nodes: True\n",
            "Contains self-loops: True\n",
            "Is undirected: False\n",
            "\n",
            "Training data: Data(edge_index=[2, 272115], edge_type=[272115], num_nodes=14541)\n",
            "Validation data: Data(edge_index=[2, 17535], edge_type=[17535], num_nodes=14541)\n",
            "Test data: Data(edge_index=[2, 20466], edge_type=[20466], num_nodes=14541)\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import FB15k_237\n",
        "\n",
        "dataset = FB15k_237(\"data/FB15k\")\n",
        "data = dataset[0]\n",
        "print(f'Dataset: {dataset}')\n",
        "print(f'Data: {data}\\n')\n",
        "\n",
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "# print(f'Number of features: {dataset.num_features}')\n",
        "# print(f'Number of relations: {dataset.num_relations}')\n",
        "print(f'Average node degree: {(data.num_edges) / data.num_nodes:.2f}')\n",
        "print(f'Contains isolated nodes: {data.has_isolated_nodes()}')\n",
        "print(f'Contains self-loops: {data.has_self_loops()}')\n",
        "print(f'Is undirected: {data.is_undirected()}\\n')\n",
        "\n",
        "train_data = FB15k_237(\"data/FB15k\", split='train')[0]\n",
        "val_data = FB15k_237(\"data/FB15k\", split='val')[0]\n",
        "test_data = FB15k_237(\"data/FB15k\", split='test')[0]\n",
        "print(f'Training data: {train_data}')\n",
        "print(f'Validation data: {val_data}')\n",
        "print(f'Test data: {test_data}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsjGcOJ7uGys"
      },
      "outputs": [],
      "source": [
        "dataset.num_relations = torch.amax(data.edge_type) + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import random\n",
        "random.seed(42)\n",
        "# Choose nodes for visualization\n",
        "nodes = random.sample(range(14541), 10)\n",
        "edgelist = []\n",
        "typelist = []\n",
        "\n",
        "# Ues NetworkX\n",
        "G = nx.Graph()\n",
        "for node in nodes:\n",
        "    neighbors = data.edge_index[0, (data.edge_index[1] == node)].numpy()\n",
        "    G.add_node(node)\n",
        "    for neighbor in neighbors:\n",
        "        G.add_node(neighbor)\n",
        "        G.add_edge(neighbor, node)\n",
        "        edgelist.append((neighbor, node))\n",
        "        type = data.edge_type[torch.logical_and(data.edge_index[0] == neighbor, data.edge_index[1] == node)].numpy()\n",
        "        typelist.append(type[0])\n",
        "\n",
        "# Scale edge type values\n",
        "scale_min, scale_max = 0.2, 1.0\n",
        "colorlist = (scale_max - scale_min) / (np.max(typelist) - np.min(typelist)) * (typelist - np.min(typelist)) + scale_min\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "pos = nx.spring_layout(G)\n",
        "nx.draw_networkx_nodes(G, pos, ax=ax, nodelist=list(G), node_size=10)\n",
        "nx.draw_networkx_edges(G, pos, edgelist=edgelist, edge_color=colorlist, edge_cmap=plt.cm.YlOrRd,\n",
        "                        width=1.5, ax=ax, edge_vmin=0, edge_vmax=1)\n",
        "plt.savefig('10-node-subgraph-1.3.png', dpi=300, bbox_inches='tight')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "WTdUlBEjMkVB",
        "outputId": "3611a3ed-21da-4074-9a7e-1b9937c1a056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFICAYAAAA24bcOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0Y0lEQVR4nO3deXyV5YH3/899spGdQBJCIJETZd9yoqhFAaFKoNZa6GOXp61dnBro1HZa25KZ36/tM9OZaZyxfVq7SLQdu9hl6gjWtWqLFhUXNCcIiMhyIIEQICFk38/1/HEnIYeccBLIcp/k+369eIVzb7lo4zfXdV+bZYwxiIhIv1yjXQAREadTUIqIhKCgFBEJQUEpIhKCglJEJAQFpYhICApKEZEQFJQiIiFEDuQiv99PRUUFiYmJWJY13GUSERl2xhjq6+vJzMzE5bpwnXFAQVlRUUFWVtaQFE5ExEnKy8uZPn36Ba8ZUFAmJib2PDApKenSSyYiMsrq6urIysrqybcLGVBQdje3k5KSFJQiMqYM5HWiOnNEREJQUIqIhKCgFBEJQUEpIhKCglJEJAQFpYhICApKEZEQFJQiIiEoKEVEQlBQioiEoKAUEQlBQSkiEoKCUkQkBAWliEgICkoRkRAUlCIiISgoRURCUFCKiISgoBQRCUFBKSISgoJSRCSEAe3CKMPHW1aDr6oRd2o8nuyUfo+JyOhRUI6iomf2sXn74Z7PG5bnAPQ5Vrh2rsJTZBQpKEeJt6wmIBCBPp+7j52sa2FraUXPse7wFJGRoXeUo8RX1Tjga3uHJNjh6S2rGeoiiUg/VKMcQb2bz+7U+Et6lq+qUU1wkRGioBwhwd5HblieE3hs2QywXAHH1nsy2eINrFECtHf62VJyTO8sRUaAgnIE9Pc+cuvGpayeP4UXH70fOlu4YWoaeZ6rWV37B3wnz+C+dj1513hIq9tN8aHJPffmTk9m05bdPZ/1zlJkeCkoR0B/7yN9VY28d7KezadyAbjvj6fZULmPbyacIbflXaypMZjOdvJ5hZjJ6XD5TUybPiMgJMEO3fz5GapZigwTBeUI6O99ZNvZE2zefirg2Obth1k9P45cgIgoih7dTvGhD9knq+tZWVsZ9Fl6ZykyfNTrPcy6O3DW5WYGHN8Q9ypRex8Peo+vOda+95Sh2NsScO6F/aeD3nOpnUMi0j/VKIfR+R0463IzWTYzjRmJhtwXH6T0bAxwbZ/73NFnwYCvpiPoc1fGHeaFppyezxtX5Kg2KTKMFJTDJFgHztbSCm5/3ww82SmY6H8i97GvUxD3GsVN58JyQ9YxcmNPQRO4Ow4DfQPwrrQ3uevaazjiz1Svt8gIUFAOk/46cF548VV8CxbhTp3J4tyPsKn0UfInVuKLmI678R1yo2rBnwBA7pnnKYjLDgzSlJ14Vt6GNftq8rADWcOERIaXgnKY9PfO8L59BvbtAqDg+vezadJb5J7ZT+5kP7SfgBYLYqPAGKg6yqYkH/kL0vEdP4I74hS5nquxZn8QgO89/Q7FL/l6nq1hQiLDQ505w8STndKzyEV/il8+Sunir4MrEk4fsA/6DXS2dX31A5Db9irrEt4mNycD6+qNGH8HJTueDQhJ0NRGkeGiGuUwKlw7l/z5GfiqGjla3ciPth3sc83h3xezeMUHsPY/DliAAeOHNjskmRALzachMROuL4QDf8bs/m98xycCa/o8T8OERIaegnKYebJT8GSn4C2rCRqU7qZj8NTrmCmTIL4Jy+UCvx/aO+0LXO0QmQCXLYOn/h7TVG3fl5AQ9PtpmJDI0FPTe5h1d7YAfZriBVc0kBt50v5w8gwcbcW0WJTWpbO1aT6l7VMh0gWWC/b8NzRVQ1wq1tVfxPOZ/9vneRomJDI8LGOMCXVRXV0dycnJ1NbWkpSUNBLlGhPOH0dZkBtD/uUT8NUa3JNi8GTG4u9og6d/CAfeA2O4x3o/D0Rcf+6elJ1sSn8FEjKwFn0CLr+R0uONPasQAVrQV+QiDCbX1PQeJsHGURaXtpJ/5lesi62EcjC77LeSRAHzkihtzuCBsusD76lZwpx9DeQtXkB8QgKbS0r5+a5zs3PU0y0y/BSUw6TfhTCi55CbEgemE/yd4O+w/97WjK82eI1wz84KEn/5BIenZvPzz/xDwDktiCEy/BSUw6S/TpWcm76Iq1eomdMHMdt/DFVe3G3RQe/JveV60mZPpqQh+P9d6ukWGV4KymHSPY6yd/N74wq782VLyTFmJHSSW/5H2PMkYCAimtzrbqTg5GSK36gOuOeWNTcD4C+r4Wf37+jzvdTTLTK8FJTDqPc4SndqPM/urWRdr6AriKtjU5KBWauwrtuAlZRBYV0F+a0P4WtLwZ33EfIWnHv/2F/4qjYpMrzU6z1CvGU1ASHZbcttU8jLu6rns6k9htl+F9aEKFjwZayp1/e5R1vXilw69Xo7UH+dO0fIIK/3AeOntDYVX81k3BPryJva957uQewiMjIUlCOkv/eI5x8veqGC4r0ftj/sM2yo2qfhPyKjTDNzRkiwRTLOf7/oLasJ6MgBLXQh4gSqUY6g8zt3zm8+X2gTMjW1RUaPgnKEXej94kCb5yIystT0dpCBNM9FZOSpRukwhWvnstpt8L3xa9zJhryuweYiMnoUlA7kmZGBp/wwWBEYY7Asa7SLJDKuqentRFFdi/KaTuhoGt2yiIiC0omsiGiImGB/aK8f3cKIiILSsaK7plS11Y1uOUREQelYUYn2V9UoRUadgtKpolSjFHEKBaVTRatGKeIUCkqn6q5RtqtGKTLaFJRO1V2jVNNbZNQpKJ2quzOnTU1vkdGmoHSq7uFBekcpMuoUlE4VpaAUcQoFpVPpHaWIYygonar7HWVHI8bfMbplERnnFJROFZUAdK0a1N4wqkURGe8UlA5lWa5zqwjpPaXIqFJQOpkWxhBxBAWlk2lhDBFHUFA6mWqUIo6goHSynhqlglJkNCkonUzTGEUcQZuLOZmmMUoI3rIafFWNuFPjta3xMFJQOpmmMUqXYIFY9Mw+Nm8/3HPNhuU5FK6dO1pFHNMUlE6maYxC8EDMn58RcAxg8/bD5M/PwJOdoprmEFNQOllUIt7aVHzVieRk1ugHfhzyltUEDcSYyODdC76qRp7dW6ma5hBTZ46DFW2vZf1bN3P3Lg/r7t9B0TP7RrtIMsJ8VY2Dur690x80WL1lNUNZrHFHQelQ3rIaindUBhzTD/z4406ND3r8htnpFMwNXANg44ocIlurg14/2MCVQApKh+rvB1s/8OOLJzuFDctzAo5t8HTgyU6hcMEptsz9H75/XRNbNy7lm/lzcJ9+Iuhz+gtcGRi9o3So/n6w9QM/fnR3yOTPzyB/fgaHy/fjbn4cT3oHxv8B6GjGk3AKz+xIrOwUzNFteNpfpWBKBMUnc3ues3FFjt5vXyIFpUN11yR6v2/SD/z4Eayne9OaJbD3CWhvhNq3oaPZPhkZi2lrhF0/B6Aw/wrWxC9Vr/cQUlA6WOHauaw+ci++pgm45+SSt+bm0S6SjID+errz52eQO+laOPlnqN4REJTsfRhaaiBxGsxahyciWgE5hPSO0uFyE+tYl7iP3JgTo10UGSH9vYc+vG8XTF4KWFD/Lvi7grK1Dg4+bv/dsxErIhpvWQ1bSo6p82+IqEbpdFFxQDW01I52SWSE9Pt++u3NkJwPqbPtoIxsA2Pg0DNg/DD9OqyMKzVjZxioRul00V2rnLdqGuN4EbSne0Y1uVEVmNcewhw+Yh+cABig1gcRMbDoC5Qc2K1xlMNANUqnm9A9jVHDgsaTwrVzyZ+fEdAhY/amYbZ9H/a9iUmZR2ltCr76RNyRZ/AsWQinf4XvYCQwu8/zfFWNemd5CRSUTjeh64e7vXl0yyEjzpOdEhBu1vy1kJaDeeJb3PPaZRRXLOw5VxBRTuGSStwTJwd9loaVXRo1vZ0ufpL9taNldMshzpCcSumcjwSEJEDx7iy8HbfiuebLfZrtGlZ26VSjdLq4VPur9vYeV3qv/pOblQxn98LJF6DmbXzHpwNL+tzjO1CKZ1pK0Ga7XBoFpdPFp9lf/Z2jWw4ZMef3WhfMLqNw9ps9n91TUoPe5448CHt3YpLnk5u9Hk/2jOEu6rihprfTJU3t+ovB39E2qkWR4RdssHnx/my8tVNh6k2Q+2/krfgSBQsDf3FuuC4Tz5zFYEVA7V7Y/V3M/p9imo6PZPHHLNUonS5xKnT4obkTvpePPyYea/lnYO4KrOT00S6dDLF+F0NJ/TvyZszo+Vw47zj5HW/gm7ianNw1Xc1rDyZzDZT/CapegzMlcMaLSb0Gsm7FmqCfl4uloHQw01ANj/8HnOjuyGmHtmbMU9+Hp76PWbQa64Nfx4pNGtVyytDpr3c6Jz058EBjpb0gxsIUrN494xPSYObfYaathfLH7LCseg2qd2LSr4dpt2DFjM47y3BedV1B6VDm5GHMQ38PjV0DhWNcEJ8BiWn2bIzy3fD2c5iju+CO+7FSMke3wDIkBrwYSlPXWqXxGUGfY8VNg9l/j2k4AuVb4eweOPk3OPUKJmMVTPsAVvcunyMg3GcLWcYYE+qiuro6kpOTqa2tJSlJtZfhZhqqMcV3wNlKSL8cIk9DRAfk3Y7rqs/a15TvwfzP/4EzxyBtBtYXHsSKHbkffBleF6p9GePH+9sCfE0JuG/4EnmzLg/5PFP3HpRtgfoD9gFXjP3OMzMfKzJuWMsPsO7+HX2u2bpx6ajWLAeTa6pROpB55j47JCdnYd3xM8wjt9tTGJvOrV5tZS2AO35mB+rpI5htD2DdfPcollqG0vmDzXsrerKU4r0ftj/43mXD8raQtTMraRZm/ia7Zlm+FRqPwvEnoXIbZtpavO1XceRM25A0i8+vPa6anRb0uu73seHQHFdQOow5eQh2PweAddt3seKSMVGxdlA2B87XtZLSYf23Mb+8C3Y+hrnuk1gTgzfFZGywtwgJXEmq9+6LF2JZFqQsxExcYL+7LN8KzSco+vO7FB8817C8lGZxsF77bftPB712+4GTfO2Rc9udOLk5ruFBDmO2PWi/g5y3EmvaHPtgVNcL/pa+29Zaly8B95XQ2Y558b9GsKQyGoZiixDLsrAmXwmL/wVv/GcoPhg4N3zz9sOUlJ0Z0vKtdB0I+LxucTqPlYbPnlAKSgcxrU2wbzsA1qq/O3cipmsFobaGIHeBteoL9l92P4/p1AyesWwotwixLBdHOnKCnvOVPIyp2cUAujAGVI67Yl5my+JD/OC2xWy5M4/rJ70Z9Dqn7gmloHSS4+/Y6womT8Ga0usF/YSuoSH9rSCUvRBi4qCtGU4dDn6NjAnBlmC7lLnc/QZvdBm8ex/sLcLUHQh6TX/lK1ga+E5yQ/Sr5EZU4Fm5lnW5qXisX+NOCr5soFMX79A7Sicp221/zVoQeDy26z+CfhbGsFwRmOnz4dBOe9jQ1FnDWEgZbUM5lzvYcKQN12fhmX8tnPgL1B+0w3LiIshejxWfFbp8qyaSn/YivtoJuNsmkvv2Npi+CNKyofxH4G/Ckw4F10yg+PVzP9NOXrxDQekgpnwPAFZW4MowxHUtnXWhKYxZC+HQTkzZHqyrPzJMJRSnuFCv+GAFD95FmIz3w/En4ORLcPZtOLu7a5bPh+2B7f3xN+FJbyQ3vQme+AsA1lUfhvIfQ2dXq2jSatbkzWNC/CnA3qfcqSEJCkpnOf6O/fX8GmVC98IY7f3eamUtwPR+hsggBAteKyYFcm7HTF1tz/Kp3nluls+UFTDtg1jRyX0f1tlVS2zvhIYqiE+BhL3Q2dXcTnk/97w6ic3bz42tbO3w48lOcezsHQWlk7R1Lc6bMCnwePwU+6vx939vQlets61p6Msl45oVmwGzNmAa1tiD1mv3QuU2e5bP1NWQuTpw0Hr3pmfNXYG59hro7BqxkbwMr88Kul1FZU09j+0+N5TIScOF1JkTDnpWEAJ/Pz3fIsPNSpiBNe9rMO/rkOAGf6vdNPf+I6biWUx3i8ffFZDNLXDzUqyoTnvIW9skePMP+N7cEvT5vUMSnDVcSEEZDhJ6vQ+qrRi9cogAVvJcWPD/wawvQuxU6GiAo38E7z9hTr0MnU14T8Wz9czllLakgzGY8nJ45zloPIE7pu944P44ZbiQmt5hwOWKxI8FGGg4CWnq1ZbRZVkWTL4SMykXTu+wl3ZrOwOHHqJoXy7FB+b3XFswYx+FaacwrZ1wpoXc2n0URO2guH1pzzXrLo9i66G+7+CdMlxIQekkrq4KfntrkHMR9nYQDaeC39vRdY8VMTxlk3Hrwh0sLpgwG+LWYhq3U1rbSPGBwHGexUfmkl+3k9z4Tpj+PqxrF1I4bQH5rZM4Ut3S89wp580Rd9JwIQWlk6TnQPkeqHgX0t2B5yKi7KBsDD5vluP77K9Tgs+0ELkYfbalWDqdwvmtUPEO5sQ+qNhn92x38XUuCvocX8I0PPPiYNoSyLwGK24yeUDeZeeucfJePwpKJ8laAOV7MOV7sHLXBp6LiLG3rG0KPgf33BjMBUHPiwxW0G0pdhwj3/sQuRG93pVbEfYv+ZQs3PsOBX2WO7oaKt6BCnvqYknkVfhiFuG+fB6eefOxLMuxQ4NAQekI3T8gM2Lnkwv27JrzRcdBy1loqQ3+kO57zh+sLnKR+l2AY8Ll5M6ch5U5DzLnQcYs6GjDPHQHudZxCpK8FNd5eq7fsPgEnsXZcCYOzlRRdGAhxaevtE++epSCqc9AYibF7008d4+DhgaBgnLU9WnaWKvYdPJvmOb6wIV4o7sWxmjtO0fW1J6016+0XDB93nAXWcaJfrel+Hghrl41PuPvwDyyCWqOQ3IGm66pJr96O76yNtwZLjwLEgAXZM3Gm7CK4h2BCwUXn5gHgSvHDXjpuJGi4UGjKGjTxlxHaecUePW/Ay+O7n8FIfPyb+2/ZC/EinFGL6GEv4EuwGH++lPw7YSoWPjId7Ei2/BMaWD9nBg8He9CY9fU244afFXNA/7+ThkaBKpRjqp+mzZmMrk7fgfX3oYV1zVFLHai/fW8mTfmbCXs3AqAtfKO4SqqjFOhOljMrifhDfuXuvWhb8HESVAJRMRCzs1QtRvKj8O8heBvwB1fCUwe0Pd2ytAgUI1yVPW7xFViE7Q2YbYW4u/sGvYT1zWtsdcKQsbfiXnyP6GzHdx5kLNkuIss45AnO4X1edMDQtJbVsOjf30N7xMP2weWfR5rzg3Q3tXZGDUJpl4L0UnQUg2R14ErDk96IwWLAidNbFyRM6RLxw0H1ShHUdAlrq6OJjc1DZ4/BO964Q+347/pCxA7kdKWDHyNaeSU1ZA7NQ7z5L2w/xWIjMZa82V7ELDIMAt8r/5pCqYco3DZ5+2PbV1BGZ2CFRGFuexGOLAFyp6Da74F5f9B4TXHyHfX4Gu+nI6EJURFuHCnxjt2aBAoKEddsKaN8a/E+H8Ef3kE3j0KJ7/HPdZqik990r7p/h0UxO9hU+sTAFjrv42VOWcU/xUyXgR9r35yOmvKa+1wa+uamx3d1QKascYOysq3oLUasr4BZUV40ht59vUzFL99boSH03q6e1PT2wHOb9pYrkhcK+6Gj/4LTIij9EwyxacCx0cWNy6gdMJcrE99H2vhjaNRbBmHQu7Z01OjtIPSSpwGqQsBP96d29i6qxKvdSfeU0kUvx24F72TFsE4n2qUDuZauBoz40p8Tz4Pb/c973v/P5E3e+bIF0zGrVB79niPN+E7lYk7OoG8Kd0n11Dkjad4ZyKwC4CVs5YCfSdP+KoaHdfsBtUoHc9KnEzOdflBz+Vkpo5waWS8u9CQoaJn9rH+ycu4+41c1j98hqJn7Gm13s75FFfmBdzzwnvBZ5g5qae7N9Uow0CwTh+n9QrK+BHsvXqwd5fdg8aPnAmyyAuwanZawJ7fTv6ZVlCGicK1c1md+ga+k6dwT/STd/3No10kGcfO3zriQu8u+93CdtVM7lo107E93b0pKMOIZ0YmngS7l9B01GNFJoa4Q2RkXOjdZagWkZMDspuCMpxMOLclBE1HIEkLYIgzhApDJy+hNhAKynAS1WvqV/OREQtKJy9/Jc4RKgyHcovdkaagDCfdg3gBmoKv+zfUzl/dyMmDgmX0hXMYXoiCMoxYrhhMRAJ0NkBLBcbfjuWKGrLnn19zvFBPJqBapowbCspwE5VqByV+aDkGce6QtwxEsJrjrCnBO4t+vO1AwLAO1TJlrNOA83AT02uQeZNvSB7ZX82xvdMf9PreIdl9rVOnnokMBQVluInuFZTNR4bkkf2NgYuKcPWZhbFqdlrQa31VjXjLathSckyhKWOOmt7h5ryeb2PMJS+vdqExcOvzpnPwP39GWXQS6z9/M9dcO7NPjRLgpQOn+doju3o+qzkuY4lqlOEmuldQdjZBWz/b1w7SyvNqinfEV/fM3/3LNWt4z7OUIm8Nz+6tpODqwN+v6z2ZbC0NXIxVzXEZS1SjDDfR5y2E0XwEYtIv+nHnd+KsSDF89k/3sii6lZJP3Rz03eWWjxwjf2otPv/15Eyfy+GqBrZ4K85/tGNXghEZLAVlmLEi4jCuWPB3bdLUdAQmXj2oZ3QPA2rv9PcJwr/VWHwuIQl/+W4O7CgJer+vupX1s9rwXHalPWSp7s2g1zl1JRiRwVJQhqPoyfbQIBh0h875NchgKq7LZ/4fdpP5xl8hdlmf8+7kFoibY4dkw248cS9TsGh6wEKsTl4JRmSwFJThKDr1XFC2ncJ0NGJFhq69BRsGFMzMFR74A8zZ9igF3/kQxW+ee9e4IbcKT3ojJC7CtBzDu/c5fGcnk78wizXXXROwWsyWkmMakC5jgoIyHHX3fLsmgL/FrlUmzg9520D2Sd6wuIKrLi/n7OJcOnaV8pWmUvJvbeDwmRjiW2awJvcwuOIgKo2iLY9TXNq9V08nG5ZXUrh2rqY9ypijoAxH3R06ruiuoDw6oKDs751h0U3tRCUtxD05Bo+1B9qamLB6Ng27Sml97DE8//k+POmNlL3TYd8QPwfvrq0Ul04JeM7m7YeZkdLJ5u1H+xzPn5+hmqWELQ0PCkfdQ4RMV3ANcIZOsGX8111RRVR7Ge7OJ/BMOg7p6wGL6CUuiJ1Ax4Fzi29YrV0B2H4GX3VD0O+xa/8bQY8PpDYr4lSqUYaj7qZ3Z5P9taUcYzqwrND/d/ZeCuulA6fZWgpbD9o11IJFb1O4rBMS83DxFjHLsml97j2M32C5LKATrBhoOYI7OXjtdHFaE79/t+9x9YBLOFONMhxFJoHVtWqQK9auWbYcH/DtnuwU3KnxfQaJF7+dibesFurfgogkJqy+HADT1glAXEo0GHv/E096IwWLTwbcv+GqTj5248f73XxKJFypRhmGLMvCRE+G1kqIToOWMns8ZexlA35Gv3ucbCsj97IKmJZGpDuViOxkSitiOdKZhDspjsk09VxbePVR8t1n8bXOxp21iDx3ln18bSru1Hh2HTvL4ukT+diS7Ev694qMNgVluIpKtYMyMsH+3HwEWDHg2/ud3+0/CWVdfyyL+6/5EA/+1dNzvmBRBYXXHAOiIGE+ninz8UTEgOnENPsAQ9FfTlK8w96O9HdvlOOralSvt4Q1BWW46u7QsSLxnk7C56vD7a8hbxBN3JWz03ih97qSy2aQO/fL8N6LcOgtSquieLDtmoB7it/OJN9dY4+lbCi1//TiPRVP8Y7AHnj1eku4U1CGq+jJeE8n8eMX43mh7Er72Es7BjRm8fxxjivdndyVdxrPpLfAdMJMYGYuvrcT4fW+9/tq4/BMtcCKBFxgWYD9x9eQEPR7at63hDMFZZgqeslQ/OqVfY6Hqr0Fm53zgi+CuxZVY/dqR9udRR21uDOCL9ybHVkLnW0QnQWTlkPszJ6l3nJMDfx1R5971Ost4Uy93mHIW1ZD8atn+z0frKPG1J7CvPEohx/9afB7zErI/ALEXgHtVWDa8aQ3UZBaGnDdrW88T+L3/ozp9ENbOVT+Fu9b/8Wjr75GSdmZoGM11est4U41yjAUavB279qbqTyIefJeOFpqnzOZgKfvPSkGKh/uWpXIAlccpvUsmyJfJH/S2/hmLSFj916id+6gtq2T8h/sIfsbiyh6fTrFb2cA1cCrFFwbR+GHlqnXW8YUBWUYulAzdsOSiJ7am/E+hflTEXS22+8Rk6aQW1tBQYyX4tZzYbkhuwxP9BvgB6IzIDIFmvbBqQYwfnIn1eJZWI9pa+LMrRM59Eg1lQ/t5tDMqyg+nRnw/Ytfa+Jk9R957EAyoF5vGRsUlGGou3nb+13jqhmdfGluKZ5pMRiTDwdfwzz27+DvhNnXYd2yCSvZXuB3TVkNMbuPwLsvcEPNy+RWVGCO5GF5Pg4RiVD1GGDBma4fj4yu1c8TJzNpTjnNn8+n4r+epeR378BNuX3K1x2S3dTrLeFOQRmmuqciHj78Km7Xm3imx0NbM7TVYWregUe+Y4ek5wNY677V09kS2OM9m9bUNnLPPgYv78XkTsGqfgQAk7AUyu+ltH0qvraFuE+BZ+pEDKVkvs+iuXo1Ga/vH3B51est4UydOWHMk53C+utX4ElvhtYT52bmbH8QmusgzY31oX/sCclgPd7FVQspTb0O2lvhuX8H0w6xOVA3gXtqrmH9mdu5+435rP/TfIresztprDIvOf/3GyxOi+VDO/8S8Lz1nsCmeDf1eks4U1CGOSsyHlLeZ3/oqMe0tMOunfa599+JFRnVc21/nUAvZnyQrf6FlO5twDRHQNpHKPW+RXHTtQHXFZdEUpp6A2CIOPISsx7ZzGfefZl//f0P+OaZ3RStX8j1V6SxLjcwLNXrLeFOTe+xYNIKqHkF2k5CWS10dMKUbJh3Q8Bl/dXq7ittAj4MfijYXk3hnAn4jpYBs/pc65uylNyqFzG7/0z0+z7NzN//lM61t/PwoZM8vmV3z3XrcjNZNjNNK5zLmKAa5RhgRSVDctcGY1V19testD77fQcb43i+4rLJeEt24jZ9d1UEcC+8EiKjoeoIVO4nadnVNNzzLzy+5MaA67aWVigkZcxQUI4Vk1cCLjhVbX9OasO01/a5rHDtXLZuXMoPblvMV1ZdEfRRvv17yI06QUF2VcDxDVe2kHf5VJhlbzjmffkFtpQcY9esxcGfo8V6ZYxQ03uMsKIn4Y+YBU3b7WnXkxOgrqQrQAN5slPwZKfgLavhR9sO9jl/tOw4pVFTKbx1NmsiZnP4+H7c1nY82fbwImvhWoq8fopLsqFkV79lUgeOjBWqUY4lzV3jHZPjsaIi4OxOjDH9Xt5fU/y++iWsP3M7Re8k2D3riyYCsGVfJN6yGrxRsyhuX3rBoqgDR8YS1SjHEKvdYADiYwAL2k5BSznE9j+FsHs85ov7T/WpXRa/fJQ1C6fx510155ZO+8sOVs5OC/qsr6y6gssmx+vdpIw5CsqxyALoqknWvnnBoAS7Ztnv0KH9p3oW4e3Wew3L3m6Yna6AlDFJTe+xKCLp3N9rvRh/R8hbBvs+cdV5tUo1tWUsU41yLIpJPfd3fzM07IWk4D3T3TzZKRRMqaT4ZEbPsY0rcrhhdnrQDp+7Vs3krlUz8VU1qqktY56CckzpHjcZDfGzoPE9+2PtmyGDEmBT5lHyq57Ct/Dj5Lzvpp7wO38Bjt61RwWkjAcKyrFk8nT7a+VBSP37c0HZ8C6mow4rMqn/ewEqD5BrVeBZlIHVKwB77wWu2qOMR2EZlN6yGv1HG8y0eeCKgLpT0J4IsW7o2hmR2hKYfEO/t5rmejjtsz9kLehzvnvspch4FHZBef7GWAPZTKu3sRyyVnQsZsrlcOI9KN8NM26E8gftk2ffwExa0WdaY49je+2vk6ZjJUwamQKLhImwCspgy4QNZlHYSw3ZsJC1EE68hynbjTV/FcRkQmtF15jK4xA7PehtpqxrQYsgtUmR8S6shgf1N9ZvIHOKS46eDhqy3rKaISmbU1jurp0ZS5+G1iZIW33u5NnXgt5j2luh5PGu+/OGu4giYSesgrK/sX6hxgCa1hP4Dj4V9NyYW7hh7nJIvcxeuHfH7yFhnr0HDkDtWxgTZEzlzq1QdxqS0mFR/siWVyQMhFVQBpubvGG5u99mtzF+zNlXoOLnuBOqgl4z1hZusCIisVZ9AQCz43dw5jikrbFPmnao2x1wvak9hfnbL+17V34eKypmJIsrEhbC6h0l2ENVVs9Pw7d/C+6kOjwLZgS9znTUwunHoOUIAJ4ZWRQsy6L4pfKea8bsbJL5q+x3leW7Mb+5Gz57H5YrFvzNeN95hSMx9oK6uZP8mIfvhqazMOVy8HxwtEsu4kiWudDyMl3q6upITk6mtraWpKQQY/FGiKl5Ac5uh5hsrMzPBZ5r2APVT4G/BawomLwGEjxYljWme717M/VVmOI7oPYkTEiEJddzz/FJFL93rkZeEP0Wm/xPQ3wKVsEvsFKC73cjMhYNJtfCNyg76qH8h4AfMu/EipmK8bdC9dPQ8LZ9Ucw0SFuHFTV5NIs6asyZY5g/fhuOv0OpyWR95x19rtmS9iyeT30VK909CiUUGT2DybWwa3p3syITMfHz8foO4yt7A/e02XhinoWOs4AFE5fBxOVYVsRoF3XUWJOmwxcegDcfw/eiF872vca3/Gvkpc8Y6aKJhBXHBeVAm8bGGIpen0rxju7Oh0MULI6ncKmB9I9gTci66GePJVZEJOayK5lx+n8gqu9iu+4kx/0IiDiOo/4rOX9AeMHSyRSujIfOeuioD/jqreikeEfgLoHFu6aS796Px3oUE5EIEQldfxIp2u6n+LVzQ4HG5GDzIEz9Gfw/+wq5zce50/8SD8Qs6zlX0Lqdxb//OWbjfVjpfX+xiIjNMUEZbNZN8Y5q8tNfxpPed6yj72zwaXa+s1F40s9Ax7mNtbyn4il+LTAUBzOjJ1yZthb8xV+D6uMQE8um1ufxvPM2+5PyWL7poyzeugdOVeK/9zO47vw+1hWe0S6yiCM5Jij7nXXTOB1PfDRE2jVDIhKh7QTuiXuDXu+e+WGYCnQ2dNVAG/CVNfT7PcdqUBq/H/+vvw2+3RCbCP5OADJ2H2ZKZjR5V/4r5opf4d/8VSh7B/+PN2J98tu4rv7AKJdcxHkcM+C8v4HfOVfkY6Wvx5q0GpKWQOtRqN+JJ6OJgrzmgGs3rsghLycLa0IWVvxcrKSrsSatIse9LOizx9pg897M4z8B718hIhJrzeehtQn/hCTqT/rpqLd/KVnJqbi++gDkroKOdsyvvoX/qeILbkgmMh45JiiDzbrZuML+vKXkGCW+Y1D5G2jYhd2rfQOFSyey5drn+P61x9i6cSmb1gR/59jfs8dqbdL/yhbM878CwPrUd6DquH3cfRUAnfXnau9WdCyuO+7BuvF2AMzTD2B+9W1Me9sIl1rEuRzT9Ia+C8Q+u7eSdffv6DlfkAuFS2Mh9Vas2BzMiWI8E6vxXJYasNDsQJ49VkPS7HsV84ciAKwPFGBdtQb/Y/fZ5+ZeB/yJzrrAVxGWy4W17iv407MwfyjC7Hwac+YErjvvxUqYOML/AhHncUyNspsnO4X1efZSYH06d0rT8bb/L6zYrtphXddeLolXDOrZYzEkvWU1PLrtLUp+8UPwd2JdfTPWB74AR/dC7WmYEE/E/GsB8De3YDr6Lo7hum49ri/eBxPi4ZAX/72fxZw8OsL/EhHncVxQduuvc+fIWXvhWdPeAM0n7INJOUGvHS+KntnHuvt3cPfzlXwk6nbuyfg01v/+/7EsC/P2iwBY868jIuXcSIHOhqagz7LmXovr7odg0lQ4XW6H5YG3RuKfIeJYjg3KkEuq1R2yv8ZmYEUljlCpnCfYsKoHmmZSesL+RWN2vWgfXLwSV0w0VnQUAB11wUcCAFiZl+P6xq9gxgJoqsP/4y/if/3JYSm/SDhwbFCG6oDxHjzEluMz8LbOH43iOcaFFjM2lT44ecTu+Z5nz8qJTEoAAjt0grGSJuP6SjGW50bo7MD8+jv4n7xfPeIyLjmqM+d8/XXA2DN4YoD3wW7Y0LBvXMyyCeZCNW/vS09yOGox7uxMroy1A/LwZZdTlg6uozVcH+J3jBU9AT7/PXgiC/PcQ5hnfg6nyuHT3xnRdStNfRXs+Stm9/NQvsc+uGQd1rwbIGcJlsuxv+9ljAi71YO8ZTUBPeHdtm5cOiY7aQbi/KmfG1fkYAx99geCvscG+gvGv+NPmN//mz1wPWexPZMncXj/9zbGwFuPY575IbQ1B78o5yqs9d/GSk4f1rLI2DOml1nbUnKMrz2yq8/xH9y2uKe3fDzqveAHEPSXSTCD+QVj9r+B/8FvQnM9pE7DtfFHWBnDtzyb//n7Ybs9HpTMOViL8yE6FmLiMYffgl3PQHsrJEzCuvPnWk9TBmUwuRZ2bZaL3TdnrOs99Gkw+wAN5lpr9tW4vv4QTJ4GVcfx3/s5zP43Lqa4IRnvUz0had240V5YeOknsK76MNbCm3DdWoi18deQngMNZzAPfx3TX61T5BKFXVCOt1k2F2MwvzQG+wvGynDbPeLuRdBcj/8nX8L/6uODLeIFmZZGzDM/sj/c8HmsFZ/BcvVdV9RKuwzr9h9CYiqcOgyv/veQlkOkW9gFJdidPFs3LuUHty2+4NTF8aq/XyZD9QvGSkzB9ZXNWFfmg78T8/A/4//TTzB+/yWVu8eO39u7SKZehrWy76rsAWVJTsfKvwsA8/JvMc31Q1MGkV7C7h2lDFywhYqHcvFi4/djntqM+fMvALDybqJ05Vc5crb9op9vWhow994KrY1YH/s3rAXvH1g5fvppOHUIVt6Bq2sXSpELGRdbQUhonuyUPmEV7NjFslwurFu+iD8tC/O7f6VoLzxw8M2e8xe1OPIRL7Q2wqTpMG/lgMvBsk9hHv1n2P8yKChliIVl01ucxXXtLez62A8DVk8HeyiSt6xmUM8y3eMkZ3gGNz7SnWd/rTyoTh0ZcgpKGRJHYoNvJXH4dP9TJYMq3w2AlbVgULdZyVMgKc0e53l83+C+p0gICkoZEv31ns/42wOY+oHVKk1nBxx7x/6QtXDwhei+p7tWKjJEFJQyJIL1tBe0v0Luoafxf+8TmAMloR9y5ji0t9iDytNmDLoM1vR5AJgT7w36XpELUWeODJnz5+bnRszC/4v9cPII/h8VYN1cgJX/uaBjIgHwd62RGTXh4uZvR8cFPkdkiKhGKUOq9wwha9pMXN/8DdY1N4PxY568H/9P78LUVY92MUUGRUEpw8qaEIfr9n/B+vT/gegJ8O7r+P/9E5h3h2fqo8hwUFDKiHBdewuub/4GMi+H+mr8P/ki/ic3Y7q20RVxMgWljBhrag6ub/wKa+mHwRjMMw/iv28j5uxp+4LuNS5bm+we8MFqqrW/Ro7cWpkyPigoZURZ0bG4PvktrM/+K8TEwYG38H/v45i9O2BiJkxIhI5WqDw46GebY/awIGvanKEutoxzCkoZFa4la3FtehimzYKGs/h/dhfmiZ/CtK4pj10DzwfKGAPle+0PFzMGU+QCFJQyaqwpl+H6xi+xlt8GgHnul5jjPvvvgwxKzpRD01mIiIKps/CW1bCl5Nigp1CKBKNxlDKqrKgYrI8VYmZeif+334VTJyApEg68hulox4qMGtiDDnb1omfO4Z7nD130lhciwahGKY5g5d2E6x9/B1NnY/wGmuswv/gHTEd7yHtNRxvmpYcBKJ12U5/tey9mcQ6R3hSU4hhW6nRcdz+ENd0DgCl7E//3P4epOn7hG9/8E9RWwoQkDu8JPn1xMFteiJxPQSmOYkVFY33hPohNxnJZUP0e/qJPYEq3Bb3e7yvB/Pk+AEx1De7jO4NeN973VJJLo6AUx7Eio7Fu+2ewXFgxLrBa8D/4Dfx//A9KDp9mS8kxSt4owb/5S5iffxE62zHtfohMwLNyFQVL0gKepz2V5FKpM0ccyZp5LdzyDczj92BNcGGiLYrequEB77mpj3eSRGEkGCsKa+2XsN53K1b0BP4RWHPV0G15IaKgFMeylqyDyVmYLd9l19kIHnBdH3D+Aa5jzeQacm/5KJZ7OZYrImBPoPG8z7sMLQWlOJqVcxX8wyP4nnsFXmrqc953RQ6etqcwux+naOcsig9l95zrHhY0lBuqyfikoBTHsyKjcc9dCC+93uecu60G09pBad2kgJAEe1hQ5REfj5Wd22hUYyrlYqgzR8JCzpGDfPDNvwYcK2jdzuK/Pos5Ngdf/ZKg9/UOSdCYSrk4qlFKWKh67Dk++sKTfPbmUxw5E4f77Ely45qgFXjmQdx5nwZmDuhZvqpGNcFlUFSjFMczfj9Vjz0PwOLEJtZlvEduRBXUn4Gl68CyWFzyG+5MOhpw33pPZtDnaUylDJaCUhyvfudu2o6fJCIxnoiUDKxIF3i6esDL38H63PcgMopNx37Bo8nb+P6HZrF141J+8FFPnw3PNKZSLoaa3uJ4VVufA2DSB26A+ASoAmu+B+N9Bcr3Y0XHYH3pp/iLv0Zu+Yvk/uUou9YVsaWkkfz5GQEbnikk5WKoRimOZoyh6jE7KFPXrYZYO+gsWrFWfBQA/9MPwhV5uL76c5iYzj01V7D+t/v52iO7WHf/Dp7dW9mz4ZnIxVBQiqM17XmPloNHsWKimbRmOcTZYWeaa7De/2l7w7Kyd2DvK1jTZrLrf/+EB2KWBTxDPd1yqRSU4mjbH/0br8y7ilMfuoWIhHisrholTTVYiSlYy+xFf0se/x8eLTnG3yqC77Wj1YPkUugdpThW0TP72Nw6DW7+JAAHntnHptkT7ZPNdg3RuvHTFO04zQP1S+GRXf0+Sz3dcikUlOJI3rKaoAvwrs5Ig5YMfBXJ5JTVAC4eiFp6wWepp1sulYJSHKm/pvKP32zmhRN2DZP7d7BqdlrQ676y6goumxyvnm4ZEgpKcaT+msovHG4I+Lxt/+mg190wO10BKUNGnTniSJ7slD6DxVfNCV57XDlbC/XK8FKNUhyrcO3cgMHiANve7VuD/PKqmXx51UwNKpdho6AUR/NkpwQE34blOQGdPL1rjwpIGS4KSgkr59cyFY4yEhSUEnbOr2WKDDd15oiIhKCgFBEJQUEpIhKCglJEJAQFpYhICApKEZEQFJQiIiEoKEVEQlBQioiEoKAUEQlBQSkiEoJj53p7y2q08IGIOIIjg7LomX0BS2ltWJ5D4dq5o1giERnPHNf07m9TKe3LLCKjxXFB2d+mUtqXWURGi+OCsr9NpbQvs4iMFscFZbBNpbRZlIiMJkd25mi5fxFxEkcGJWi5fxFxDsc1vUVEnEZBKSISgoJSRCQEBaWISAgKShGREBSUIiIhKChFREJQUIqIhKCgFBEJQUEpIhKCglJEJAQFpYhICApKEZEQFJQiIiEoKEVEQlBQioiEoKAUEQlBQSkiEoKCUkQkBAWliEgICkoRkRAcuwujiFN5y2q0lfI4o6AUGYSiZ/axefvhns8bludQuHbuKJZIRoKCUmSAvGU1ASEJsHn7YfLnZwColjmGKShFBshX1Rj0+H1P/40Xjkb1fFYtc+xRZ47IALlT44Me7x2SYNcyvWU1I1EkGSEKSpEB8mSnsGF5TsCxVVckBL22v9qnhCc1vUUGoXDtXPLnZ/S8jwTYdnBHn+v6q31KeFJQigySJzsloMNmw/KcgE6ejSty1KEzxigoRS7R+bVMheTYo6AUGQLn1zJlbFFnjohICApKEZEQFJQiIiEoKEVEQlBQioiEoKAUEQlBQSkiEoKCUkQkBAWliEgICkoRkRAUlCIiISgoRURCUFCKiISgoBQRCUFBKSISgoJSRCQEBaWISAgKShGREBSUIiIhKChFREJQUIqIhDCgXRiNMQDU1dUNa2FEREZKd55159uFDCgo6+vrAcjKyrqEYomIOE99fT3JyckXvMYyA4hTv99PRUUFiYmJWJY1ZAUUERktxhjq6+vJzMzE5brwW8gBBaWIyHimzhwRkRAUlCIiISgoRURCUFCKiISgoBQRCUFBKSISgoJSRCSE/wfv/awrTNdWuQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5vXpGfGOa0R"
      },
      "source": [
        "*b. Random baseline*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLf69UaOObNE",
        "outputId": "b0b4f477-9bc1-41e5-f24f-3c28be24132c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Run: 1\n",
            "### Run: 2\n",
            "### Run: 3\n",
            "Model: Random\n",
            "Test MRR:\tMean: 0.0005276817052314678\tStandard deviation: 2.8745697146413585e-05\n",
            "Test H@10:\tMean: 0.0004886152643408581\tStandard deviation: 6.910063336133565e-05\n"
          ]
        }
      ],
      "source": [
        "def eval_random_metrics(eval_data, k=10):\n",
        "    head_idx, rel_type, tail_idx = eval_data.edge_index[0], eval_data.edge_type, eval_data.edge_index[1]\n",
        "\n",
        "    reciprocal_ranks, hits_at_k = [], []\n",
        "    for i in range(rel_type.shape[0]):\n",
        "        rank = torch.randint(0, rel_type.shape[0], size=(1,))\n",
        "        reciprocal_ranks.append(1 / (rank + 1))\n",
        "        hits_at_k.append(rank < k)\n",
        "\n",
        "    mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "    hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "    return mrr, hits_at_k\n",
        "\n",
        "def use_random():\n",
        "    # test\n",
        "    mrr, hits_at_k = eval_random_metrics(test_data)\n",
        "    return mrr, hits_at_k\n",
        "\n",
        "num_runs = 3\n",
        "mrr_list = []\n",
        "hits_at_k_list = []\n",
        "for run in range(num_runs):\n",
        "    print(\"### Run: {}\".format(run + 1))\n",
        "    mrr, hits_at_k = use_random()\n",
        "    mrr_list.append(mrr)\n",
        "    hits_at_k_list.append(hits_at_k)\n",
        "print(\"Model: Random\")\n",
        "print(\"Test MRR:\\tMean: {}\\tStandard deviation: {}\".format(np.mean(mrr_list), np.std(mrr_list)))\n",
        "print(\"Test H@10:\\tMean: {}\\tStandard deviation: {}\".format(np.mean(hits_at_k_list), np.std(hits_at_k_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJSkpgt0ObgZ"
      },
      "source": [
        "*c. Feature baseline*   \n",
        "Feature: (head, relation, tail)   ->   Prediction: a 0~1 score   \n",
        "Label: 1 for positive edges, 0 for negative edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j4dGNOJOdm2",
        "outputId": "04057d77-229c-4366-e51f-8582d9452e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Run: 1\n",
            "Epoch: 20\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 40\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 60\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 80\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 100\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "### Run: 2\n",
            "Epoch: 20\tValidation MRR: 0.0045\tH@10: 0.0061\n",
            "Epoch: 40\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 60\tValidation MRR: 0.0036\tH@10: 0.0048\n",
            "Epoch: 80\tValidation MRR: 0.0043\tH@10: 0.0060\n",
            "Epoch: 100\tValidation MRR: 0.0043\tH@10: 0.0060\n",
            "### Run: 3\n",
            "Epoch: 20\tValidation MRR: 0.0044\tH@10: 0.0063\n",
            "Epoch: 40\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 60\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 80\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Epoch: 100\tValidation MRR: 0.0043\tH@10: 0.0059\n",
            "Model: MLP\n",
            "Test MRR:\tMean: 0.0042495219968259335\tStandard deviation: 2.858459982794982e-05\n",
            "Test H@10:\tMean: 0.005781947294700153\tStandard deviation: 2.3033544453778778e-05\n"
          ]
        }
      ],
      "source": [
        "class MLPPredictor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPPredictor, self).__init__()\n",
        "        self.scores = nn.Linear(3, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.sigmoid(self.scores(x))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_metrics(self, eval_data, k=10):\n",
        "        head_idx, rel_type, tail_idx = eval_data.edge_index[0].to(\"cuda\"), eval_data.edge_type.to(\"cuda\"), eval_data.edge_index[1].to(\"cuda\")\n",
        "\n",
        "        reciprocal_ranks, hits_at_k = [], []\n",
        "        for i in range(rel_type.shape[0]):\n",
        "            h, r, t = head_idx[i].to(dtype=torch.float32), rel_type[i].to(dtype=torch.float32), tail_idx[i].to(dtype=torch.float32)\n",
        "            all_tails = torch.arange(data.num_nodes, device=\"cuda\")\n",
        "            scores = self(torch.stack([h.expand_as(all_tails), r.expand_as(all_tails), all_tails], dim=0).T).view(-1)\n",
        "            rank = int((scores.argsort(descending=True) == t).nonzero().view(-1))\n",
        "            reciprocal_ranks.append(1 / (rank + 1))\n",
        "            hits_at_k.append(rank < k)\n",
        "\n",
        "        mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "        hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "        return mrr, hits_at_k\n",
        "\n",
        "# negative sampling\n",
        "def process_data(train_data):\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    mask_1 = torch.rand(train_data.edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = train_data.edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(train_data.num_nodes, (mask_1.sum(),), device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(train_data.num_nodes, (mask_2.sum(),), device=neg_edge_index.device)\n",
        "    return train_data.edge_index, neg_edge_index\n",
        "\n",
        "def use_mlp(seed):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    mlp_model = MLPPredictor().to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(mlp_model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "    # train\n",
        "    for epoch in range(100):\n",
        "        mlp_model.train()\n",
        "\n",
        "        # data\n",
        "        pos_edge_index, neg_edge_index = process_data(train_data)\n",
        "\n",
        "        # loss\n",
        "        pos_feature = torch.stack([pos_edge_index[0], train_data.edge_type, pos_edge_index[1]], dim=0).to(dtype=torch.float32).T\n",
        "        neg_feature = torch.stack([neg_edge_index[0], train_data.edge_type, neg_edge_index[1]], dim=0).to(dtype=torch.float32).T\n",
        "        pos_edge_pred = mlp_model(pos_feature)\n",
        "        neg_edge_pred = mlp_model(neg_feature)\n",
        "        pred = torch.cat([pos_edge_pred, neg_edge_pred], dim=1)\n",
        "        label = torch.cat([torch.ones_like(pos_edge_pred), torch.zeros_like(neg_edge_pred)], dim=1)\n",
        "        loss = F.binary_cross_entropy(pred, label)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            mlp_model.eval()\n",
        "            mrr, hits_at_k = mlp_model.eval_metrics(val_data)\n",
        "            print(\"Epoch: {}\\tValidation MRR: {:.4f}\\tH@10: {:.4f}\".format(epoch + 1, mrr, hits_at_k))\n",
        "\n",
        "    # test\n",
        "    mlp_model.eval()\n",
        "    mrr, hits_at_k = mlp_model.eval_metrics(test_data)\n",
        "    return mrr, hits_at_k\n",
        "\n",
        "seed_list = [0, 10388, 19260817]\n",
        "num_runs = len(seed_list)\n",
        "mrr_list = []\n",
        "hits_at_k_list = []\n",
        "for run in range(num_runs):\n",
        "    print(\"### Run: {}\".format(run + 1))\n",
        "    mrr, hits_at_k = use_mlp(seed=seed_list[run])\n",
        "    mrr_list.append(mrr)\n",
        "    hits_at_k_list.append(hits_at_k)\n",
        "print(\"Model: MLP\")\n",
        "print(\"Test MRR:\\tMean: {}\\tStandard deviation: {}\".format(np.mean(mrr_list), np.std(mrr_list)))\n",
        "print(\"Test H@10:\\tMean: {}\\tStandard deviation: {}\".format(np.mean(hits_at_k_list), np.std(hits_at_k_list)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GagwEVwEloYa"
      },
      "source": [
        "#### 1.3.2 GNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uXw0tzsAsUx"
      },
      "source": [
        "RGCN encoder + TransE decoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipt2zHx19Bl6"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "class GNNPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout):\n",
        "        super(GNNPredictor, self).__init__()\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2,  bias=False))\n",
        "        for _ in range(num_gnn_layers - 1):\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2, bias=False))\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.input_emb = nn.Parameter(torch.empty(input_dim, hidden_dim))\n",
        "        init.xavier_uniform_(self.input_emb)\n",
        "\n",
        "    def encoder(self, edge_index, edge_type):\n",
        "        x = self.input_emb\n",
        "        for i, layer in enumerate(self.gnn_layers):\n",
        "            x = layer(x, edge_index, edge_type)\n",
        "            if i < len(self.gnn_layers) - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return x\n",
        "\n",
        "    def decoder(self, head_idx, rel_type, tail_idx):\n",
        "        head = self.node_emb[head_idx]\n",
        "        tail = self.node_emb[tail_idx]\n",
        "        rel = self.rel_emb[rel_type]\n",
        "        head = F.normalize(head, p=1, dim=1)\n",
        "        tail = F.normalize(tail, p=1, dim=1)\n",
        "        return -((head + rel) - tail).norm(p=1, dim=1).view(-1,1)\n",
        "\n",
        "    def forward(self, pos_edge_index, neg_edge_index, edge_type):\n",
        "        self.node_emb = self.encoder(pos_edge_index, edge_type)\n",
        "        return self.decoder(pos_edge_index[0], edge_type, pos_edge_index[1]), self.decoder(neg_edge_index[0], edge_type, neg_edge_index[1])\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_metrics(self, eval_data, k=10):\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/torch_geometric/nn/kge/base.py\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/examples/kge_fb15k_237.py\n",
        "        head_idx, rel_type, tail_idx = eval_data.edge_index[0].to(\"cuda\"), eval_data.edge_type.to(\"cuda\"), eval_data.edge_index[1].to(\"cuda\")\n",
        "\n",
        "        reciprocal_ranks, hits_at_k = [], []\n",
        "        for i in range(rel_type.shape[0]):\n",
        "            h, r, t = head_idx[i], rel_type[i], tail_idx[i]\n",
        "            all_tails = torch.arange(data.num_nodes, device=\"cuda\")\n",
        "            scores = self.decoder(h.expand_as(all_tails), r.expand_as(all_tails), all_tails).view(-1)\n",
        "            rank = int((scores.argsort(descending=True) == t).nonzero().view(-1))\n",
        "            reciprocal_ranks.append(1 / (rank + 1))\n",
        "            hits_at_k.append(rank < k)\n",
        "\n",
        "        mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "        hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "        return mrr, hits_at_k\n",
        "\n",
        "# negative sampling\n",
        "def process_data(train_data):\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    mask_1 = torch.rand(train_data.edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = train_data.edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(train_data.num_nodes, (mask_1.sum(),), device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(train_data.num_nodes, (mask_2.sum(),), device=neg_edge_index.device)\n",
        "    return train_data.edge_index, neg_edge_index\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, reg_coeff):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = GNNPredictor(input_dim=data.num_nodes,\n",
        "                             hidden_dim=hidden_dim,\n",
        "                             num_gnn_layers=num_gnn_layers,\n",
        "                             dropout=dropout).to(\"cuda\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    # train\n",
        "    best_val_mrr = 0\n",
        "    best_val_hits = 0\n",
        "    best_test_mrr = 0\n",
        "    best_test_hits = 0\n",
        "    for epoch in range(400):\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "        # data\n",
        "        pos_edge_index, neg_edge_index = process_data(train_data)\n",
        "\n",
        "        # loss\n",
        "        pos_edge_pred, neg_edge_pred = gnn_model(pos_edge_index, neg_edge_index, train_data.edge_type)\n",
        "        margin_ranking_loss = F.margin_ranking_loss(pos_edge_pred, neg_edge_pred, target=torch.ones_like(pos_edge_pred), margin=1)\n",
        "        reg_loss = gnn_model.node_emb.pow(2).mean() + gnn_model.rel_emb.pow(2).mean()\n",
        "        loss = margin_ranking_loss + reg_coeff * reg_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            gnn_model.eval()\n",
        "            val_mrr, val_hits_at_k = gnn_model.eval_metrics(val_data)\n",
        "            test_mrr, test_hits_at_k = gnn_model.eval_metrics(test_data)\n",
        "            print(\"Epoch: {}\\tValidation MRR: {:.4f}\\tH@10: {:.4f}\\tTest MRR: {:.4f}\\tH@10: {:.4f}\".format(epoch + 1, val_mrr, val_hits_at_k, test_mrr, test_hits_at_k))\n",
        "\n",
        "            if val_hits_at_k > best_val_hits:\n",
        "                best_val_mrr = val_mrr\n",
        "                best_val_hits = val_hits_at_k\n",
        "                best_test_mrr = test_mrr\n",
        "                best_test_hits = test_hits_at_k\n",
        "\n",
        "    return best_val_mrr, best_val_hits, best_test_mrr, best_test_hits\n",
        "\n",
        "# example of running with fixed parameters\n",
        "# hidden_dim = 128\n",
        "# num_gnn_layers = 2\n",
        "# seed_list = [14504]\n",
        "# reg_coeff = 1e-2\n",
        "# dropout = 0\n",
        "# lr = 0.001\n",
        "\n",
        "\n",
        "# num_runs = len(seed_list)\n",
        "# for run in range(num_runs):\n",
        "#     print(\"### Run: {}\".format(run + 1))\n",
        "#     best_val_mrr, best_val_hits, best_test_mrr, best_test_hits = use_gnn(seed=seed_list[run],\n",
        "#                                                                          hidden_dim=hidden_dim,\n",
        "#                                                                          num_gnn_layers=num_gnn_layers,\n",
        "#                                                                          dropout=dropout,\n",
        "#                                                                          lr=lr,\n",
        "#                                                                          reg_coeff=reg_coeff)\n",
        "\n",
        "# print(\"===========Best Results==========\")\n",
        "# # print(\"hidden_dim: {}\".format())\n",
        "# print(\"Validation MRR: {}\".format(best_val_mrr))\n",
        "# print(\"Validation H@10: {}\".format(best_val_hits))\n",
        "# print(\"Test MRR: {}\".format(best_test_mrr))\n",
        "# print(\"Test H@10: {}\".format(best_test_hits))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzc_ymp1cGEG"
      },
      "source": [
        "GPU Release"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srBPeHjVcIDg"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAFKr6XwxIzO"
      },
      "source": [
        "Hyperparameter search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SuRvHN5xIBC",
        "outputId": "331d1762-c019-4214-fc9a-d2f4ed3af17d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10\tValidation MRR: 0.1836\tH@10: 0.2777\tTest MRR: 0.1819\tH@10: 0.2739\n",
            "Epoch: 20\tValidation MRR: 0.1863\tH@10: 0.2992\tTest MRR: 0.1838\tH@10: 0.2951\n",
            "Epoch: 30\tValidation MRR: 0.1861\tH@10: 0.3029\tTest MRR: 0.1849\tH@10: 0.2977\n",
            "Epoch: 40\tValidation MRR: 0.1979\tH@10: 0.3253\tTest MRR: 0.1920\tH@10: 0.3175\n",
            "Epoch: 50\tValidation MRR: 0.2097\tH@10: 0.3469\tTest MRR: 0.2020\tH@10: 0.3402\n",
            "Epoch: 60\tValidation MRR: 0.2170\tH@10: 0.3593\tTest MRR: 0.2110\tH@10: 0.3535\n",
            "Epoch: 70\tValidation MRR: 0.2184\tH@10: 0.3642\tTest MRR: 0.2133\tH@10: 0.3595\n",
            "Epoch: 80\tValidation MRR: 0.2189\tH@10: 0.3664\tTest MRR: 0.2140\tH@10: 0.3585\n",
            "Epoch: 90\tValidation MRR: 0.2252\tH@10: 0.3684\tTest MRR: 0.2205\tH@10: 0.3637\n",
            "Epoch: 100\tValidation MRR: 0.2285\tH@10: 0.3760\tTest MRR: 0.2233\tH@10: 0.3689\n",
            "Epoch: 110\tValidation MRR: 0.2314\tH@10: 0.3792\tTest MRR: 0.2257\tH@10: 0.3722\n",
            "Epoch: 120\tValidation MRR: 0.2325\tH@10: 0.3824\tTest MRR: 0.2273\tH@10: 0.3724\n",
            "Epoch: 130\tValidation MRR: 0.2340\tH@10: 0.3841\tTest MRR: 0.2292\tH@10: 0.3726\n",
            "Epoch: 140\tValidation MRR: 0.2353\tH@10: 0.3864\tTest MRR: 0.2293\tH@10: 0.3736\n",
            "Epoch: 150\tValidation MRR: 0.2374\tH@10: 0.3861\tTest MRR: 0.2278\tH@10: 0.3773\n",
            "Epoch: 160\tValidation MRR: 0.2364\tH@10: 0.3861\tTest MRR: 0.2300\tH@10: 0.3750\n",
            "Epoch: 170\tValidation MRR: 0.2376\tH@10: 0.3868\tTest MRR: 0.2315\tH@10: 0.3769\n",
            "Epoch: 180\tValidation MRR: 0.2365\tH@10: 0.3845\tTest MRR: 0.2313\tH@10: 0.3774\n",
            "Epoch: 190\tValidation MRR: 0.2370\tH@10: 0.3870\tTest MRR: 0.2324\tH@10: 0.3770\n",
            "Epoch: 200\tValidation MRR: 0.2377\tH@10: 0.3872\tTest MRR: 0.2325\tH@10: 0.3798\n",
            "Epoch: 210\tValidation MRR: 0.2380\tH@10: 0.3871\tTest MRR: 0.2334\tH@10: 0.3801\n",
            "Epoch: 220\tValidation MRR: 0.2379\tH@10: 0.3867\tTest MRR: 0.2322\tH@10: 0.3791\n",
            "Epoch: 230\tValidation MRR: 0.2387\tH@10: 0.3854\tTest MRR: 0.2331\tH@10: 0.3794\n",
            "Epoch: 240\tValidation MRR: 0.2394\tH@10: 0.3900\tTest MRR: 0.2336\tH@10: 0.3841\n",
            "Epoch: 250\tValidation MRR: 0.2405\tH@10: 0.3900\tTest MRR: 0.2348\tH@10: 0.3847\n",
            "Epoch: 260\tValidation MRR: 0.2410\tH@10: 0.3895\tTest MRR: 0.2336\tH@10: 0.3843\n",
            "Epoch: 270\tValidation MRR: 0.2415\tH@10: 0.3916\tTest MRR: 0.2343\tH@10: 0.3830\n",
            "Epoch: 280\tValidation MRR: 0.2417\tH@10: 0.3926\tTest MRR: 0.2345\tH@10: 0.3836\n",
            "Epoch: 290\tValidation MRR: 0.2434\tH@10: 0.3933\tTest MRR: 0.2346\tH@10: 0.3845\n",
            "Epoch: 300\tValidation MRR: 0.2432\tH@10: 0.3940\tTest MRR: 0.2359\tH@10: 0.3862\n",
            "Epoch: 310\tValidation MRR: 0.2426\tH@10: 0.3913\tTest MRR: 0.2351\tH@10: 0.3845\n",
            "Epoch: 320\tValidation MRR: 0.2444\tH@10: 0.3900\tTest MRR: 0.2362\tH@10: 0.3840\n",
            "Epoch: 330\tValidation MRR: 0.2429\tH@10: 0.3942\tTest MRR: 0.2350\tH@10: 0.3852\n",
            "Epoch: 340\tValidation MRR: 0.2422\tH@10: 0.3930\tTest MRR: 0.2360\tH@10: 0.3869\n",
            "Epoch: 350\tValidation MRR: 0.2450\tH@10: 0.3956\tTest MRR: 0.2362\tH@10: 0.3868\n",
            "Epoch: 360\tValidation MRR: 0.2439\tH@10: 0.3951\tTest MRR: 0.2360\tH@10: 0.3870\n",
            "Epoch: 370\tValidation MRR: 0.2437\tH@10: 0.3958\tTest MRR: 0.2366\tH@10: 0.3882\n",
            "Epoch: 380\tValidation MRR: 0.2435\tH@10: 0.3914\tTest MRR: 0.2359\tH@10: 0.3869\n",
            "Epoch: 390\tValidation MRR: 0.2433\tH@10: 0.3955\tTest MRR: 0.2352\tH@10: 0.3868\n",
            "Epoch: 400\tValidation MRR: 0.2444\tH@10: 0.3968\tTest MRR: 0.2366\tH@10: 0.3878\n",
            "Epoch: 10\tValidation MRR: 0.1927\tH@10: 0.2989\tTest MRR: 0.1926\tH@10: 0.2964\n",
            "Epoch: 20\tValidation MRR: 0.1893\tH@10: 0.3070\tTest MRR: 0.1876\tH@10: 0.3019\n",
            "Epoch: 30\tValidation MRR: 0.2030\tH@10: 0.3212\tTest MRR: 0.1973\tH@10: 0.3132\n",
            "Epoch: 40\tValidation MRR: 0.2142\tH@10: 0.3386\tTest MRR: 0.2106\tH@10: 0.3312\n",
            "Epoch: 50\tValidation MRR: 0.2184\tH@10: 0.3579\tTest MRR: 0.2101\tH@10: 0.3476\n",
            "Epoch: 60\tValidation MRR: 0.2242\tH@10: 0.3609\tTest MRR: 0.2162\tH@10: 0.3522\n",
            "Epoch: 70\tValidation MRR: 0.2278\tH@10: 0.3706\tTest MRR: 0.2180\tH@10: 0.3637\n",
            "Epoch: 80\tValidation MRR: 0.2294\tH@10: 0.3721\tTest MRR: 0.2200\tH@10: 0.3644\n",
            "Epoch: 90\tValidation MRR: 0.2366\tH@10: 0.3782\tTest MRR: 0.2274\tH@10: 0.3722\n",
            "Epoch: 100\tValidation MRR: 0.2395\tH@10: 0.3817\tTest MRR: 0.2309\tH@10: 0.3753\n",
            "Epoch: 110\tValidation MRR: 0.2431\tH@10: 0.3873\tTest MRR: 0.2350\tH@10: 0.3781\n",
            "Epoch: 120\tValidation MRR: 0.2454\tH@10: 0.3897\tTest MRR: 0.2362\tH@10: 0.3799\n",
            "Epoch: 130\tValidation MRR: 0.2447\tH@10: 0.3917\tTest MRR: 0.2393\tH@10: 0.3842\n",
            "Epoch: 140\tValidation MRR: 0.2453\tH@10: 0.3921\tTest MRR: 0.2404\tH@10: 0.3869\n",
            "Epoch: 150\tValidation MRR: 0.2463\tH@10: 0.3956\tTest MRR: 0.2386\tH@10: 0.3869\n",
            "Epoch: 160\tValidation MRR: 0.2457\tH@10: 0.3971\tTest MRR: 0.2390\tH@10: 0.3897\n",
            "Epoch: 170\tValidation MRR: 0.2460\tH@10: 0.3977\tTest MRR: 0.2403\tH@10: 0.3875\n",
            "Epoch: 180\tValidation MRR: 0.2473\tH@10: 0.3991\tTest MRR: 0.2409\tH@10: 0.3903\n",
            "Epoch: 190\tValidation MRR: 0.2474\tH@10: 0.3975\tTest MRR: 0.2426\tH@10: 0.3928\n",
            "Epoch: 200\tValidation MRR: 0.2473\tH@10: 0.3999\tTest MRR: 0.2415\tH@10: 0.3868\n",
            "Epoch: 210\tValidation MRR: 0.2471\tH@10: 0.4019\tTest MRR: 0.2413\tH@10: 0.3923\n",
            "Epoch: 220\tValidation MRR: 0.2492\tH@10: 0.4010\tTest MRR: 0.2432\tH@10: 0.3908\n",
            "Epoch: 230\tValidation MRR: 0.2485\tH@10: 0.4003\tTest MRR: 0.2419\tH@10: 0.3901\n",
            "Epoch: 240\tValidation MRR: 0.2495\tH@10: 0.4015\tTest MRR: 0.2436\tH@10: 0.3916\n",
            "Epoch: 250\tValidation MRR: 0.2485\tH@10: 0.4000\tTest MRR: 0.2420\tH@10: 0.3895\n",
            "Epoch: 260\tValidation MRR: 0.2509\tH@10: 0.4023\tTest MRR: 0.2441\tH@10: 0.3920\n",
            "Epoch: 270\tValidation MRR: 0.2503\tH@10: 0.4011\tTest MRR: 0.2431\tH@10: 0.3915\n",
            "Epoch: 280\tValidation MRR: 0.2505\tH@10: 0.4017\tTest MRR: 0.2446\tH@10: 0.3928\n",
            "Epoch: 290\tValidation MRR: 0.2513\tH@10: 0.4003\tTest MRR: 0.2443\tH@10: 0.3927\n",
            "Epoch: 300\tValidation MRR: 0.2508\tH@10: 0.4014\tTest MRR: 0.2419\tH@10: 0.3930\n",
            "Epoch: 310\tValidation MRR: 0.2509\tH@10: 0.4020\tTest MRR: 0.2426\tH@10: 0.3928\n",
            "Epoch: 320\tValidation MRR: 0.2515\tH@10: 0.4027\tTest MRR: 0.2441\tH@10: 0.3931\n",
            "Epoch: 330\tValidation MRR: 0.2517\tH@10: 0.4025\tTest MRR: 0.2438\tH@10: 0.3933\n",
            "Epoch: 340\tValidation MRR: 0.2515\tH@10: 0.4026\tTest MRR: 0.2456\tH@10: 0.3920\n",
            "Epoch: 350\tValidation MRR: 0.2520\tH@10: 0.4026\tTest MRR: 0.2449\tH@10: 0.3928\n",
            "Epoch: 360\tValidation MRR: 0.2514\tH@10: 0.4025\tTest MRR: 0.2435\tH@10: 0.3916\n",
            "Epoch: 370\tValidation MRR: 0.2521\tH@10: 0.4038\tTest MRR: 0.2441\tH@10: 0.3926\n",
            "Epoch: 380\tValidation MRR: 0.2502\tH@10: 0.4019\tTest MRR: 0.2451\tH@10: 0.3928\n",
            "Epoch: 390\tValidation MRR: 0.2521\tH@10: 0.4001\tTest MRR: 0.2454\tH@10: 0.3940\n",
            "Epoch: 400\tValidation MRR: 0.2534\tH@10: 0.4046\tTest MRR: 0.2464\tH@10: 0.3943\n",
            "===========Best Results==========\n",
            "Validation MRR: 0.2534167468547821\n",
            "Validation H@10: 0.40461933276304535\n",
            "Test MRR: 0.24639004468917847\n",
            "Test H@10: 0.39426365679663833\n",
            "Best Hyperparameters: {'hidden_dim': 128, 'num_gnn_layer': 2, 'seed': 0, 'reg_coeff': 1, 'dropout': 0, 'num_gnn_layers': 2}\n"
          ]
        }
      ],
      "source": [
        "import itertools\n",
        "_hidden_dim = [64, 128]\n",
        "_num_gnn_layers = [2]\n",
        "_seed = [0]\n",
        "_reg_coeff = [1]\n",
        "_dropout = [0]\n",
        "lr = 0.001\n",
        "\n",
        "_best_val_mrr = 0\n",
        "_best_val_hits = 0\n",
        "_best_test_mrr = 0\n",
        "_best_test_hits = 0\n",
        "\n",
        "best_parameters = {'hidden_dim': 64, 'num_gnn_layer': 2, 'seed':14504, 'reg_coeff': 1, 'dropout': 0}\n",
        "\n",
        "\n",
        "for hidden_dim, num_gnn_layers, seed, reg_coeff, dropout in itertools.product(_hidden_dim, _num_gnn_layers, _seed, _reg_coeff, _dropout):\n",
        "    best_val_mrr, best_val_hits, best_test_mrr, best_test_hits = use_gnn(seed=seed,\n",
        "                                                                         hidden_dim=hidden_dim,\n",
        "                                                                         num_gnn_layers=num_gnn_layers,\n",
        "                                                                         dropout=dropout,\n",
        "                                                                         lr=lr,\n",
        "                                                                         reg_coeff=reg_coeff)\n",
        "    if best_val_hits > _best_val_hits:\n",
        "        _best_val_mrr = best_val_mrr\n",
        "        _best_val_hits = best_val_hits\n",
        "        _best_test_mrr = best_test_mrr\n",
        "        _best_test_hits = best_test_hits\n",
        "\n",
        "        best_parameters[\"hidden_dim\"] = hidden_dim\n",
        "        best_parameters[\"num_gnn_layers\"] = num_gnn_layers\n",
        "        best_parameters[\"seed\"] = seed\n",
        "        best_parameters[\"reg_coeff\"] = reg_coeff\n",
        "        best_parameters[\"dropout\"] = dropout\n",
        "\n",
        "    # clear GPU Resources once finished one task\n",
        "    import gc\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"===========Best Results==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(_best_val_mrr))\n",
        "print(\"Validation H@10: {}\".format(_best_val_hits))\n",
        "print(\"Test MRR: {}\".format(_best_test_mrr))\n",
        "print(\"Test H@10: {}\".format(_best_test_hits))\n",
        "print(\"Best Hyperparameters: {}\".format(best_parameters))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Release GPU"
      ],
      "metadata": {
        "id": "jTkEM82mm1MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clear GPU Resources once finished one task\n",
        "import gc\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "tvU-WYpVmxTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fCv54N_loqf"
      },
      "source": [
        "#### 1.3.3 Augmentations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWzGrzP51Sxa"
      },
      "source": [
        "Node feature augmentation:\n",
        "1. Constant feature\n",
        "2. One-hot feature\n",
        "3. Virtual Node (Sparse Graph)\n",
        "4. Dropping Node / Dropping Edge (Dense Graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-7bHZtjlowE"
      },
      "outputs": [],
      "source": [
        "class GNNPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout, feature_augment):\n",
        "        super(GNNPredictor, self).__init__()\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        if feature_augment == \"constant\": # constant feature\n",
        "            data.x = torch.ones((data.num_nodes, 1)).to(\"cuda\")\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(1, hidden_dim, dataset.num_relations*2, bias=False))\n",
        "        elif feature_augment == \"one_hot\": # one-hot feature\n",
        "            data.x = torch.eye(data.num_nodes).to(\"cuda\")\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2, bias=False))\n",
        "        elif feature_augment == \"virtualnode\": # virtual node\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2, bias=False))\n",
        "        for _ in range(num_gnn_layers - 1):\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2, bias=False))\n",
        "        self.dropout = dropout\n",
        "        self.feature_augment = feature_augment\n",
        "        self.onehot_lin = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.input_emb = nn.Parameter(torch.empty(input_dim, hidden_dim))\n",
        "        init.xavier_uniform_(self.input_emb)\n",
        "\n",
        "        # virtual node embedding\n",
        "        self.virtual_node = nn.Parameter(torch.randn(hidden_dim))\n",
        "        self.virtual_linear = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def encoder(self, edge_index, edge_type):\n",
        "        if self.feature_augment == \"virtualnode\":\n",
        "            x = self.input_emb\n",
        "        else:\n",
        "            x = data.x\n",
        "            if self.feature_augment == \"one_hot\":\n",
        "                x = F.relu(self.onehot_lin(x))\n",
        "\n",
        "        for i, layer in enumerate(self.gnn_layers):\n",
        "            x = layer(x, edge_index, edge_type)\n",
        "            if i < len(self.gnn_layers) - 1:\n",
        "                x = F.relu(x)\n",
        "                x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "                if self.feature_augment == \"virtualnode\":\n",
        "                    virtualnode_embedding = self.virtual_node + x.sum(dim=0)\n",
        "                    virtualnode_embedding = F.relu(self.virtual_linear(virtualnode_embedding))\n",
        "                    x = x + virtualnode_embedding.unsqueeze(0)\n",
        "        return x\n",
        "\n",
        "    def decoder(self, head_idx, rel_type, tail_idx):\n",
        "        head = self.node_emb[head_idx]\n",
        "        tail = self.node_emb[tail_idx]\n",
        "        rel = self.rel_emb[rel_type]\n",
        "        head = F.normalize(head, p=1, dim=1)\n",
        "        tail = F.normalize(tail, p=1, dim=1)\n",
        "        return -((head + rel) - tail).norm(p=1, dim=1).view(-1,1)\n",
        "\n",
        "    def forward(self, pos_edge_index, neg_edge_index, edge_type):\n",
        "        self.node_emb = self.encoder(pos_edge_index, edge_type)\n",
        "        return self.decoder(pos_edge_index[0], edge_type, pos_edge_index[1]), self.decoder(neg_edge_index[0], edge_type, neg_edge_index[1])\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_metrics(self, eval_data, k=10):\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/torch_geometric/nn/kge/base.py\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/examples/kge_fb15k_237.py\n",
        "        head_idx, rel_type, tail_idx = eval_data.edge_index[0].to(\"cuda\"), eval_data.edge_type.to(\"cuda\"), eval_data.edge_index[1].to(\"cuda\")\n",
        "\n",
        "        reciprocal_ranks, hits_at_k = [], []\n",
        "        for i in range(rel_type.shape[0]):\n",
        "            h, r, t = head_idx[i], rel_type[i], tail_idx[i]\n",
        "            all_tails = torch.arange(data.num_nodes, device=\"cuda\")\n",
        "            scores = self.decoder(h.expand_as(all_tails), r.expand_as(all_tails), all_tails).view(-1)\n",
        "            rank = int((scores.argsort(descending=True) == t).nonzero().view(-1))\n",
        "            reciprocal_ranks.append(1 / (rank + 1))\n",
        "            hits_at_k.append(rank < k)\n",
        "\n",
        "        mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "        hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "        return mrr, hits_at_k\n",
        "\n",
        "# negative sampling\n",
        "def process_data(train_data):\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    mask_1 = torch.rand(train_data.edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = train_data.edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(train_data.num_nodes, (mask_1.sum(),), device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(train_data.num_nodes, (mask_2.sum(),), device=neg_edge_index.device)\n",
        "    return train_data.edge_index, neg_edge_index\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, reg_coeff, feature_augment):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = GNNPredictor(input_dim=data.num_nodes,\n",
        "                             hidden_dim=hidden_dim,\n",
        "                             num_gnn_layers=num_gnn_layers,\n",
        "                             dropout=dropout,\n",
        "                             feature_augment=feature_augment).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    # train\n",
        "    for epoch in range(400):\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # data\n",
        "        pos_edge_index, neg_edge_index = process_data(train_data)\n",
        "\n",
        "        # loss\n",
        "        pos_edge_pred, neg_edge_pred = gnn_model(pos_edge_index, neg_edge_index, train_data.edge_type)\n",
        "        margin_ranking_loss = F.margin_ranking_loss(pos_edge_pred, neg_edge_pred, target=torch.ones_like(pos_edge_pred), margin=1)\n",
        "        reg_loss = gnn_model.node_emb.pow(2).mean() + gnn_model.rel_emb.pow(2).mean()\n",
        "        loss = margin_ranking_loss + reg_coeff * reg_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            gnn_model.eval()\n",
        "            val_mrr, val_hits_at_k = gnn_model.eval_metrics(val_data)\n",
        "            test_mrr, test_hits_at_k = gnn_model.eval_metrics(test_data)\n",
        "            print(\"Epoch: {}\\tValidation MRR: {:.4f}\\tH@10: {:.4f}\\tTest MRR: {:.4f}\\tH@10: {:.4f}\".format(epoch + 1, val_mrr, val_hits_at_k, test_mrr, test_hits_at_k))\n",
        "\n",
        "    return val_mrr, val_hits_at_k, test_mrr, test_hits_at_k\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPLrCJ5Vc9Ig"
      },
      "source": [
        " **One**-**hot** **feature** augmentation (Feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdpA7DuYc6hD",
        "outputId": "5a0aa6f8-23be-4139-93b6-837c00a12ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10\tValidation MRR: 0.1756\tH@10: 0.2825\tTest MRR: 0.1758\tH@10: 0.2808\n",
            "Epoch: 20\tValidation MRR: 0.1806\tH@10: 0.2935\tTest MRR: 0.1785\tH@10: 0.2882\n",
            "Epoch: 30\tValidation MRR: 0.1922\tH@10: 0.3092\tTest MRR: 0.1899\tH@10: 0.3024\n",
            "Epoch: 40\tValidation MRR: 0.1970\tH@10: 0.3236\tTest MRR: 0.1932\tH@10: 0.3153\n",
            "Epoch: 50\tValidation MRR: 0.2108\tH@10: 0.3381\tTest MRR: 0.2039\tH@10: 0.3284\n",
            "Epoch: 60\tValidation MRR: 0.2187\tH@10: 0.3458\tTest MRR: 0.2111\tH@10: 0.3373\n",
            "Epoch: 70\tValidation MRR: 0.2206\tH@10: 0.3509\tTest MRR: 0.2150\tH@10: 0.3410\n",
            "Epoch: 80\tValidation MRR: 0.2171\tH@10: 0.3553\tTest MRR: 0.2094\tH@10: 0.3422\n",
            "Epoch: 90\tValidation MRR: 0.2236\tH@10: 0.3565\tTest MRR: 0.2148\tH@10: 0.3477\n",
            "Epoch: 100\tValidation MRR: 0.2259\tH@10: 0.3594\tTest MRR: 0.2195\tH@10: 0.3505\n",
            "Epoch: 110\tValidation MRR: 0.2214\tH@10: 0.3678\tTest MRR: 0.2173\tH@10: 0.3597\n",
            "Epoch: 120\tValidation MRR: 0.2280\tH@10: 0.3726\tTest MRR: 0.2215\tH@10: 0.3618\n",
            "Epoch: 130\tValidation MRR: 0.2317\tH@10: 0.3749\tTest MRR: 0.2255\tH@10: 0.3642\n",
            "Epoch: 140\tValidation MRR: 0.2349\tH@10: 0.3791\tTest MRR: 0.2277\tH@10: 0.3676\n",
            "Epoch: 150\tValidation MRR: 0.2354\tH@10: 0.3807\tTest MRR: 0.2271\tH@10: 0.3692\n",
            "Epoch: 160\tValidation MRR: 0.2367\tH@10: 0.3807\tTest MRR: 0.2287\tH@10: 0.3699\n",
            "Epoch: 170\tValidation MRR: 0.2370\tH@10: 0.3816\tTest MRR: 0.2293\tH@10: 0.3698\n",
            "Epoch: 180\tValidation MRR: 0.2371\tH@10: 0.3835\tTest MRR: 0.2297\tH@10: 0.3706\n",
            "Epoch: 190\tValidation MRR: 0.2388\tH@10: 0.3860\tTest MRR: 0.2298\tH@10: 0.3740\n",
            "Epoch: 200\tValidation MRR: 0.2387\tH@10: 0.3888\tTest MRR: 0.2307\tH@10: 0.3757\n",
            "Epoch: 210\tValidation MRR: 0.2412\tH@10: 0.3883\tTest MRR: 0.2324\tH@10: 0.3769\n",
            "Epoch: 220\tValidation MRR: 0.2406\tH@10: 0.3876\tTest MRR: 0.2319\tH@10: 0.3760\n",
            "Epoch: 230\tValidation MRR: 0.2404\tH@10: 0.3891\tTest MRR: 0.2321\tH@10: 0.3785\n",
            "Epoch: 240\tValidation MRR: 0.2414\tH@10: 0.3906\tTest MRR: 0.2327\tH@10: 0.3794\n",
            "Epoch: 250\tValidation MRR: 0.2436\tH@10: 0.3926\tTest MRR: 0.2345\tH@10: 0.3797\n",
            "Epoch: 260\tValidation MRR: 0.2403\tH@10: 0.3926\tTest MRR: 0.2326\tH@10: 0.3813\n",
            "Epoch: 270\tValidation MRR: 0.2429\tH@10: 0.3930\tTest MRR: 0.2346\tH@10: 0.3808\n",
            "Epoch: 280\tValidation MRR: 0.2423\tH@10: 0.3939\tTest MRR: 0.2340\tH@10: 0.3820\n",
            "Epoch: 290\tValidation MRR: 0.2416\tH@10: 0.3922\tTest MRR: 0.2333\tH@10: 0.3821\n",
            "Epoch: 300\tValidation MRR: 0.2402\tH@10: 0.3954\tTest MRR: 0.2330\tH@10: 0.3823\n",
            "Epoch: 310\tValidation MRR: 0.2414\tH@10: 0.3965\tTest MRR: 0.2343\tH@10: 0.3840\n",
            "Epoch: 320\tValidation MRR: 0.2437\tH@10: 0.3949\tTest MRR: 0.2359\tH@10: 0.3838\n",
            "Epoch: 330\tValidation MRR: 0.2431\tH@10: 0.3939\tTest MRR: 0.2349\tH@10: 0.3814\n",
            "Epoch: 340\tValidation MRR: 0.2424\tH@10: 0.3943\tTest MRR: 0.2347\tH@10: 0.3824\n",
            "Epoch: 350\tValidation MRR: 0.2437\tH@10: 0.3969\tTest MRR: 0.2364\tH@10: 0.3845\n",
            "Epoch: 360\tValidation MRR: 0.2423\tH@10: 0.3959\tTest MRR: 0.2354\tH@10: 0.3864\n",
            "Epoch: 370\tValidation MRR: 0.2429\tH@10: 0.3940\tTest MRR: 0.2350\tH@10: 0.3845\n",
            "Epoch: 380\tValidation MRR: 0.2419\tH@10: 0.3937\tTest MRR: 0.2358\tH@10: 0.3877\n",
            "Epoch: 390\tValidation MRR: 0.2423\tH@10: 0.3953\tTest MRR: 0.2349\tH@10: 0.3866\n",
            "Epoch: 400\tValidation MRR: 0.2428\tH@10: 0.3953\tTest MRR: 0.2350\tH@10: 0.3857\n",
            "===========Best GNN==========\n",
            "Validation MRR: 0.24278390407562256\n",
            "Validation H@10: 0.39526660963786714\n",
            "Test MRR: 0.23499339818954468\n",
            "Test H@10: 0.3856640281442392\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "hidden_dim = 128\n",
        "num_gnn_layers = 2\n",
        "seed = 0\n",
        "reg_coeff = 1e-2\n",
        "dropout = 0\n",
        "lr = 0.001\n",
        "feature_augment = \"one_hot\"\n",
        "\n",
        "val_mrr, val_hits_at_k, test_mrr, test_hits_at_k = use_gnn(seed=seed,\n",
        "                                                           hidden_dim=hidden_dim,\n",
        "                                                           num_gnn_layers=num_gnn_layers,\n",
        "                                                           dropout=dropout,\n",
        "                                                           lr=lr,\n",
        "                                                           reg_coeff=reg_coeff,\n",
        "                                                           feature_augment=feature_augment)\n",
        "\n",
        "print(\"===========Best GNN==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(val_mrr))\n",
        "print(\"Validation H@10: {}\".format(val_hits_at_k))\n",
        "print(\"Test MRR: {}\".format(test_mrr))\n",
        "print(\"Test H@10: {}\".format(test_hits_at_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1K5_6YBbw2u"
      },
      "source": [
        "Release GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evtpa10sbwDc"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NBc6wCkddhI"
      },
      "source": [
        " **Constant** **feature** augmentation (Feature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUu-_06pdkZs",
        "outputId": "5e32a3b7-6c83-417f-bba7-0d00a3043ffd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10\tValidation MRR: 0.1465\tH@10: 0.2396\tTest MRR: 0.1474\tH@10: 0.2384\n",
            "Epoch: 20\tValidation MRR: 0.1583\tH@10: 0.2691\tTest MRR: 0.1566\tH@10: 0.2669\n",
            "Epoch: 30\tValidation MRR: 0.1720\tH@10: 0.2864\tTest MRR: 0.1700\tH@10: 0.2835\n",
            "Epoch: 40\tValidation MRR: 0.1784\tH@10: 0.2923\tTest MRR: 0.1778\tH@10: 0.2906\n",
            "Epoch: 50\tValidation MRR: 0.1842\tH@10: 0.2960\tTest MRR: 0.1827\tH@10: 0.2956\n",
            "Epoch: 60\tValidation MRR: 0.1988\tH@10: 0.3102\tTest MRR: 0.1938\tH@10: 0.3060\n",
            "Epoch: 70\tValidation MRR: 0.2009\tH@10: 0.3184\tTest MRR: 0.1969\tH@10: 0.3126\n",
            "Epoch: 80\tValidation MRR: 0.2066\tH@10: 0.3235\tTest MRR: 0.2037\tH@10: 0.3184\n",
            "Epoch: 90\tValidation MRR: 0.2088\tH@10: 0.3235\tTest MRR: 0.2061\tH@10: 0.3187\n",
            "Epoch: 100\tValidation MRR: 0.2124\tH@10: 0.3306\tTest MRR: 0.2088\tH@10: 0.3208\n",
            "Epoch: 110\tValidation MRR: 0.2145\tH@10: 0.3301\tTest MRR: 0.2097\tH@10: 0.3235\n",
            "Epoch: 120\tValidation MRR: 0.2153\tH@10: 0.3330\tTest MRR: 0.2107\tH@10: 0.3236\n",
            "Epoch: 130\tValidation MRR: 0.2168\tH@10: 0.3362\tTest MRR: 0.2112\tH@10: 0.3260\n",
            "Epoch: 140\tValidation MRR: 0.2193\tH@10: 0.3388\tTest MRR: 0.2115\tH@10: 0.3284\n",
            "Epoch: 150\tValidation MRR: 0.2220\tH@10: 0.3425\tTest MRR: 0.2146\tH@10: 0.3335\n",
            "Epoch: 160\tValidation MRR: 0.2222\tH@10: 0.3407\tTest MRR: 0.2160\tH@10: 0.3318\n",
            "Epoch: 170\tValidation MRR: 0.2244\tH@10: 0.3423\tTest MRR: 0.2172\tH@10: 0.3332\n",
            "Epoch: 180\tValidation MRR: 0.2261\tH@10: 0.3483\tTest MRR: 0.2184\tH@10: 0.3365\n",
            "Epoch: 190\tValidation MRR: 0.2280\tH@10: 0.3492\tTest MRR: 0.2204\tH@10: 0.3375\n",
            "Epoch: 200\tValidation MRR: 0.2269\tH@10: 0.3483\tTest MRR: 0.2203\tH@10: 0.3393\n",
            "Epoch: 210\tValidation MRR: 0.2299\tH@10: 0.3547\tTest MRR: 0.2230\tH@10: 0.3434\n",
            "Epoch: 220\tValidation MRR: 0.2298\tH@10: 0.3536\tTest MRR: 0.2231\tH@10: 0.3423\n",
            "Epoch: 230\tValidation MRR: 0.2313\tH@10: 0.3543\tTest MRR: 0.2239\tH@10: 0.3436\n",
            "Epoch: 240\tValidation MRR: 0.2321\tH@10: 0.3565\tTest MRR: 0.2246\tH@10: 0.3442\n",
            "Epoch: 250\tValidation MRR: 0.2335\tH@10: 0.3572\tTest MRR: 0.2251\tH@10: 0.3451\n",
            "Epoch: 260\tValidation MRR: 0.2331\tH@10: 0.3574\tTest MRR: 0.2242\tH@10: 0.3466\n",
            "Epoch: 270\tValidation MRR: 0.2338\tH@10: 0.3593\tTest MRR: 0.2246\tH@10: 0.3453\n",
            "Epoch: 280\tValidation MRR: 0.2338\tH@10: 0.3599\tTest MRR: 0.2255\tH@10: 0.3459\n",
            "Epoch: 290\tValidation MRR: 0.2339\tH@10: 0.3589\tTest MRR: 0.2255\tH@10: 0.3473\n",
            "Epoch: 300\tValidation MRR: 0.2364\tH@10: 0.3585\tTest MRR: 0.2274\tH@10: 0.3474\n",
            "Epoch: 310\tValidation MRR: 0.2350\tH@10: 0.3601\tTest MRR: 0.2266\tH@10: 0.3504\n",
            "Epoch: 320\tValidation MRR: 0.2372\tH@10: 0.3623\tTest MRR: 0.2288\tH@10: 0.3526\n",
            "Epoch: 330\tValidation MRR: 0.2380\tH@10: 0.3639\tTest MRR: 0.2293\tH@10: 0.3514\n",
            "Epoch: 340\tValidation MRR: 0.2366\tH@10: 0.3631\tTest MRR: 0.2279\tH@10: 0.3521\n",
            "Epoch: 350\tValidation MRR: 0.2386\tH@10: 0.3646\tTest MRR: 0.2292\tH@10: 0.3537\n",
            "Epoch: 360\tValidation MRR: 0.2386\tH@10: 0.3636\tTest MRR: 0.2293\tH@10: 0.3521\n",
            "Epoch: 370\tValidation MRR: 0.2379\tH@10: 0.3654\tTest MRR: 0.2284\tH@10: 0.3528\n",
            "Epoch: 380\tValidation MRR: 0.2386\tH@10: 0.3646\tTest MRR: 0.2294\tH@10: 0.3534\n",
            "Epoch: 390\tValidation MRR: 0.2377\tH@10: 0.3660\tTest MRR: 0.2294\tH@10: 0.3548\n",
            "Epoch: 400\tValidation MRR: 0.2372\tH@10: 0.3659\tTest MRR: 0.2285\tH@10: 0.3554\n",
            "===========Best GNN==========\n",
            "Validation MRR: 0.23723140358924866\n",
            "Validation H@10: 0.36589677787282576\n",
            "Test MRR: 0.22850371897220612\n",
            "Test H@10: 0.3554187432815401\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "hidden_dim = 128\n",
        "num_gnn_layers = 2\n",
        "seed = 0\n",
        "reg_coeff = 1e-2\n",
        "dropout = 0\n",
        "lr = 0.001\n",
        "feature_augment = \"constant\"\n",
        "\n",
        "val_mrr, val_hits_at_k, test_mrr, test_hits_at_k = use_gnn(seed=seed,\n",
        "                                                           hidden_dim=hidden_dim,\n",
        "                                                           num_gnn_layers=num_gnn_layers,\n",
        "                                                           dropout=dropout,\n",
        "                                                           lr=lr,\n",
        "                                                           reg_coeff=reg_coeff,\n",
        "                                                           feature_augment=feature_augment)\n",
        "\n",
        "print(\"===========Best GNN==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(val_mrr))\n",
        "print(\"Validation H@10: {}\".format(val_hits_at_k))\n",
        "print(\"Test MRR: {}\".format(test_mrr))\n",
        "print(\"Test H@10: {}\".format(test_hits_at_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG9TVHC2c8H9"
      },
      "source": [
        "Release GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGGjG9MXdjvE"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1RgCLZC1Wxz"
      },
      "source": [
        " **Virtual** **Node** augmentation (Structure)\n",
        "\n",
        "Since the graph is relatively sparses, we use virtual node augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJYPWw3Dd7Ss",
        "outputId": "2da877cd-7da6-4236-ec3e-aa81a58b47bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10\tValidation MRR: 0.0015\tH@10: 0.0027\tTest MRR: 0.0017\tH@10: 0.0027\n",
            "Epoch: 20\tValidation MRR: 0.1812\tH@10: 0.2756\tTest MRR: 0.1834\tH@10: 0.2786\n",
            "Epoch: 30\tValidation MRR: 0.1911\tH@10: 0.2938\tTest MRR: 0.1908\tH@10: 0.2894\n",
            "Epoch: 40\tValidation MRR: 0.1929\tH@10: 0.3101\tTest MRR: 0.1902\tH@10: 0.3051\n",
            "Epoch: 50\tValidation MRR: 0.2119\tH@10: 0.3413\tTest MRR: 0.2083\tH@10: 0.3378\n",
            "Epoch: 60\tValidation MRR: 0.2170\tH@10: 0.3442\tTest MRR: 0.2132\tH@10: 0.3383\n",
            "Epoch: 70\tValidation MRR: 0.2227\tH@10: 0.3534\tTest MRR: 0.2177\tH@10: 0.3447\n",
            "Epoch: 80\tValidation MRR: 0.2213\tH@10: 0.3588\tTest MRR: 0.2149\tH@10: 0.3475\n",
            "Epoch: 90\tValidation MRR: 0.2214\tH@10: 0.3607\tTest MRR: 0.2156\tH@10: 0.3495\n",
            "Epoch: 100\tValidation MRR: 0.2248\tH@10: 0.3634\tTest MRR: 0.2177\tH@10: 0.3519\n",
            "Epoch: 110\tValidation MRR: 0.2311\tH@10: 0.3676\tTest MRR: 0.2234\tH@10: 0.3589\n",
            "Epoch: 120\tValidation MRR: 0.2299\tH@10: 0.3648\tTest MRR: 0.2238\tH@10: 0.3548\n",
            "Epoch: 130\tValidation MRR: 0.2314\tH@10: 0.3672\tTest MRR: 0.2262\tH@10: 0.3577\n",
            "Epoch: 140\tValidation MRR: 0.2360\tH@10: 0.3693\tTest MRR: 0.2301\tH@10: 0.3588\n",
            "Epoch: 150\tValidation MRR: 0.2365\tH@10: 0.3718\tTest MRR: 0.2297\tH@10: 0.3634\n",
            "Epoch: 160\tValidation MRR: 0.2379\tH@10: 0.3752\tTest MRR: 0.2305\tH@10: 0.3641\n",
            "Epoch: 170\tValidation MRR: 0.2365\tH@10: 0.3807\tTest MRR: 0.2275\tH@10: 0.3657\n",
            "Epoch: 180\tValidation MRR: 0.2385\tH@10: 0.3761\tTest MRR: 0.2309\tH@10: 0.3675\n",
            "Epoch: 190\tValidation MRR: 0.2367\tH@10: 0.3796\tTest MRR: 0.2271\tH@10: 0.3677\n",
            "Epoch: 200\tValidation MRR: 0.2364\tH@10: 0.3784\tTest MRR: 0.2273\tH@10: 0.3674\n",
            "Epoch: 210\tValidation MRR: 0.2393\tH@10: 0.3814\tTest MRR: 0.2294\tH@10: 0.3688\n",
            "Epoch: 220\tValidation MRR: 0.2383\tH@10: 0.3785\tTest MRR: 0.2297\tH@10: 0.3661\n",
            "Epoch: 230\tValidation MRR: 0.2396\tH@10: 0.3816\tTest MRR: 0.2307\tH@10: 0.3670\n",
            "Epoch: 240\tValidation MRR: 0.2411\tH@10: 0.3820\tTest MRR: 0.2313\tH@10: 0.3726\n",
            "Epoch: 250\tValidation MRR: 0.2432\tH@10: 0.3873\tTest MRR: 0.2334\tH@10: 0.3745\n",
            "Epoch: 260\tValidation MRR: 0.2460\tH@10: 0.3880\tTest MRR: 0.2351\tH@10: 0.3769\n",
            "Epoch: 270\tValidation MRR: 0.2467\tH@10: 0.3884\tTest MRR: 0.2359\tH@10: 0.3780\n",
            "Epoch: 280\tValidation MRR: 0.2468\tH@10: 0.3886\tTest MRR: 0.2354\tH@10: 0.3782\n",
            "Epoch: 290\tValidation MRR: 0.2465\tH@10: 0.3908\tTest MRR: 0.2362\tH@10: 0.3801\n",
            "Epoch: 300\tValidation MRR: 0.2467\tH@10: 0.3919\tTest MRR: 0.2369\tH@10: 0.3818\n",
            "Epoch: 310\tValidation MRR: 0.2477\tH@10: 0.3934\tTest MRR: 0.2384\tH@10: 0.3832\n",
            "Epoch: 320\tValidation MRR: 0.2470\tH@10: 0.3924\tTest MRR: 0.2378\tH@10: 0.3823\n",
            "Epoch: 330\tValidation MRR: 0.2469\tH@10: 0.3938\tTest MRR: 0.2371\tH@10: 0.3836\n",
            "Epoch: 340\tValidation MRR: 0.2471\tH@10: 0.3966\tTest MRR: 0.2385\tH@10: 0.3841\n",
            "Epoch: 350\tValidation MRR: 0.2476\tH@10: 0.3977\tTest MRR: 0.2389\tH@10: 0.3858\n",
            "Epoch: 360\tValidation MRR: 0.2469\tH@10: 0.3967\tTest MRR: 0.2387\tH@10: 0.3862\n",
            "Epoch: 370\tValidation MRR: 0.2476\tH@10: 0.3966\tTest MRR: 0.2397\tH@10: 0.3856\n",
            "Epoch: 380\tValidation MRR: 0.2485\tH@10: 0.3960\tTest MRR: 0.2396\tH@10: 0.3873\n",
            "Epoch: 390\tValidation MRR: 0.2485\tH@10: 0.3999\tTest MRR: 0.2397\tH@10: 0.3896\n",
            "Epoch: 400\tValidation MRR: 0.2483\tH@10: 0.3981\tTest MRR: 0.2406\tH@10: 0.3892\n",
            "===========Best GNN==========\n",
            "Validation MRR: 0.24826869368553162\n",
            "Validation H@10: 0.3981180496150556\n",
            "Test MRR: 0.2406429946422577\n",
            "Test H@10: 0.3891820580474934\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "hidden_dim = 128\n",
        "num_gnn_layers = 2\n",
        "seed = 0\n",
        "reg_coeff = 1e-2\n",
        "dropout = 0\n",
        "lr = 0.001\n",
        "feature_augment = \"virtualnode\"\n",
        "\n",
        "val_mrr, val_hits_at_k, test_mrr, test_hits_at_k = use_gnn(seed=seed,\n",
        "                                hidden_dim=hidden_dim,\n",
        "                                num_gnn_layers=num_gnn_layers,\n",
        "                                dropout=dropout,\n",
        "                                lr=lr,\n",
        "                                reg_coeff=reg_coeff,\n",
        "                                feature_augment=feature_augment)\n",
        "\n",
        "print(\"===========Best GNN==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(val_mrr))\n",
        "print(\"Validation H@10: {}\".format(val_hits_at_k))\n",
        "print(\"Test MRR: {}\".format(test_mrr))\n",
        "print(\"Test H@10: {}\".format(test_hits_at_k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffx0zC-gd79t"
      },
      "source": [
        "Release GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKLRoSdpd9gO"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4gUHlLSlypo"
      },
      "source": [
        "## 1.3.4 Contrastive Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEcsYLepl2jF"
      },
      "source": [
        "We have generated pos edge index and neg edge index.\n",
        "\n",
        "Then the graph contrastive learning will look like:\n",
        "1. anchor: RGCN(input_embed, pos_edge_index, edge_type)\n",
        "2. positive: RGCN(one_hot, pos_edge_index, edge_type)\n",
        "3. negative: RGCN(input_embed, neg_edge_index, edge_type)\n",
        "4. loss = TripletLoss()\n",
        "5. loss = loss(anchor, positive, negative)\n",
        "6. loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P04HGQewQBt"
      },
      "source": [
        "CLRGCN: Graph Contrastive Learning with RGCN\n",
        "Where anchor, positive and negative share the same model parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. TransE"
      ],
      "metadata": {
        "id": "35P2e3mv-2Pr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8Bt-9AW3ZKo"
      },
      "outputs": [],
      "source": [
        "def edge_types_to_groups(edge_type, edge_index):\n",
        "    edge_type_min = torch.amin(edge_type).item()\n",
        "    edge_type_max = torch.amax(edge_type).item()\n",
        "    ans = []\n",
        "    edge_type_list = []\n",
        "    for i in range(edge_type_min, edge_type_max + 1):\n",
        "        _edge_type = {}\n",
        "        idx = (edge_type == i).nonzero().squeeze(1)\n",
        "\n",
        "        _edge_index = edge_index[:, idx]\n",
        "        if _edge_index.shape[1] == 0:\n",
        "            continue\n",
        "        else:\n",
        "            edge_type_list.append(i)\n",
        "        _edge_type[i] = _edge_index\n",
        "        ans.append(_edge_type)\n",
        "    return ans, edge_type_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoQfNXG_sZSk"
      },
      "outputs": [],
      "source": [
        "ans, edge_type_max = edge_types_to_groups(train_data.edge_type, train_data.edge_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5DQWcWN8BQq"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "def sample_triplets(type_filtered_index, edge_type_list, sample_size):\n",
        "    anchors = []\n",
        "    positives = []\n",
        "    negatives = []\n",
        "    rel_types = []\n",
        "    for count in range(len(edge_type_list)):\n",
        "        key = next(iter(type_filtered_index[count].keys()))\n",
        "        edge_index =  next(iter(type_filtered_index[count].values()))\n",
        "\n",
        "        len_edge_index = edge_index.shape[1]\n",
        "        for i in range(len_edge_index):\n",
        "            # if edge_index.shape[1] == 1:\n",
        "                # sampled_values = random.sample(range(edge_index.shape[1]), 1) + random.sample(range(edge_index.shape[1]), 1)\n",
        "            # else:\n",
        "            sampled_values = random.sample(range(edge_index.shape[1]), 2)\n",
        "            anchor, positive = edge_index[:, sampled_values][:, 0],  edge_index[:, sampled_values][:, 1]\n",
        "            negative_relation = random.sample(range(len(edge_type_list)), 1) # the index of existing relation\n",
        "\n",
        "            negative_edge_index =  type_filtered_index[negative_relation[0]]\n",
        "            while negative_relation[0] == key:\n",
        "                negative_relation = random.sample(range(len(edge_type_list)), 1)\n",
        "                negative_edge_index = type_filtered_index[negative_relation[0]]\n",
        "\n",
        "\n",
        "            sampled_negative_values = random.sample(range(next(iter(negative_edge_index.values())).shape[1]), 1)\n",
        "            negative = next(iter(negative_edge_index.values()))[:, sampled_negative_values][:, 0]\n",
        "\n",
        "            anchors.append(anchor)\n",
        "            positives.append(positive)\n",
        "            negatives.append(negative)\n",
        "            rel_types.append(count)\n",
        "\n",
        "            if i == int(sample_size * len_edge_index):\n",
        "                break\n",
        "\n",
        "    return anchors, positives, negatives, rel_types\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loxzyKMarDRU"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from torch_geometric.data import Data\n",
        "class CLRGCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout):\n",
        "        super(CLRGCN, self).__init__()\n",
        "\n",
        "        # anchor\n",
        "        self.input_emb = nn.Parameter(torch.empty(input_dim, hidden_dim))\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.input_emb)\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        self.dropout = dropout\n",
        "        for _ in range(num_gnn_layers):\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2,  bias=False))\n",
        "\n",
        "    def forward(self, edge_index, edge_type, anchor, positive, negative, rel_types):\n",
        "\n",
        "        for i, layer in enumerate(self.gnn_layers):\n",
        "          if i == 0:\n",
        "            x = layer(self.input_emb, edge_index, edge_type)\n",
        "          else:\n",
        "            x = layer(x, edge_index, edge_type)\n",
        "\n",
        "          if i < len(self.gnn_layers) - 1:\n",
        "              x = F.relu(x)\n",
        "              # x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        self.embed = x\n",
        "        return x[anchor[:, 0]] + self.rel_emb[rel_types] - x[anchor[:, 1]], x[positive[:, 0]] + self.rel_emb[rel_types] - x[positive[:, 1]], x[negative[:, 0]] + self.rel_emb[rel_types] - x[negative[:, 1]]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_infoNCE(self, eval, gnn_model, sample_size):\n",
        "\n",
        "        ans, edge_type_max  = edge_types_to_groups(eval.edge_type, eval.edge_index)\n",
        "        anchors, positives, negatives, rel_types = sample_triplets(ans, edge_type_max, sample_size)\n",
        "        anchors = torch.stack(anchors, dim=0)\n",
        "        positives = torch.stack(positives, dim=0)\n",
        "        negatives = torch.stack(negatives, dim=0)\n",
        "        anchor, positive, negative = gnn_model(eval.edge_index, eval.edge_type, anchors, positives, negatives)\n",
        "        loss = nn.TripletMarginLoss()\n",
        "        loss = loss(anchor, positive, negative)\n",
        "        return loss\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, epochs, sample_size, train_data, val_data, test_data):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    val_data = val_data.to(\"cuda\")\n",
        "    test_data = test_data.to(\"cuda\")\n",
        "    # model and optimizer\n",
        "\n",
        "    gnn_model = CLRGCN(input_dim=data.num_nodes,\n",
        "                       hidden_dim=hidden_dim,\n",
        "                       num_gnn_layers=num_gnn_layers,\n",
        "                       dropout=dropout).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    # total_edge_index = torch.cat((train_data.edge_index, test_data.edge_index, val_data.edge_index), dim=1)\n",
        "    # total_edge_types = torch.cat((train_data.edge_type, test_data.edge_type, val_data.edge_type), dim=0)\n",
        "\n",
        "    total_edge_index = train_data.edge_index\n",
        "    total_edge_types = train_data.edge_type\n",
        "\n",
        "    ans, edge_type_max  = edge_types_to_groups(total_edge_types, total_edge_index)\n",
        "\n",
        "    # train\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "        anchors, positives, negatives, rel_types = sample_triplets(ans, edge_type_max, sample_size)\n",
        "        anchors = torch.stack(anchors, dim=0).to(\"cuda\")\n",
        "        positives = torch.stack(positives, dim=0).to(\"cuda\")\n",
        "        negatives = torch.stack(negatives, dim=0).to(\"cuda\")\n",
        "\n",
        "        # contrastive loss: Tripletloss\n",
        "        anchor, positive, negative = gnn_model(total_edge_index, total_edge_types, anchors, positives, negatives, rel_types)\n",
        "\n",
        "        loss = nn.TripletMarginLoss()\n",
        "        loss = loss(anchor, positive, negative)\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "    return val_mrr, val_hits_at_k, test_mrr, test_hits_at_k, anchor, positive, negative, gnn_model.embed, gnn_model.rel_emb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhWanDTz9vdu"
      },
      "source": [
        "1. Train Encoder with Triplet loss\n",
        "2. Fix the encoder and extract anchor embedding as node embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6J2DG3t9utm",
        "outputId": "fde13010-cf0e-40ad-9690-31a3c8db842e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/120 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9168, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/120 [01:01<2:01:32, 61.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4096, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/120 [02:01<1:58:51, 60.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2425, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▎         | 3/120 [02:59<1:55:34, 59.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1731, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 4/120 [03:59<1:55:51, 59.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 5/120 [04:58<1:53:45, 59.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1207, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 6/120 [06:03<1:56:14, 61.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1049, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 7/120 [07:02<1:54:08, 60.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0896, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 8/120 [08:01<1:52:28, 60.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0790, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 9/120 [09:00<1:50:24, 59.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0733, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 10/120 [09:58<1:48:49, 59.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0650, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 11/120 [10:58<1:47:40, 59.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0589, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 12/120 [11:56<1:46:14, 59.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0554, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 13/120 [12:55<1:45:17, 59.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0522, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 14/120 [13:54<1:44:09, 58.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0491, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▎        | 15/120 [14:53<1:43:30, 59.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0470, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 16/120 [15:53<1:42:29, 59.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 17/120 [16:51<1:40:55, 58.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0426, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 18/120 [17:51<1:40:47, 59.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0411, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 19/120 [18:50<1:39:30, 59.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0399, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 20/120 [19:49<1:38:30, 59.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0387, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 21/120 [20:47<1:37:16, 58.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0368, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 22/120 [21:46<1:36:05, 58.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0367, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 23/120 [22:46<1:35:29, 59.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0356, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 24/120 [23:44<1:34:21, 58.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0335, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 25/120 [24:44<1:33:37, 59.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0330, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 26/120 [25:43<1:32:32, 59.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0326, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▎       | 27/120 [26:41<1:31:16, 58.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0320, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 28/120 [27:41<1:30:30, 59.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0314, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 29/120 [28:39<1:29:05, 58.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0308, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 30/120 [29:37<1:28:03, 58.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0300, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 31/120 [30:36<1:26:57, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0296, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 32/120 [31:34<1:25:41, 58.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 33/120 [32:32<1:24:45, 58.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0294, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 34/120 [33:31<1:23:46, 58.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0285, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 35/120 [34:29<1:22:45, 58.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 36/120 [35:28<1:22:03, 58.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0270, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 37/120 [36:26<1:20:48, 58.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0281, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 38/120 [37:24<1:19:45, 58.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0267, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▎      | 39/120 [38:23<1:19:05, 58.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0270, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 40/120 [39:21<1:17:55, 58.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 41/120 [40:21<1:17:14, 58.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0257, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 42/120 [41:19<1:16:09, 58.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0256, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 43/120 [42:18<1:15:12, 58.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0263, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 44/120 [43:17<1:14:22, 58.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0258, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 45/120 [44:15<1:13:14, 58.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0247, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 46/120 [45:14<1:12:18, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0251, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 47/120 [46:12<1:11:20, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 48/120 [47:11<1:10:21, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 49/120 [48:11<1:09:48, 59.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0243, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 50/120 [49:09<1:08:39, 58.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0237, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▎     | 51/120 [50:08<1:07:44, 58.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 52/120 [51:07<1:06:40, 58.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0238, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 53/120 [52:06<1:05:44, 58.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 54/120 [53:05<1:04:51, 58.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0244, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 55/120 [54:03<1:03:34, 58.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 56/120 [55:02<1:02:41, 58.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 57/120 [56:01<1:01:46, 58.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0235, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 58/120 [57:00<1:00:45, 58.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0239, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 59/120 [57:59<59:56, 58.95s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0234, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 60/120 [58:58<58:48, 58.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0229, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 61/120 [59:56<57:43, 58.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 62/120 [1:00:55<56:51, 58.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0229, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▎    | 63/120 [1:01:54<55:50, 58.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0233, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 64/120 [1:02:53<54:55, 58.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0231, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 65/120 [1:03:51<53:50, 58.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0230, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 66/120 [1:04:49<52:43, 58.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 67/120 [1:05:49<51:56, 58.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 68/120 [1:06:47<50:50, 58.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0222, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▊    | 69/120 [1:07:46<49:56, 58.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0220, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 70/120 [1:08:45<48:59, 58.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0224, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 71/120 [1:09:43<47:51, 58.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0223, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 72/120 [1:10:42<46:51, 58.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0226, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 73/120 [1:11:40<45:55, 58.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0218, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 74/120 [1:12:39<45:02, 58.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▎   | 75/120 [1:13:38<43:58, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 76/120 [1:14:36<42:50, 58.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 77/120 [1:15:35<42:00, 58.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 78/120 [1:16:33<41:02, 58.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 79/120 [1:17:33<40:12, 58.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0214, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 80/120 [1:18:32<39:18, 58.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 81/120 [1:19:31<38:15, 58.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 82/120 [1:20:30<37:21, 59.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 83/120 [1:21:29<36:18, 58.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 84/120 [1:22:27<35:15, 58.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 85/120 [1:23:26<34:14, 58.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 86/120 [1:24:24<33:13, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▎  | 87/120 [1:25:23<32:17, 58.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0212, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 88/120 [1:26:21<31:15, 58.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 89/120 [1:27:20<30:15, 58.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0209, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 90/120 [1:28:19<29:21, 58.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 91/120 [1:29:17<28:20, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 92/120 [1:30:17<27:27, 58.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 93/120 [1:31:15<26:24, 58.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 94/120 [1:32:13<25:24, 58.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 95/120 [1:33:12<24:28, 58.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 96/120 [1:34:11<23:27, 58.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0208, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 97/120 [1:35:09<22:27, 58.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0204, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 98/120 [1:36:09<21:33, 58.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▎ | 99/120 [1:37:07<20:32, 58.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 100/120 [1:38:06<19:32, 58.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0211, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 101/120 [1:39:04<18:33, 58.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 102/120 [1:40:02<17:32, 58.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 103/120 [1:41:01<16:36, 58.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 104/120 [1:41:59<15:33, 58.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0210, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 105/120 [1:42:59<14:44, 58.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 106/120 [1:44:14<14:50, 63.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 107/120 [1:45:21<13:59, 64.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0204, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 108/120 [1:46:32<13:21, 66.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0207, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 109/120 [1:47:48<12:43, 69.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 110/120 [1:49:07<12:01, 72.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0206, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▎| 111/120 [1:50:17<10:43, 71.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 112/120 [1:51:15<09:01, 67.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 113/120 [1:52:15<07:36, 65.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0200, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 114/120 [1:53:54<07:32, 75.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0202, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 115/120 [1:54:53<05:52, 70.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0203, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 116/120 [1:55:54<04:29, 67.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0198, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 117/120 [1:56:52<03:14, 64.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 118/120 [1:57:58<02:10, 65.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 119/120 [1:58:59<01:03, 63.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [1:59:57<00:00, 59.98s/it]\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "hidden_dim = 64\n",
        "num_gnn_layers = 2\n",
        "seed = 0\n",
        "dropout = 0.2\n",
        "lr = 0.01\n",
        "epochs = 120\n",
        "sample_size = 1\n",
        "val_mrr, val_hits_at_k, test_mrr, test_hits_at_k, anchor, positive, negative, gnn_pretrain_embed, gnn_rel_embed = use_gnn(seed=seed, hidden_dim=hidden_dim,\n",
        "                                                          num_gnn_layers=num_gnn_layers,\n",
        "                                                          dropout=dropout,\n",
        "                                                          lr=lr,\n",
        "                                                          epochs = epochs,\n",
        "                                                          sample_size = sample_size,\n",
        "                                                          train_data = train_data,\n",
        "                                                          val_data = val_data,\n",
        "                                                          test_data = test_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triplet loss vs. epochs"
      ],
      "metadata": {
        "id": "KiykzyaaXS6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "triplet_loss = [0.9168, 0.4096, 0.2425, 0.1731, 0.1389, 0.1207,\n",
        "         0.1049, 0.0896, 0.0790, 0.0733, 0.0650, 0.0589,\n",
        "         0.0554, 0.0522, 0.0491, 0.0470, 0.0439, 0.0426,\n",
        "         0.0411, 0.0399, 0.0387, 0.0368, 0.0367, 0.0356,\n",
        "         0.0335, 0.0330, 0.0326, 0.0320, 0.0314, 0.0308,\n",
        "         0.0300, 0.0296, 0.0294, 0.0294, 0.0285, 0.0281,\n",
        "         0.0270, 0.0281, 0.0267, 0.0270, 0.0263, 0.0257,\n",
        "         0.0256, 0.0263, 0.0258, 0.0247, 0.0251, 0.0239,\n",
        "         0.0239, 0.0243, 0.0237, 0.0248, 0.0238, 0.0239,\n",
        "         0.0244, 0.0234, 0.0233, 0.0235, 0.0239, 0.0234,\n",
        "         0.0229, 0.224]\n",
        "\n",
        "print_epochs = range(0, len(triplet_loss))\n",
        "plt.plot(print_epochs, triplet_loss)\n",
        "plt.xlabel(\"epochs\", fontsize = 10)\n",
        "plt.ylabel(\"triplet_loss\", fontsize = 10)\n",
        "plt.title(\"Triplet losss vs. epochs\")\n",
        "plt.savefig(\"triplet_loss.eps\", dpi = 300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tfWLKCZMT9tJ",
        "outputId": "b4755d97-fe0b-4f80-b925-53d38a9ac8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovnBP3Iw-F7B"
      },
      "source": [
        "Release GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpuaLYGk-IUn"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV33ZWIlIGrL"
      },
      "source": [
        "Set node features with anchor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z81FkhG_rBHH"
      },
      "outputs": [],
      "source": [
        "data.x = gnn_pretrain_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyyTEOXtiTKm"
      },
      "outputs": [],
      "source": [
        "data.x = data.x.detach()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_rel_embed = gnn_rel_embed.detach()"
      ],
      "metadata": {
        "id": "Irzkh7Hk-gND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TransE with rel"
      ],
      "metadata": {
        "id": "satjkdz0AN9i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug9D8IW_rC7B"
      },
      "outputs": [],
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "class GNNPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout):\n",
        "        super(GNNPredictor, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def decoder(self, head_idx, rel_type, tail_idx):\n",
        "        self.node_emb = F.relu(self.lin(data.x))\n",
        "        # self.node_emb = data.x\n",
        "        head = self.node_emb[head_idx]\n",
        "        tail = self.node_emb[tail_idx]\n",
        "        rel = self.rel_emb[rel_type]\n",
        "        head = F.normalize(head, p=1, dim=1)\n",
        "        tail = F.normalize(tail, p=1, dim=1)\n",
        "        return -((head + rel) - tail).norm(p=1, dim=1).view(-1,1)\n",
        "        # return torch.sum(head * rel * tail, dim=1)\n",
        "    def forward(self, pos_edge_index, neg_edge_index, edge_type):\n",
        "        return self.decoder(pos_edge_index[0], edge_type, pos_edge_index[1]), self.decoder(neg_edge_index[0], edge_type, neg_edge_index[1])\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_metrics(self, eval_data, k=10):\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/torch_geometric/nn/kge/base.py\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/examples/kge_fb15k_237.py\n",
        "        head_idx, rel_type, tail_idx = eval_data.edge_index[0].to(\"cuda\"), eval_data.edge_type.to(\"cuda\"), eval_data.edge_index[1].to(\"cuda\")\n",
        "\n",
        "        reciprocal_ranks, hits_at_k = [], []\n",
        "        for i in range(rel_type.shape[0]):\n",
        "            h, r, t = head_idx[i], rel_type[i], tail_idx[i]\n",
        "            all_tails = torch.arange(data.num_nodes, device=\"cuda\")\n",
        "            scores = self.decoder(h.expand_as(all_tails), r.expand_as(all_tails), all_tails).view(-1)\n",
        "            rank = int((scores.argsort(descending=True) == t).nonzero().view(-1))\n",
        "            reciprocal_ranks.append(1 / (rank + 1))\n",
        "            hits_at_k.append(rank < k)\n",
        "\n",
        "        mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "        hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "        return mrr, hits_at_k\n",
        "\n",
        "# negative sampling\n",
        "def process_data(train_data):\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    mask_1 = torch.rand(train_data.edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = train_data.edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(train_data.num_nodes, (mask_1.sum(),), device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(train_data.num_nodes, (mask_2.sum(),), device=neg_edge_index.device)\n",
        "    return train_data.edge_index, neg_edge_index\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, reg_coeff):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = GNNPredictor(input_dim=data.num_nodes,\n",
        "                             hidden_dim=hidden_dim,\n",
        "                             num_gnn_layers=num_gnn_layers,\n",
        "                             dropout=dropout).to(\"cuda\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    # train\n",
        "    best_val_mrr = 0\n",
        "    best_val_hits = 0\n",
        "    best_test_mrr = 0\n",
        "    best_test_hits = 0\n",
        "    for epoch in range(400):\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # data\n",
        "        pos_edge_index, neg_edge_index = process_data(train_data)\n",
        "\n",
        "        # loss\n",
        "        pos_edge_pred, neg_edge_pred = gnn_model(pos_edge_index, neg_edge_index, train_data.edge_type)\n",
        "\n",
        "\n",
        "        out = torch.cat([pos_edge_pred, neg_edge_pred])\n",
        "        gt = torch.cat([torch.ones_like(pos_edge_pred), torch.zeros_like(neg_edge_pred)])\n",
        "        loss = F.binary_cross_entropy_with_logits(out, gt)\n",
        "\n",
        "        # loss = F.margin_ranking_loss(pos_edge_pred, neg_edge_pred, target=torch.ones_like(pos_edge_pred), margin=1)\n",
        "        reg_loss = gnn_model.node_emb.pow(2).mean() +  gnn_model.rel_emb.pow(2).mean()\n",
        "        loss = loss + reg_coeff * reg_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            gnn_model.eval()\n",
        "            val_mrr, val_hits_at_k = gnn_model.eval_metrics(val_data)\n",
        "            test_mrr, test_hits_at_k = gnn_model.eval_metrics(test_data)\n",
        "            print(\"Epoch: {}\\tValidation MRR: {:.4f}\\tH@10: {:.4f}\\tTest MRR: {:.4f}\\tH@10: {:.4f}\".format(epoch + 1, val_mrr, val_hits_at_k, test_mrr, test_hits_at_k))\n",
        "\n",
        "            if val_hits_at_k > best_val_hits:\n",
        "                best_val_mrr = val_mrr\n",
        "                best_val_hits = val_hits_at_k\n",
        "                best_test_mrr = test_mrr\n",
        "                best_test_hits = test_hits_at_k\n",
        "\n",
        "    return best_val_mrr, best_val_hits, best_test_mrr, best_test_hits\n",
        "\n",
        "# example of running with fixed parameters\n",
        "hidden_dim = 64\n",
        "num_gnn_layers = 2\n",
        "seed_list = [14504]\n",
        "reg_coeff = 1e-2\n",
        "dropout = 0\n",
        "lr = 0.01\n",
        "\n",
        "\n",
        "num_runs = len(seed_list)\n",
        "for run in range(num_runs):\n",
        "    print(\"### Run: {}\".format(run + 1))\n",
        "    best_val_mrr, best_val_hits, best_test_mrr, best_test_hits = use_gnn(seed=seed_list[run],\n",
        "                                                                         hidden_dim=hidden_dim,\n",
        "                                                                         num_gnn_layers=num_gnn_layers,\n",
        "                                                                         dropout=dropout,\n",
        "                                                                         lr=lr,\n",
        "                                                                         reg_coeff=reg_coeff)\n",
        "\n",
        "print(\"===========Best Results==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(best_val_mrr))\n",
        "print(\"Validation H@10: {}\".format(best_val_hits))\n",
        "print(\"Test MRR: {}\".format(best_test_mrr))\n",
        "print(\"Test H@10: {}\".format(best_test_hits))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. DistMult with rel"
      ],
      "metadata": {
        "id": "xWg5lhCM_SVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch_geometric.data import Data\n",
        "class CLRGCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout):\n",
        "        super(CLRGCN, self).__init__()\n",
        "\n",
        "        # anchor\n",
        "        self.input_emb = nn.Parameter(torch.empty(input_dim, hidden_dim))\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.input_emb)\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.gnn_layers = nn.ModuleList()\n",
        "        self.dropout = dropout\n",
        "        for _ in range(num_gnn_layers):\n",
        "            self.gnn_layers.append(pyg_nn.RGCNConv(hidden_dim, hidden_dim, dataset.num_relations*2,  bias=False))\n",
        "\n",
        "    def forward(self, edge_index, edge_type, anchor, positive, negative, rel_types):\n",
        "\n",
        "        for i, layer in enumerate(self.gnn_layers):\n",
        "          if i == 0:\n",
        "            x = layer(self.input_emb, edge_index, edge_type)\n",
        "          else:\n",
        "            x = layer(x, edge_index, edge_type)\n",
        "\n",
        "          if i < len(self.gnn_layers) - 1:\n",
        "              x = F.relu(x)\n",
        "              # x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        self.embed = x\n",
        "        return x[anchor[:, 0]] * self.rel_emb[rel_types] * x[anchor[:, 1]], x[positive[:, 0]] * self.rel_emb[rel_types] * x[positive[:, 1]], x[negative[:, 0]] * self.rel_emb[rel_types] * x[negative[:, 1]]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_infoNCE(self, eval, gnn_model, sample_size):\n",
        "\n",
        "        ans, edge_type_max  = edge_types_to_groups(eval.edge_type, eval.edge_index)\n",
        "        anchors, positives, negatives, rel_types = sample_triplets(ans, edge_type_max, sample_size)\n",
        "        anchors = torch.stack(anchors, dim=0)\n",
        "        positives = torch.stack(positives, dim=0)\n",
        "        negatives = torch.stack(negatives, dim=0)\n",
        "        anchor, positive, negative = gnn_model(eval.edge_index, eval.edge_type, anchors, positives, negatives)\n",
        "        loss = nn.TripletMarginLoss()\n",
        "        loss = loss(anchor, positive, negative)\n",
        "        return loss\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, epochs, sample_size, train_data, val_data, test_data):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    val_data = val_data.to(\"cuda\")\n",
        "    test_data = test_data.to(\"cuda\")\n",
        "\n",
        "    gnn_model = CLRGCN(input_dim=data.num_nodes,\n",
        "                       hidden_dim=hidden_dim,\n",
        "                       num_gnn_layers=num_gnn_layers,\n",
        "                       dropout=dropout).to(\"cuda\")\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    total_edge_index = train_data.edge_index\n",
        "    total_edge_types = train_data.edge_type\n",
        "\n",
        "    ans, edge_type_max  = edge_types_to_groups(total_edge_types, total_edge_index)\n",
        "\n",
        "    # train\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "        anchors, positives, negatives, rel_types = sample_triplets(ans, edge_type_max, sample_size)\n",
        "        anchors = torch.stack(anchors, dim=0).to(\"cuda\")\n",
        "        positives = torch.stack(positives, dim=0).to(\"cuda\")\n",
        "        negatives = torch.stack(negatives, dim=0).to(\"cuda\")\n",
        "\n",
        "        # contrastive loss: Tripletloss\n",
        "        anchor, positive, negative = gnn_model(total_edge_index, total_edge_types, anchors, positives, negatives, rel_types)\n",
        "\n",
        "        loss = nn.TripletMarginLoss()\n",
        "        loss = loss(anchor, positive, negative)\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "    return val_mrr, val_hits_at_k, test_mrr, test_hits_at_k, anchor, positive, negative, gnn_model.embed, gnn_model.rel_emb"
      ],
      "metadata": {
        "id": "Zvc90Dn__Rrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "hidden_dim = 64\n",
        "num_gnn_layers = 2\n",
        "seed = 0\n",
        "dropout = 0.2\n",
        "lr = 0.01\n",
        "epochs = 100\n",
        "sample_size = 1\n",
        "val_mrr, val_hits_at_k, test_mrr, test_hits_at_k, anchor, positive, negative, gnn_pretrain_embed, gnn_rel_embed = use_gnn(seed=seed, hidden_dim=hidden_dim,\n",
        "                                                          num_gnn_layers=num_gnn_layers,\n",
        "                                                          dropout=dropout,\n",
        "                                                          lr=lr,\n",
        "                                                          epochs = epochs,\n",
        "                                                          sample_size = sample_size,\n",
        "                                                          train_data = train_data,\n",
        "                                                          val_data = val_data,\n",
        "                                                          test_data = test_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WHP1OmBrfvg",
        "outputId": "ed5a5161-8e80-4875-910b-4e87b854185c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9998, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 1/100 [00:58<1:36:46, 58.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9677, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 2/100 [02:01<1:39:46, 61.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 3/100 [03:00<1:37:19, 60.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 4/100 [03:59<1:35:27, 59.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.4668, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 5/100 [05:04<1:37:21, 61.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.3127, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 6/100 [06:03<1:35:00, 60.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.2355, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 7/100 [07:03<1:33:39, 60.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1889, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 8/100 [08:01<1:31:34, 59.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1427, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 9/100 [09:00<1:30:26, 59.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1154, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 10/100 [09:59<1:29:00, 59.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0940, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█         | 11/100 [10:58<1:27:50, 59.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0796, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 12/100 [11:58<1:27:05, 59.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0656, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 13/100 [12:57<1:26:06, 59.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0548, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 14/100 [13:57<1:25:08, 59.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0483, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 15/100 [14:55<1:23:57, 59.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0427, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 16/100 [15:55<1:23:07, 59.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0393, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 17/100 [16:54<1:21:56, 59.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0359, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 18/100 [17:54<1:21:08, 59.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0340, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 19%|█▉        | 19/100 [18:53<1:19:59, 59.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0303, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 20/100 [19:52<1:19:04, 59.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0279, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 21/100 [20:51<1:18:04, 59.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0260, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 22/100 [21:50<1:17:01, 59.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 23/100 [22:51<1:16:19, 59.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0219, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 24/100 [23:50<1:15:15, 59.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0205, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 25/100 [24:50<1:14:25, 59.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0197, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 26/100 [25:49<1:13:20, 59.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 27/100 [26:49<1:12:30, 59.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 28/100 [27:48<1:11:19, 59.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0168, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 29%|██▉       | 29/100 [28:48<1:10:26, 59.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0160, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 30/100 [29:47<1:09:21, 59.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0164, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 31/100 [30:46<1:08:25, 59.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0163, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 32/100 [31:46<1:07:15, 59.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0146, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 33/100 [32:45<1:06:29, 59.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0148, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 34/100 [33:45<1:05:26, 59.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0143, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 35/100 [34:45<1:04:36, 59.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0142, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 36/100 [35:44<1:03:25, 59.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0137, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 37/100 [36:44<1:02:33, 59.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0126, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 38/100 [37:43<1:01:21, 59.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 39/100 [38:52<1:03:30, 62.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0124, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 40/100 [40:00<1:03:56, 63.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 41/100 [41:00<1:01:44, 62.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 42/100 [42:00<59:49, 61.89s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 43%|████▎     | 43/100 [43:00<58:19, 61.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0111, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 44/100 [43:59<56:46, 60.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0115, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 45/100 [44:59<55:32, 60.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 46/100 [45:58<54:06, 60.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 47%|████▋     | 47/100 [46:58<52:59, 60.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0108, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 48/100 [47:57<51:48, 59.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0106, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 49/100 [48:57<50:44, 59.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 50/100 [49:56<49:43, 59.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0107, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 51/100 [50:56<48:36, 59.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0102, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 52/100 [51:55<47:39, 59.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 53%|█████▎    | 53/100 [52:55<46:34, 59.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0101, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 54/100 [53:54<45:39, 59.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0099, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▌    | 55/100 [54:54<44:37, 59.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0097, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▌    | 56/100 [55:53<43:41, 59.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0098, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 57%|█████▋    | 57/100 [56:53<42:38, 59.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 58/100 [57:53<41:49, 59.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0096, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 59/100 [58:53<40:47, 59.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0091, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 60/100 [59:52<39:47, 59.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 61/100 [1:00:52<38:42, 59.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0094, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 62/100 [1:01:51<37:41, 59.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 63/100 [1:02:50<36:41, 59.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 64%|██████▍   | 64/100 [1:03:50<35:45, 59.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0090, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▌   | 65/100 [1:04:49<34:41, 59.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 66/100 [1:05:49<33:47, 59.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0088, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 67/100 [1:06:49<32:44, 59.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 68/100 [1:07:49<31:49, 59.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0089, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 69/100 [1:08:48<30:45, 59.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 70/100 [1:09:48<29:49, 59.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0092, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 71%|███████   | 71/100 [1:10:47<28:47, 59.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0087, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 72/100 [1:11:47<27:46, 59.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 73/100 [1:12:47<26:56, 59.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0085, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 74%|███████▍  | 74/100 [1:13:47<25:56, 59.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 75/100 [1:14:47<24:57, 59.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 76/100 [1:15:47<23:56, 59.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 77/100 [1:16:47<22:55, 59.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0083, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 78%|███████▊  | 78/100 [1:17:46<21:51, 59.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0086, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 79/100 [1:18:46<20:54, 59.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 80/100 [1:19:45<19:50, 59.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 81%|████████  | 81/100 [1:20:45<18:53, 59.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 82/100 [1:21:44<17:51, 59.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0080, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 83/100 [1:22:44<16:55, 59.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 84%|████████▍ | 84/100 [1:23:44<15:53, 59.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0081, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▌ | 85/100 [1:24:44<14:56, 59.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0084, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 86/100 [1:25:43<13:56, 59.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 87/100 [1:26:43<12:55, 59.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 88%|████████▊ | 88/100 [1:27:42<11:54, 59.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0082, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▉ | 89/100 [1:28:42<10:55, 59.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0079, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 90/100 [1:29:41<09:54, 59.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 91%|█████████ | 91/100 [1:30:41<08:56, 59.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 92/100 [1:31:40<07:56, 59.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 93/100 [1:32:41<06:58, 59.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0077, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 94/100 [1:33:40<05:58, 59.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0078, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 95%|█████████▌| 95/100 [1:34:40<04:58, 59.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 96/100 [1:35:39<03:58, 59.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 97/100 [1:36:40<02:59, 59.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0073, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 98%|█████████▊| 98/100 [1:37:38<01:59, 59.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▉| 99/100 [1:38:38<00:59, 59.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0074, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [1:39:38<00:00, 59.78s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Release GPU"
      ],
      "metadata": {
        "id": "bZsml2Q9EYIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect() # Python thing\n",
        "# torch.cuda.empty_cache() # PyTorch thing\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "4B077A5PEXjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x = gnn_pretrain_embed"
      ],
      "metadata": {
        "id": "KCE3xcErSdUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.x = data.x.detach()"
      ],
      "metadata": {
        "id": "QxxCabUkSgcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gnn_rel_embed = gnn_rel_embed.detach()"
      ],
      "metadata": {
        "id": "JtVUEWreSi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " TransE Decoder"
      ],
      "metadata": {
        "id": "DdDVZRMsENca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "class GNNPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout):\n",
        "        super(GNNPredictor, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def decoder(self, head_idx, rel_type, tail_idx):\n",
        "        self.node_emb = F.relu(self.lin(data.x))\n",
        "        # self.node_emb = data.x\n",
        "        head = self.node_emb[head_idx]\n",
        "        tail = self.node_emb[tail_idx]\n",
        "        rel = self.rel_emb[rel_type]\n",
        "        head = F.normalize(head, p=1, dim=1)\n",
        "        tail = F.normalize(tail, p=1, dim=1)\n",
        "        return -((head + rel) - tail).norm(p=1, dim=1).view(-1,1)\n",
        "        # return torch.sum(head * rel * tail, dim=1)\n",
        "    def forward(self, pos_edge_index, neg_edge_index, edge_type):\n",
        "        return self.decoder(pos_edge_index[0], edge_type, pos_edge_index[1]), self.decoder(neg_edge_index[0], edge_type, neg_edge_index[1])\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_metrics(self, eval_data, k=10):\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/torch_geometric/nn/kge/base.py\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/examples/kge_fb15k_237.py\n",
        "        head_idx, rel_type, tail_idx = eval_data.edge_index[0].to(\"cuda\"), eval_data.edge_type.to(\"cuda\"), eval_data.edge_index[1].to(\"cuda\")\n",
        "\n",
        "        reciprocal_ranks, hits_at_k = [], []\n",
        "        for i in range(rel_type.shape[0]):\n",
        "            h, r, t = head_idx[i], rel_type[i], tail_idx[i]\n",
        "            all_tails = torch.arange(data.num_nodes, device=\"cuda\")\n",
        "            scores = self.decoder(h.expand_as(all_tails), r.expand_as(all_tails), all_tails).view(-1)\n",
        "            rank = int((scores.argsort(descending=True) == t).nonzero().view(-1))\n",
        "            reciprocal_ranks.append(1 / (rank + 1))\n",
        "            hits_at_k.append(rank < k)\n",
        "\n",
        "        mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "        hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "        return mrr, hits_at_k\n",
        "\n",
        "# negative sampling\n",
        "def process_data(train_data):\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    mask_1 = torch.rand(train_data.edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = train_data.edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(train_data.num_nodes, (mask_1.sum(),), device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(train_data.num_nodes, (mask_2.sum(),), device=neg_edge_index.device)\n",
        "    return train_data.edge_index, neg_edge_index\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, reg_coeff):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = GNNPredictor(input_dim=data.num_nodes,\n",
        "                             hidden_dim=hidden_dim,\n",
        "                             num_gnn_layers=num_gnn_layers,\n",
        "                             dropout=dropout).to(\"cuda\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    # train\n",
        "    best_val_mrr = 0\n",
        "    best_val_hits = 0\n",
        "    best_test_mrr = 0\n",
        "    best_test_hits = 0\n",
        "    for epoch in range(400):\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # data\n",
        "        pos_edge_index, neg_edge_index = process_data(train_data)\n",
        "\n",
        "        # loss\n",
        "        pos_edge_pred, neg_edge_pred = gnn_model(pos_edge_index, neg_edge_index, train_data.edge_type)\n",
        "\n",
        "\n",
        "        out = torch.cat([pos_edge_pred, neg_edge_pred])\n",
        "        gt = torch.cat([torch.ones_like(pos_edge_pred), torch.zeros_like(neg_edge_pred)])\n",
        "        loss = F.binary_cross_entropy_with_logits(out, gt)\n",
        "\n",
        "        # loss = F.margin_ranking_loss(pos_edge_pred, neg_edge_pred, target=torch.ones_like(pos_edge_pred), margin=1)\n",
        "        reg_loss = gnn_model.node_emb.pow(2).mean() +  gnn_model.rel_emb.pow(2).mean()\n",
        "        loss = loss + reg_coeff * reg_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            gnn_model.eval()\n",
        "            val_mrr, val_hits_at_k = gnn_model.eval_metrics(val_data)\n",
        "            test_mrr, test_hits_at_k = gnn_model.eval_metrics(test_data)\n",
        "            print(\"Epoch: {}\\tValidation MRR: {:.4f}\\tH@10: {:.4f}\\tTest MRR: {:.4f}\\tH@10: {:.4f}\".format(epoch + 1, val_mrr, val_hits_at_k, test_mrr, test_hits_at_k))\n",
        "\n",
        "            if val_hits_at_k > best_val_hits:\n",
        "                best_val_mrr = val_mrr\n",
        "                best_val_hits = val_hits_at_k\n",
        "                best_test_mrr = test_mrr\n",
        "                best_test_hits = test_hits_at_k\n",
        "\n",
        "    return best_val_mrr, best_val_hits, best_test_mrr, best_test_hits\n",
        "\n",
        "# example of running with fixed parameters\n",
        "hidden_dim = 64\n",
        "num_gnn_layers = 2\n",
        "seed_list = [14504]\n",
        "reg_coeff = 1e-2\n",
        "dropout = 0\n",
        "lr = 0.01\n",
        "\n",
        "\n",
        "num_runs = len(seed_list)\n",
        "for run in range(num_runs):\n",
        "    print(\"### Run: {}\".format(run + 1))\n",
        "    best_val_mrr, best_val_hits, best_test_mrr, best_test_hits = use_gnn(seed=seed_list[run],\n",
        "                                                                         hidden_dim=hidden_dim,\n",
        "                                                                         num_gnn_layers=num_gnn_layers,\n",
        "                                                                         dropout=dropout,\n",
        "                                                                         lr=lr,\n",
        "                                                                         reg_coeff=reg_coeff)\n",
        "\n",
        "print(\"===========Best Results==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(best_val_mrr))\n",
        "print(\"Validation H@10: {}\".format(best_val_hits))\n",
        "print(\"Test MRR: {}\".format(best_test_mrr))\n",
        "print(\"Test H@10: {}\".format(best_test_hits))"
      ],
      "metadata": {
        "id": "1_oU_bokELAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DistMult Decoder"
      ],
      "metadata": {
        "id": "t7sLcNdEWjVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.init as init\n",
        "\n",
        "class GNNPredictor(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_gnn_layers, dropout):\n",
        "        super(GNNPredictor, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.rel_emb = nn.Parameter(torch.empty(dataset.num_relations, hidden_dim))\n",
        "        init.xavier_uniform_(self.rel_emb)\n",
        "        self.lin = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "    def decoder(self, head_idx, rel_type, tail_idx):\n",
        "        self.node_emb = F.relu(self.lin(data.x))\n",
        "        # self.node_emb = data.x\n",
        "        head = self.node_emb[head_idx]\n",
        "        tail = self.node_emb[tail_idx]\n",
        "        rel = self.rel_emb[rel_type]\n",
        "        # head = F.normalize(head, p=1, dim=1)\n",
        "        # tail = F.normalize(tail, p=1, dim=1)\n",
        "        # return -((head + rel) - tail).norm(p=1, dim=1).view(-1,1)\n",
        "        return torch.sum(head * rel * tail, dim=1)\n",
        "    def forward(self, pos_edge_index, neg_edge_index, edge_type):\n",
        "        return self.decoder(pos_edge_index[0], edge_type, pos_edge_index[1]), self.decoder(neg_edge_index[0], edge_type, neg_edge_index[1])\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def eval_metrics(self, eval_data, k=10):\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/torch_geometric/nn/kge/base.py\n",
        "        # https://github.com/pyg-team/pytorch_geometric/blob/ea2ab705716f02396b074cb1c6175b9224a3bf79/examples/kge_fb15k_237.py\n",
        "        head_idx, rel_type, tail_idx = eval_data.edge_index[0].to(\"cuda\"), eval_data.edge_type.to(\"cuda\"), eval_data.edge_index[1].to(\"cuda\")\n",
        "\n",
        "        reciprocal_ranks, hits_at_k = [], []\n",
        "        for i in range(rel_type.shape[0]):\n",
        "            h, r, t = head_idx[i], rel_type[i], tail_idx[i]\n",
        "            all_tails = torch.arange(data.num_nodes, device=\"cuda\")\n",
        "            scores = self.decoder(h.expand_as(all_tails), r.expand_as(all_tails), all_tails).view(-1)\n",
        "            rank = int((scores.argsort(descending=True) == t).nonzero().view(-1))\n",
        "            reciprocal_ranks.append(1 / (rank + 1))\n",
        "            hits_at_k.append(rank < k)\n",
        "\n",
        "        mrr = float(torch.tensor(reciprocal_ranks, dtype=torch.float).mean())\n",
        "        hits_at_k = int(torch.tensor(hits_at_k).sum()) / len(hits_at_k)\n",
        "        return mrr, hits_at_k\n",
        "\n",
        "# negative sampling\n",
        "def process_data(train_data):\n",
        "    train_data = train_data.to(\"cuda\")\n",
        "    mask_1 = torch.rand(train_data.edge_index.size(1)) < 0.5\n",
        "    mask_2 = ~mask_1\n",
        "\n",
        "    neg_edge_index = train_data.edge_index.clone()\n",
        "    neg_edge_index[0, mask_1] = torch.randint(train_data.num_nodes, (mask_1.sum(),), device=neg_edge_index.device)\n",
        "    neg_edge_index[1, mask_2] = torch.randint(train_data.num_nodes, (mask_2.sum(),), device=neg_edge_index.device)\n",
        "    return train_data.edge_index, neg_edge_index\n",
        "\n",
        "def use_gnn(seed, hidden_dim, num_gnn_layers, dropout, lr, reg_coeff):\n",
        "    # seed\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # model and optimizer\n",
        "    gnn_model = GNNPredictor(input_dim=data.num_nodes,\n",
        "                             hidden_dim=hidden_dim,\n",
        "                             num_gnn_layers=num_gnn_layers,\n",
        "                             dropout=dropout).to(\"cuda\")\n",
        "\n",
        "    optimizer = torch.optim.Adam(gnn_model.parameters(), lr=lr)\n",
        "    val_mrr, val_hits_at_k = 0, 0\n",
        "    test_mrr, test_hits_at_k = 0, 0\n",
        "\n",
        "    # train\n",
        "    best_val_mrr = 0\n",
        "    best_val_hits = 0\n",
        "    best_test_mrr = 0\n",
        "    best_test_hits = 0\n",
        "    for epoch in range(400):\n",
        "        gnn_model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # data\n",
        "        pos_edge_index, neg_edge_index = process_data(train_data)\n",
        "\n",
        "        # loss\n",
        "        pos_edge_pred, neg_edge_pred = gnn_model(pos_edge_index, neg_edge_index, train_data.edge_type)\n",
        "\n",
        "\n",
        "        out = torch.cat([pos_edge_pred, neg_edge_pred])\n",
        "        gt = torch.cat([torch.ones_like(pos_edge_pred), torch.zeros_like(neg_edge_pred)])\n",
        "        # loss = F.binary_cross_entropy_with_logits(out, gt)\n",
        "\n",
        "        loss = F.margin_ranking_loss(pos_edge_pred, neg_edge_pred, target=torch.ones_like(pos_edge_pred), margin=1)\n",
        "        reg_loss = gnn_model.node_emb.pow(2).mean() +  gnn_model.rel_emb.pow(2).mean()\n",
        "        loss = loss + reg_coeff * reg_loss\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(gnn_model.parameters(), 1.)\n",
        "        optimizer.step()\n",
        "\n",
        "        # valid\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            gnn_model.eval()\n",
        "            val_mrr, val_hits_at_k = gnn_model.eval_metrics(val_data)\n",
        "            test_mrr, test_hits_at_k = gnn_model.eval_metrics(test_data)\n",
        "            print(\"Epoch: {}\\tValidation MRR: {:.4f}\\tH@10: {:.4f}\\tTest MRR: {:.4f}\\tH@10: {:.4f}\".format(epoch + 1, val_mrr, val_hits_at_k, test_mrr, test_hits_at_k))\n",
        "\n",
        "            if val_hits_at_k > best_val_hits:\n",
        "                best_val_mrr = val_mrr\n",
        "                best_val_hits = val_hits_at_k\n",
        "                best_test_mrr = test_mrr\n",
        "                best_test_hits = test_hits_at_k\n",
        "\n",
        "    return best_val_mrr, best_val_hits, best_test_mrr, best_test_hits\n",
        "\n",
        "# example of running with fixed parameters\n",
        "hidden_dim = 64\n",
        "num_gnn_layers = 2\n",
        "seed_list = [14504]\n",
        "reg_coeff = 1e-2\n",
        "dropout = 0\n",
        "lr = 0.01\n",
        "\n",
        "\n",
        "num_runs = len(seed_list)\n",
        "for run in range(num_runs):\n",
        "    print(\"### Run: {}\".format(run + 1))\n",
        "    best_val_mrr, best_val_hits, best_test_mrr, best_test_hits = use_gnn(seed=seed_list[run],\n",
        "                                                                         hidden_dim=hidden_dim,\n",
        "                                                                         num_gnn_layers=num_gnn_layers,\n",
        "                                                                         dropout=dropout,\n",
        "                                                                         lr=lr,\n",
        "                                                                         reg_coeff=reg_coeff)\n",
        "\n",
        "print(\"===========Best Results==========\")\n",
        "# print(\"hidden_dim: {}\".format())\n",
        "print(\"Validation MRR: {}\".format(best_val_mrr))\n",
        "print(\"Validation H@10: {}\".format(best_val_hits))\n",
        "print(\"Test MRR: {}\".format(best_test_mrr))\n",
        "print(\"Test H@10: {}\".format(best_test_hits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx0owMvHWl2k",
        "outputId": "bbbdb849-2a5f-4f99-b34a-359fb1bf137f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Run: 1\n",
            "Epoch: 10\tValidation MRR: 0.0599\tH@10: 0.1141\tTest MRR: 0.0598\tH@10: 0.1158\n",
            "Epoch: 20\tValidation MRR: 0.1147\tH@10: 0.1885\tTest MRR: 0.1107\tH@10: 0.1851\n",
            "Epoch: 30\tValidation MRR: 0.1161\tH@10: 0.2001\tTest MRR: 0.1141\tH@10: 0.1978\n",
            "Epoch: 40\tValidation MRR: 0.1231\tH@10: 0.2171\tTest MRR: 0.1198\tH@10: 0.2121\n",
            "Epoch: 50\tValidation MRR: 0.1248\tH@10: 0.2163\tTest MRR: 0.1214\tH@10: 0.2117\n",
            "Epoch: 60\tValidation MRR: 0.1275\tH@10: 0.2246\tTest MRR: 0.1242\tH@10: 0.2174\n",
            "Epoch: 70\tValidation MRR: 0.1277\tH@10: 0.2244\tTest MRR: 0.1240\tH@10: 0.2177\n",
            "Epoch: 80\tValidation MRR: 0.1308\tH@10: 0.2267\tTest MRR: 0.1259\tH@10: 0.2207\n",
            "Epoch: 90\tValidation MRR: 0.1312\tH@10: 0.2267\tTest MRR: 0.1274\tH@10: 0.2210\n",
            "Epoch: 100\tValidation MRR: 0.1313\tH@10: 0.2296\tTest MRR: 0.1265\tH@10: 0.2245\n",
            "Epoch: 110\tValidation MRR: 0.1324\tH@10: 0.2344\tTest MRR: 0.1278\tH@10: 0.2285\n",
            "Epoch: 120\tValidation MRR: 0.1380\tH@10: 0.2466\tTest MRR: 0.1342\tH@10: 0.2423\n",
            "Epoch: 130\tValidation MRR: 0.1401\tH@10: 0.2427\tTest MRR: 0.1353\tH@10: 0.2361\n",
            "Epoch: 140\tValidation MRR: 0.1385\tH@10: 0.2506\tTest MRR: 0.1340\tH@10: 0.2417\n",
            "Epoch: 150\tValidation MRR: 0.1386\tH@10: 0.2479\tTest MRR: 0.1334\tH@10: 0.2385\n",
            "Epoch: 160\tValidation MRR: 0.1400\tH@10: 0.2528\tTest MRR: 0.1353\tH@10: 0.2444\n",
            "Epoch: 170\tValidation MRR: 0.1437\tH@10: 0.2553\tTest MRR: 0.1379\tH@10: 0.2459\n",
            "Epoch: 180\tValidation MRR: 0.1447\tH@10: 0.2584\tTest MRR: 0.1391\tH@10: 0.2516\n",
            "Epoch: 190\tValidation MRR: 0.1456\tH@10: 0.2589\tTest MRR: 0.1402\tH@10: 0.2497\n",
            "Epoch: 200\tValidation MRR: 0.1446\tH@10: 0.2598\tTest MRR: 0.1400\tH@10: 0.2513\n",
            "Epoch: 210\tValidation MRR: 0.1456\tH@10: 0.2610\tTest MRR: 0.1408\tH@10: 0.2517\n",
            "Epoch: 220\tValidation MRR: 0.1471\tH@10: 0.2676\tTest MRR: 0.1413\tH@10: 0.2566\n",
            "Epoch: 230\tValidation MRR: 0.1462\tH@10: 0.2648\tTest MRR: 0.1411\tH@10: 0.2552\n",
            "Epoch: 240\tValidation MRR: 0.1504\tH@10: 0.2691\tTest MRR: 0.1450\tH@10: 0.2572\n",
            "Epoch: 250\tValidation MRR: 0.1526\tH@10: 0.2655\tTest MRR: 0.1475\tH@10: 0.2563\n",
            "Epoch: 260\tValidation MRR: 0.1515\tH@10: 0.2714\tTest MRR: 0.1469\tH@10: 0.2616\n",
            "Epoch: 270\tValidation MRR: 0.1542\tH@10: 0.2708\tTest MRR: 0.1495\tH@10: 0.2600\n",
            "Epoch: 280\tValidation MRR: 0.1508\tH@10: 0.2718\tTest MRR: 0.1462\tH@10: 0.2612\n",
            "Epoch: 290\tValidation MRR: 0.1493\tH@10: 0.2719\tTest MRR: 0.1436\tH@10: 0.2611\n",
            "Epoch: 300\tValidation MRR: 0.1529\tH@10: 0.2756\tTest MRR: 0.1484\tH@10: 0.2639\n",
            "Epoch: 310\tValidation MRR: 0.1521\tH@10: 0.2768\tTest MRR: 0.1478\tH@10: 0.2650\n",
            "Epoch: 320\tValidation MRR: 0.1505\tH@10: 0.2737\tTest MRR: 0.1447\tH@10: 0.2647\n",
            "Epoch: 330\tValidation MRR: 0.1487\tH@10: 0.2771\tTest MRR: 0.1433\tH@10: 0.2646\n",
            "Epoch: 340\tValidation MRR: 0.1539\tH@10: 0.2764\tTest MRR: 0.1495\tH@10: 0.2654\n",
            "Epoch: 350\tValidation MRR: 0.1510\tH@10: 0.2776\tTest MRR: 0.1473\tH@10: 0.2658\n",
            "Epoch: 360\tValidation MRR: 0.1485\tH@10: 0.2776\tTest MRR: 0.1438\tH@10: 0.2623\n",
            "Epoch: 370\tValidation MRR: 0.1508\tH@10: 0.2758\tTest MRR: 0.1468\tH@10: 0.2632\n",
            "Epoch: 380\tValidation MRR: 0.1538\tH@10: 0.2822\tTest MRR: 0.1499\tH@10: 0.2717\n",
            "Epoch: 390\tValidation MRR: 0.1532\tH@10: 0.2777\tTest MRR: 0.1485\tH@10: 0.2663\n",
            "Epoch: 400\tValidation MRR: 0.1495\tH@10: 0.2750\tTest MRR: 0.1447\tH@10: 0.2644\n",
            "===========Best Results==========\n",
            "Validation MRR: 0.15376725792884827\n",
            "Validation H@10: 0.2822355289421158\n",
            "Test MRR: 0.14993281662464142\n",
            "Test H@10: 0.27171894849995115\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}