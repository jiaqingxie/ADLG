{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from functools import partial\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from math import ceil\n",
    "\n",
    "from torch_geometric.data import DenseDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a dataset\n",
    "\n",
    "We use the `Enymes` Dataset containing molecule graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ENZYMES(600):\n",
      "======================\n",
      "Number of graphs: 600\n",
      "Number of features: 3\n",
      "Number of classes: 6\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(name='ENZYMES', root='data/TUDataset')\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('======================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample graph: Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "==============================================================\n",
      "Number of avg. nodes: 32.63\n",
      "Number of avg. edges: 124.27\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]  # Get the first (and only) graph object.\n",
    "\n",
    "print(f\"Sample graph: {data}\")\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of avg. nodes: {np.mean([data.num_nodes for data in dataset]):.2f}')\n",
    "print(f'Number of avg. edges: {np.mean([data.num_edges for data in dataset]):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batching for graphs\n",
    "\n",
    "We make use of different dataloaders implemented in PyTorch Geometric: https://pytorch-geometric.readthedocs.io/en/latest/modules/loader.html#torch_geometric.loader.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "# Create a PyTorch Geometric DataLoader object for easy graph mini-batching.\n",
    "BATCH_SIZE = 16\n",
    "graph_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch from the dataloader\n",
    "sample_batch = next(iter(graph_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's investigate the batch object we have received"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataBatch(edge_index=[2, 2314], x=[587, 3], y=[16], batch=[587], ptr=[17])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains a single `edge_index`, a single node feature matrix `x`,\n",
    "a single target label matrix `y`, and a batch indicator matrix `batch`.\n",
    "\n",
    "The dataloader merged all graphs into a single set of disjoint graphs.\n",
    "Standard message passing operators can natively run on this representation,\n",
    "because no messages are passed between the disjoint set of graphs.\n",
    "\n",
    "This allows for efficient mini-batching and parallel processing\n",
    "of different graphs, without any memory overhead of e.g. additional padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size: torch.Size([587, 16])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "# Create a GraphSAGE model\n",
    "conv = SAGEConv(dataset.num_features, 16)\n",
    "\n",
    "# Run the convolution operator\n",
    "out = conv(sample_batch.x, sample_batch.edge_index)\n",
    "\n",
    "# Check the size of the output\n",
    "print(f'Output size: {out.size()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have node embeddings for all the graphs, but what if we want to\n",
    "aggregate them into individual representations for each graph?\n",
    "\n",
    "We need to make use of the `batch` indicator attribute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 587, batch indicator matrix: torch.Size([587])\n",
      "Batch size: 16, unique batch indicator values: tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nodes: {sample_batch.num_nodes}, batch indicator matrix: {sample_batch.batch.shape}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, unique batch indicator values: {sample_batch.batch.unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph embedding shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "# this is one of the helper libraries recommended to install along pytorch geometric\n",
    "import torch_scatter\n",
    "\n",
    "# The `scatter` function supports a set of aggregations: https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html\n",
    "graph_embeddings  = torch_scatter.scatter(out, sample_batch.batch, dim=0, reduce=\"mean\")\n",
    "print(f\"Graph embedding shape: {graph_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same but in an even simpler manner is also supported by PyG out-of-the box now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn.pool import global_mean_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph embedding shape: torch.Size([16, 16])\n"
     ]
    }
   ],
   "source": [
    "graph_embeddings = global_mean_pool(out, sample_batch.batch)\n",
    "print(f\"Graph embedding shape: {graph_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Baseline GNN\n",
    "\n",
    "We refer to the paper Design Space of GNN (Jiaxuan You et al.), where a fundamental model contains the following blocks:\n",
    "\n",
    "1. Pre-processing MLP Layers\n",
    "2. Message Passing Layers (GNN + BN + Activation + Dropout)\n",
    "3. (*) Skip-connection Layers / Residual Blocks\n",
    "4. Pooling Layer(s). \n",
    "5. Post-processing MLP Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class basicGNN(nn.Module):\n",
    "    def __init__(self, depth, method, dropout, pool, input_dim, output_dim, embed_dim, connection):\n",
    "        super(basicGNN, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.method = method\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dropout = dropout\n",
    "        self.connection = connection\n",
    "\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.preprocess_mlp = nn.ModuleList()\n",
    "        self.gnn_mlp = nn.ModuleList()\n",
    "        self.postprocess_mlp = nn.ModuleList()\n",
    "        self.pool = pool\n",
    "        \n",
    "        for i in range(2):\n",
    "            # Here the preprocess layers we refer to the paper: \n",
    "            # Design Space for Graph Neural Networks, Jiaxuan You et al. NeurIPS 2021\n",
    "            if i == 0:\n",
    "                self.preprocess_mlp.append(nn.Sequential(\n",
    "                        nn.Linear(self.input_dim, self.embed_dim),\n",
    "                        nn.BatchNorm1d(self.embed_dim),\n",
    "                        nn.PReLU(),\n",
    "                )) \n",
    "            else:\n",
    "                self.preprocess_mlp.append(nn.Sequential(\n",
    "                        nn.Linear(self.embed_dim, self.embed_dim),\n",
    "                        nn.BatchNorm1d(self.embed_dim),\n",
    "                        nn.PReLU(),\n",
    "                )) \n",
    "\n",
    "        for i in range(3):\n",
    "            # Here the preprocess layers we refer to the paper: \n",
    "            # Design Space for Graph Neural Networks, Jiaxuan You et al. NeurIPS 2021\n",
    "            if i != 2:\n",
    "                if i == 1:\n",
    "                    self.postprocess_mlp.append(nn.Sequential(\n",
    "                        nn.Linear(self.embed_dim, self.embed_dim),\n",
    "                        nn.BatchNorm1d(self.embed_dim),\n",
    "                        nn.PReLU(),\n",
    "                ))\n",
    "                else:\n",
    "                    if self.connection == \"residual\":\n",
    "                        self.postprocess_mlp.append(nn.Sequential(\n",
    "                            nn.Linear(self.embed_dim , self.embed_dim),\n",
    "                            nn.BatchNorm1d(self.embed_dim),\n",
    "                            nn.PReLU(),\n",
    "                    ))\n",
    "                    else:\n",
    "                        self.postprocess_mlp.append(nn.Sequential(\n",
    "                            nn.Linear(self.embed_dim * self.depth , self.embed_dim),\n",
    "                            nn.BatchNorm1d(self.embed_dim),\n",
    "                            nn.PReLU(),\n",
    "                        ))\n",
    "            else:\n",
    "                self.postprocess_mlp.append(nn.Sequential(\n",
    "                            nn.Linear(self.embed_dim, self.output_dim),\n",
    "                    ))\n",
    "        for i in range(self.depth):\n",
    "            # Here the MLP layers we also refer to the paper: \n",
    "            # Design Space for Graph Neural Networks, Jiaxuan You et al. NeurIPS 2021\n",
    "            # We apply ACT[DROPOUT[BN[Linear]]] in order\n",
    "            # Particularly, we use the result from the paper that dropout layer should be removed\n",
    "            self.gnn_mlp.append(nn.Sequential(\n",
    "                        nn.Linear(self.embed_dim, self.embed_dim),\n",
    "                        nn.BatchNorm1d(self.embed_dim),\n",
    "                        nn.Dropout(self.dropout),\n",
    "                        nn.PReLU(),\n",
    "                        nn.Linear(self.embed_dim, self.embed_dim),\n",
    "                        nn.BatchNorm1d(self.embed_dim),\n",
    "                        nn.Dropout(self.dropout),\n",
    "                        nn.PReLU(),\n",
    "                )) \n",
    "\n",
    "        for i in range(self.depth):\n",
    "            # Here we only provide only four mainstream graph encoders for baseline tests:\n",
    "            # GCN, GraphSAGE, GAT and GIN\n",
    "            if method == \"GAT\":\n",
    "                self.convs.append(pyg_nn.GATConv(self.embed_dim, self.embed_dim))\n",
    "            elif method == \"GIN\":\n",
    "                self.convs.append(pyg_nn.GINConv(self.gnn_mlp[i]))\n",
    "            elif method == \"GraphSAGE\":\n",
    "                self.convs.append(pyg_nn.SAGEConv(self.embed_dim, self.embed_dim, normalize=True)) \n",
    "            elif method == \"GCN\":\n",
    "                self.convs.append(pyg_nn.GCNConv(self.embed_dim, self.embed_dim))      \n",
    "\n",
    "    def forward(self, x, edge_index, batch, mask = None):\n",
    "        # 1. preprocess \n",
    "        self.save_results = []\n",
    "        h = self.preprocess_mlp[0](x)\n",
    "        h = self.preprocess_mlp[1](h)\n",
    "        # 2. residual / skip-connect\n",
    "        for i in range(self.depth):\n",
    "            if self.method == \"GIN\":\n",
    "                if self.connection == \"residual\":\n",
    "                    h = h + self.convs[i](h, edge_index)              \n",
    "                else:\n",
    "                    h = self.convs[i](h, edge_index)\n",
    "                    self.save_results.append(h)\n",
    "            else:\n",
    "                if self.connection == \"residual\":\n",
    "                    h = h + self.convs[i](self.gnn_mlp[i](h), edge_index)\n",
    "\n",
    "                else:\n",
    "                    h = self.convs[i](self.gnn_mlp[i](h), edge_index)  \n",
    "                    self.save_results.append(h)    \n",
    "         \n",
    "   \n",
    "        if self.connection == \"skip\":\n",
    "            h= torch.cat(self.save_results, dim=1)\n",
    "        # 3. pooling for graph classification\n",
    "\n",
    "        if self.pool == \"mean\":\n",
    "            h = pyg_nn.global_mean_pool(h, batch) \n",
    "        elif self.pool == \"max\":\n",
    "            h = pyg_nn.global_max_pool(h, batch)\n",
    "\n",
    "        # 4. postprocess\n",
    "        h = self.postprocess_mlp[0](h)\n",
    "        h = self.postprocess_mlp[1](h) # output\n",
    "        h = self.postprocess_mlp[2](h) # output\n",
    "        out = F.log_softmax(h, dim =1)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(dataset, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    return dataset.shuffle()\n",
    "\n",
    "def train_test_val_split(num_test, batch_size, dataset):\n",
    "    test_dataset = dataset[:num_test]\n",
    "    val_dataset = dataset[num_test:2 * num_test]\n",
    "    train_dataset = dataset[2 * num_test:]\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "    return test_loader, val_loader, train_loader\n",
    "\n",
    "def train(epoch, model, train_loader, device, optimizer):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        model.train()\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.x, data.edge_index, data.batch)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * len(data.y)\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader, model, device, ):\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.edge_index, data.batch).max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\ETH-GraphNN\\Projects\\Project1\\Project 1\\graph_mini_batching.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m times \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(epoch, model, train_loader, device, optimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     val_acc \u001b[39m=\u001b[39m test(val_loader, model, device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mif\u001b[39;00m val_acc \u001b[39m>\u001b[39m best_val_acc:\n",
      "\u001b[1;32me:\\ETH-GraphNN\\Projects\\Project1\\Project 1\\graph_mini_batching.ipynb Cell 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m loss_all \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/ETH-GraphNN/Projects/Project1/Project%201/graph_mini_batching.ipynb#X32sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:55\u001b[0m, in \u001b[0;36mCollater.collate_fn\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, OnDiskDataset):\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mmulti_get(batch))\n\u001b[1;32m---> 55\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(batch)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:28\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     26\u001b[0m elem \u001b[39m=\u001b[39m batch[\u001b[39m0\u001b[39m]\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mreturn\u001b[39;00m Batch\u001b[39m.\u001b[39;49mfrom_data_list(\n\u001b[0;32m     29\u001b[0m         batch,\n\u001b[0;32m     30\u001b[0m         follow_batch\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfollow_batch,\n\u001b[0;32m     31\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexclude_keys,\n\u001b[0;32m     32\u001b[0m     )\n\u001b[0;32m     33\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch_geometric\\data\\batch.py:93\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_data_list\u001b[39m(\u001b[39mcls\u001b[39m, data_list: List[BaseData],\n\u001b[0;32m     83\u001b[0m                    follow_batch: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m                    exclude_keys: Optional[List[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     85\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[39m    Python list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[39m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39m    :obj:`follow_batch`.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m    Will exclude any keys given in :obj:`exclude_keys`.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m     batch, slice_dict, inc_dict \u001b[39m=\u001b[39m collate(\n\u001b[0;32m     94\u001b[0m         \u001b[39mcls\u001b[39;49m,\n\u001b[0;32m     95\u001b[0m         data_list\u001b[39m=\u001b[39;49mdata_list,\n\u001b[0;32m     96\u001b[0m         increment\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     97\u001b[0m         add_batch\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(data_list[\u001b[39m0\u001b[39;49m], Batch),\n\u001b[0;32m     98\u001b[0m         follow_batch\u001b[39m=\u001b[39;49mfollow_batch,\n\u001b[0;32m     99\u001b[0m         exclude_keys\u001b[39m=\u001b[39;49mexclude_keys,\n\u001b[0;32m    100\u001b[0m     )\n\u001b[0;32m    102\u001b[0m     batch\u001b[39m.\u001b[39m_num_graphs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(data_list)\n\u001b[0;32m    103\u001b[0m     batch\u001b[39m.\u001b[39m_slice_dict \u001b[39m=\u001b[39m slice_dict\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch_geometric\\data\\collate.py:92\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39m# Collate attributes into a unified representation:\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m value, slices, incs \u001b[39m=\u001b[39m _collate(attr, values, data_list, stores,\n\u001b[0;32m     93\u001b[0m                                increment)\n\u001b[0;32m     95\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, Tensor) \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mis_cuda:\n\u001b[0;32m     96\u001b[0m     device \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mdevice\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch_geometric\\data\\collate.py:144\u001b[0m, in \u001b[0;36m_collate\u001b[1;34m(key, values, data_list, stores, increment)\u001b[0m\n\u001b[0;32m    142\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 144\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[0;32m    145\u001b[0m             value \u001b[39m+\u001b[39m inc\u001b[39m.\u001b[39mto(value\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    146\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[0;32m    147\u001b[0m         ]\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     incs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\anaconda3\\envs\\adlg\\lib\\site-packages\\torch_geometric\\data\\collate.py:145\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    142\u001b[0m     incs \u001b[39m=\u001b[39m get_incs(key, values, data_list, stores)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m incs\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mint\u001b[39m(incs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    144\u001b[0m         values \u001b[39m=\u001b[39m [\n\u001b[1;32m--> 145\u001b[0m             value \u001b[39m+\u001b[39;49m inc\u001b[39m.\u001b[39;49mto(value\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    146\u001b[0m             \u001b[39mfor\u001b[39;00m value, inc \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(values, incs)\n\u001b[0;32m    147\u001b[0m         ]\n\u001b[0;32m    148\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    149\u001b[0m     incs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "seed = [0]*5 + [42]*5 + [114514]*5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "# ------------ hyperparameters --------------- #\n",
    "modelname = \"GraphSAGE\"\n",
    "depth = 2\n",
    "dropout = 0.15\n",
    "aggr = \"mean\"\n",
    "embed_dim = 128\n",
    "connection = \"skip\"\n",
    "lr = 0.002\n",
    "weight_decay = 5e-4\n",
    "batch_size = 64\n",
    "epochs = 801\n",
    "num_test = 100 # 100 for test\n",
    "# ------------- begin training session  -----------------#\n",
    "# Shuffle dataset three times and train each dataset 5 times. then take average of them (15)\n",
    "for i in range(15):\n",
    "    dataset = shuffle(TUDataset(name='ENZYMES', root='data/TUDataset'), seed[i])\n",
    "    torch.manual_seed(seed=seed[i])\n",
    "    model = basicGNN(depth, modelname, dropout, aggr, dataset.num_features, \n",
    "                      dataset.num_classes, embed_dim, connection).to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr = lr, weight_decay=weight_decay)\n",
    "    test_loader, val_loader, train_loader = train_test_val_split(num_test, batch_size, dataset)\n",
    "    best_val_acc = test_acc = 0\n",
    "    times = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(epoch, model, train_loader, device, optimizer)\n",
    "        val_acc = test(val_loader, model, device)\n",
    "        if val_acc > best_val_acc:\n",
    "            test_acc = test(test_loader, model, device)\n",
    "            best_val_acc = val_acc\n",
    "        # if epoch % 100 == 0:\n",
    "        #     print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, '\n",
    "        #         f'Best Val Acc: {best_val_acc:.4f}, Best Test Acc: {test_acc:.4f}')\n",
    "    \n",
    "    print(\"for seed i: {}, model {} has the best test accuracy: {}\".format(seed[i], modelname, test_acc))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Improvement on pooling\n",
    "\n",
    "Diffpool (Rex et al.) 2018 KDD states that a connection of pooling layers will lead to better performance with GraphSAGE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Graph Network with Hierarchical DiffPool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels,\n",
    "                 normalize=True, lin=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = pyg_nn.DenseSAGEConv(in_channels, hidden_channels, normalize)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv2 = pyg_nn.DenseSAGEConv(hidden_channels, hidden_channels, normalize)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(hidden_channels)\n",
    "        self.conv3 = pyg_nn.DenseSAGEConv(hidden_channels, out_channels, normalize)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        if lin is True:\n",
    "            self.lin = torch.nn.Linear(2 * hidden_channels + out_channels,\n",
    "                                       out_channels)\n",
    "        else:\n",
    "            self.lin = None\n",
    "\n",
    "    def bn(self, i, x):\n",
    "        batch_size, num_nodes, num_channels = x.size()\n",
    "\n",
    "        x = x.view(-1, num_channels)\n",
    "        x = getattr(self, f'bn{i}')(x)\n",
    "        x = x.view(batch_size, num_nodes, num_channels)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        batch_size, num_nodes, in_channels = x.size()\n",
    "\n",
    "        x0 = x\n",
    "        x1 =(self.conv1(x0, adj, mask).relu())\n",
    "        x2 =(self.conv2(x1, adj, mask).relu())\n",
    "        x3 =(self.conv3(x2, adj, mask).relu())\n",
    "        x = torch.cat([x1, x2, x3], dim=-1)\n",
    "\n",
    "        if self.lin is not None:\n",
    "            x = self.lin(x).relu()\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        num_nodes = ceil(0.1 * max_nodes)\n",
    "        self.gnn1_pool = GNN(dataset.num_features, 64, num_nodes)\n",
    "        self.gnn1_embed = GNN(dataset.num_features, 64, 64, lin=False)\n",
    "\n",
    "        num_nodes = ceil(0.1* num_nodes)\n",
    "        self.gnn2_pool = GNN(3 * 64, 64, num_nodes)\n",
    "        self.gnn2_embed = GNN(3 * 64, 64, 64, lin=False)\n",
    "\n",
    "        self.gnn3_pool = GNN(3 * 64, 64, num_nodes) \n",
    "        self.gnn3_embed = GNN(3 * 64, 64, 64, lin=False)\n",
    "\n",
    "        self.gnn4_embed = GNN(3 * 64, 64, 64, lin=False)\n",
    "\n",
    "        self.lin1 = torch.nn.Linear(3 * 64, 64)\n",
    "        self.lin2 = torch.nn.Linear(64, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, adj, mask=None):\n",
    "        s = self.gnn1_pool(x, adj, mask)\n",
    "        x = self.gnn1_embed(x, adj, mask)\n",
    "\n",
    "        x, adj, l1, e1 = pyg_nn.dense_diff_pool(x, adj, s, mask)\n",
    "\n",
    "        s = self.gnn2_pool(x, adj)\n",
    "        x = self.gnn2_embed(x, adj)\n",
    "        \n",
    "        x, adj, l2, e2 = pyg_nn.dense_diff_pool(x, adj, s)\n",
    "\n",
    "        # s = self.gnn3_pool(x, adj)\n",
    "        x = self.gnn3_embed(x, adj)\n",
    "\n",
    "\n",
    "        x = x.mean(dim=1)\n",
    "        x = self.lin1(x).relu()\n",
    "        x = self.lin2(x)\n",
    "        return F.log_softmax(x, dim=-1), l1 + l2, e1 + e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Train Loss: 1.7182, Val Acc: 0.2600, Test Acc: 0.2200\n",
      "Epoch: 020, Train Loss: 1.6094, Val Acc: 0.3100, Test Acc: 0.2900\n",
      "Epoch: 030, Train Loss: 1.4914, Val Acc: 0.3200, Test Acc: 0.3400\n",
      "Epoch: 040, Train Loss: 1.4191, Val Acc: 0.2600, Test Acc: 0.3600\n",
      "Epoch: 050, Train Loss: 1.3301, Val Acc: 0.3300, Test Acc: 0.3200\n",
      "Epoch: 060, Train Loss: 1.2267, Val Acc: 0.3900, Test Acc: 0.3400\n",
      "Epoch: 070, Train Loss: 1.0643, Val Acc: 0.4100, Test Acc: 0.4000\n",
      "Epoch: 080, Train Loss: 0.8981, Val Acc: 0.4600, Test Acc: 0.4100\n",
      "Epoch: 090, Train Loss: 0.8353, Val Acc: 0.4800, Test Acc: 0.3700\n",
      "Epoch: 100, Train Loss: 0.7794, Val Acc: 0.4100, Test Acc: 0.3700\n",
      "Epoch: 110, Train Loss: 0.6267, Val Acc: 0.4300, Test Acc: 0.3700\n",
      "Epoch: 120, Train Loss: 0.5273, Val Acc: 0.4900, Test Acc: 0.5200\n",
      "Epoch: 130, Train Loss: 0.3338, Val Acc: 0.5000, Test Acc: 0.5500\n",
      "Epoch: 140, Train Loss: 0.2472, Val Acc: 0.4600, Test Acc: 0.5600\n",
      "Epoch: 150, Train Loss: 0.2156, Val Acc: 0.4600, Test Acc: 0.5600\n",
      "Epoch: 160, Train Loss: 0.2970, Val Acc: 0.4200, Test Acc: 0.5600\n",
      "Epoch: 170, Train Loss: 0.0719, Val Acc: 0.4700, Test Acc: 0.5600\n",
      "Epoch: 180, Train Loss: 0.0332, Val Acc: 0.4400, Test Acc: 0.5600\n",
      "Epoch: 190, Train Loss: 0.0188, Val Acc: 0.4700, Test Acc: 0.5600\n",
      "Epoch: 200, Train Loss: 0.1830, Val Acc: 0.5100, Test Acc: 0.5600\n",
      "Epoch: 210, Train Loss: 0.0326, Val Acc: 0.5100, Test Acc: 0.5600\n",
      "Epoch: 220, Train Loss: 0.0128, Val Acc: 0.4900, Test Acc: 0.5600\n",
      "Epoch: 230, Train Loss: 0.0092, Val Acc: 0.4900, Test Acc: 0.5600\n",
      "Epoch: 240, Train Loss: 0.0066, Val Acc: 0.4900, Test Acc: 0.5600\n",
      "Epoch: 250, Train Loss: 0.0061, Val Acc: 0.4900, Test Acc: 0.5600\n",
      "Epoch: 260, Train Loss: 0.0053, Val Acc: 0.4800, Test Acc: 0.5600\n",
      "Epoch: 270, Train Loss: 0.0056, Val Acc: 0.4800, Test Acc: 0.5600\n",
      "Epoch: 280, Train Loss: 0.0060, Val Acc: 0.4800, Test Acc: 0.5600\n",
      "Epoch: 290, Train Loss: 0.0062, Val Acc: 0.4900, Test Acc: 0.5600\n",
      "Epoch: 300, Train Loss: 0.7620, Val Acc: 0.4700, Test Acc: 0.5600\n",
      "Epoch: 310, Train Loss: 0.2311, Val Acc: 0.4500, Test Acc: 0.5100\n",
      "Epoch: 320, Train Loss: 0.0392, Val Acc: 0.5300, Test Acc: 0.5100\n",
      "Epoch: 330, Train Loss: 0.0188, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 340, Train Loss: 0.0060, Val Acc: 0.4900, Test Acc: 0.5100\n",
      "Epoch: 350, Train Loss: 0.0056, Val Acc: 0.4900, Test Acc: 0.5100\n",
      "Epoch: 360, Train Loss: 0.0055, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 370, Train Loss: 0.0040, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 380, Train Loss: 0.0061, Val Acc: 0.4900, Test Acc: 0.5100\n",
      "Epoch: 390, Train Loss: 0.0047, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 400, Train Loss: 0.0048, Val Acc: 0.4900, Test Acc: 0.5100\n",
      "Epoch: 410, Train Loss: 0.0048, Val Acc: 0.4900, Test Acc: 0.5100\n",
      "Epoch: 420, Train Loss: 0.0047, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 430, Train Loss: 0.0045, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 440, Train Loss: 0.0046, Val Acc: 0.5000, Test Acc: 0.5100\n",
      "Epoch: 450, Train Loss: 0.0046, Val Acc: 0.5100, Test Acc: 0.5100\n",
      "Epoch: 460, Train Loss: 0.0034, Val Acc: 0.5100, Test Acc: 0.5100\n",
      "Epoch: 470, Train Loss: 0.2961, Val Acc: 0.4700, Test Acc: 0.5100\n",
      "Epoch: 480, Train Loss: 0.0117, Val Acc: 0.4700, Test Acc: 0.5900\n",
      "Epoch: 490, Train Loss: 0.0077, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 500, Train Loss: 0.0067, Val Acc: 0.4700, Test Acc: 0.5900\n",
      "Epoch: 510, Train Loss: 0.0050, Val Acc: 0.4700, Test Acc: 0.5900\n",
      "Epoch: 520, Train Loss: 0.0048, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 530, Train Loss: 0.0046, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 540, Train Loss: 0.0046, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 550, Train Loss: 0.0046, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 560, Train Loss: 0.6256, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 570, Train Loss: 0.0463, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 580, Train Loss: 0.0898, Val Acc: 0.5300, Test Acc: 0.5900\n",
      "Epoch: 590, Train Loss: 0.0300, Val Acc: 0.4600, Test Acc: 0.5900\n",
      "Epoch: 600, Train Loss: 0.0322, Val Acc: 0.4600, Test Acc: 0.5900\n",
      "Epoch: 610, Train Loss: 0.0057, Val Acc: 0.4600, Test Acc: 0.5900\n",
      "Epoch: 620, Train Loss: 0.0050, Val Acc: 0.4700, Test Acc: 0.5900\n",
      "Epoch: 630, Train Loss: 0.0048, Val Acc: 0.4700, Test Acc: 0.5900\n",
      "Epoch: 640, Train Loss: 0.0046, Val Acc: 0.4700, Test Acc: 0.5900\n",
      "Epoch: 650, Train Loss: 0.0046, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 660, Train Loss: 0.0045, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 670, Train Loss: 0.0053, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 680, Train Loss: 0.0044, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 690, Train Loss: 0.0037, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 700, Train Loss: 0.0043, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 710, Train Loss: 0.0041, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 720, Train Loss: 0.0043, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 730, Train Loss: 0.0043, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 740, Train Loss: 0.0043, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 750, Train Loss: 0.9285, Val Acc: 0.4000, Test Acc: 0.5900\n",
      "Epoch: 760, Train Loss: 0.0131, Val Acc: 0.4600, Test Acc: 0.5900\n",
      "Epoch: 770, Train Loss: 0.0060, Val Acc: 0.4800, Test Acc: 0.5900\n",
      "Epoch: 780, Train Loss: 0.0052, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 790, Train Loss: 0.0049, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 800, Train Loss: 0.0052, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 810, Train Loss: 0.0042, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 820, Train Loss: 0.0044, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 830, Train Loss: 0.0043, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 840, Train Loss: 0.0044, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 850, Train Loss: 0.0043, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 860, Train Loss: 0.0043, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 870, Train Loss: 0.0031, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 880, Train Loss: 0.0042, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 890, Train Loss: 0.0051, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 900, Train Loss: 0.0042, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 910, Train Loss: 0.0042, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 920, Train Loss: 0.0042, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 930, Train Loss: 0.0031, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 940, Train Loss: 0.0032, Val Acc: 0.4900, Test Acc: 0.5900\n",
      "Epoch: 950, Train Loss: 0.0040, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 960, Train Loss: 0.0041, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 970, Train Loss: 0.0041, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 980, Train Loss: 0.0038, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Epoch: 990, Train Loss: 0.0039, Val Acc: 0.5100, Test Acc: 0.5900\n",
      "Epoch: 1000, Train Loss: 0.0040, Val Acc: 0.5000, Test Acc: 0.5900\n",
      "Median time per epoch: 0.9196s\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DenseDataLoader\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "max_nodes = 300\n",
    "dataset = TUDataset(\n",
    "    # path,\n",
    "    name='ENZYMES',\n",
    "    root='data/TUDataset',\n",
    "    transform=T.ToDense(max_nodes),\n",
    "    pre_filter=lambda data: data.num_nodes <= max_nodes,\n",
    ")\n",
    "\n",
    "dataset = dataset.shuffle()\n",
    "n = 100\n",
    "\n",
    "test_dataset = dataset[:n]\n",
    "val_dataset = dataset[n:2 * n]\n",
    "train_dataset = dataset[2 * n:]\n",
    "test_loader = DenseDataLoader(test_dataset, batch_size=20)\n",
    "val_loader = DenseDataLoader(val_dataset, batch_size=20)\n",
    "train_loader = DenseDataLoader(train_dataset, batch_size=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "torch.manual_seed(0)\n",
    "model = Net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output, _, _ = model(data.x, data.adj, data.mask)\n",
    "        loss = F.nll_loss(output, data.y.view(-1))\n",
    "        loss.backward()\n",
    "        loss_all += data.y.size(0) * float(loss)\n",
    "        optimizer.step()\n",
    "    return loss_all / len(train_dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        pred = model(data.x, data.adj, data.mask)[0].max(dim=1)[1]\n",
    "        correct += int(pred.eq(data.y.view(-1)).sum())\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "best_val_acc = test_acc = 0\n",
    "times = []\n",
    "for epoch in range(1, 1001):\n",
    "    start = time.time()\n",
    "    train_loss = train(epoch)\n",
    "    val_acc = test(val_loader)\n",
    "    if val_acc > best_val_acc:\n",
    "        test_acc = test(test_loader)\n",
    "        best_val_acc = val_acc\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Train Loss: {train_loss:.4f}, '\n",
    "          f'Val Acc: {val_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "    times.append(time.time() - start)\n",
    "print(f\"Median time per epoch: {torch.tensor(times).median():.4f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 118], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 266], x=[88, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 12], x=[4, 3], y=[1])\n",
      "Data(edge_index=[2, 56], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 150], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 194], x=[55, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 182], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 2], x=[2, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 180], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 180], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 162], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 170], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 166], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 162], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 28], x=[8, 3], y=[1])\n",
      "Data(edge_index=[2, 88], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 162], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 160], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 32], x=[100, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[47, 3], y=[1])\n",
      "Data(edge_index=[2, 194], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 194], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 30], x=[9, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 170], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 62], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 62], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 24], x=[7, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 36], x=[10, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 64], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 36], x=[10, 3], y=[1])\n",
      "Data(edge_index=[2, 32], x=[9, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 110], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 150], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 110], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 174], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 72], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 56], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[17, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 64], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 138], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 88], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 136], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 138], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 182], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 64], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 130], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 18], x=[5, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 230], x=[59, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 138], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 60], x=[17, 3], y=[1])\n",
      "Data(edge_index=[2, 166], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[51, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 180], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 242], x=[96, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 254], x=[90, 3], y=[1])\n",
      "Data(edge_index=[2, 62], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 66], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 46], x=[11, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 40], x=[11, 3], y=[1])\n",
      "Data(edge_index=[2, 50], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 64], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 68], x=[17, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[13, 3], y=[1])\n",
      "Data(edge_index=[2, 6], x=[3, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 72], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 56], x=[13, 3], y=[1])\n",
      "Data(edge_index=[2, 48], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 174], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 168], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 160], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 82], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[11, 3], y=[1])\n",
      "Data(edge_index=[2, 32], x=[8, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[13, 3], y=[1])\n",
      "Data(edge_index=[2, 66], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 30], x=[8, 3], y=[1])\n",
      "Data(edge_index=[2, 126], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 50], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 96], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 64], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 72], x=[17, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 72], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[43, 3], y=[1])\n",
      "Data(edge_index=[2, 168], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 82], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 192], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 192], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 192], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 118], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 162], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 172], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 182], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 192], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[31, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 200], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[47, 3], y=[1])\n",
      "Data(edge_index=[2, 172], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[55, 3], y=[1])\n",
      "Data(edge_index=[2, 216], x=[62, 3], y=[1])\n",
      "Data(edge_index=[2, 144], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 200], x=[56, 3], y=[1])\n",
      "Data(edge_index=[2, 210], x=[57, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 202], x=[57, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 110], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 208], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 68], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 194], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 82], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 126], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 210], x=[54, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 162], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 136], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 130], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 142], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 142], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 22], x=[6, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 82], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 124], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 124], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 96], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 60], x=[17, 3], y=[1])\n",
      "Data(edge_index=[2, 66], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 72], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 96], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 118], x=[31, 3], y=[1])\n",
      "Data(edge_index=[2, 142], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 156], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 168], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 170], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 214], x=[60, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 64], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 172], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 174], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 156], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 168], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 166], x=[43, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 160], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 208], x=[62, 3], y=[1])\n",
      "Data(edge_index=[2, 200], x=[60, 3], y=[1])\n",
      "Data(edge_index=[2, 218], x=[96, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[54, 3], y=[1])\n",
      "Data(edge_index=[2, 278], x=[124, 3], y=[1])\n",
      "Data(edge_index=[2, 282], x=[126, 3], y=[1])\n",
      "Data(edge_index=[2, 298], x=[122, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 186], x=[49, 3], y=[1])\n",
      "Data(edge_index=[2, 178], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 168], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 166], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 186], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[55, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[51, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 178], x=[51, 3], y=[1])\n",
      "Data(edge_index=[2, 192], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 76], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 180], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[31, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 192], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[49, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 96], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 174], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 170], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 236], x=[64, 3], y=[1])\n",
      "Data(edge_index=[2, 142], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 16], x=[9, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 224], x=[66, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 124], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 118], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 82], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 150], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 50], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 38], x=[11, 3], y=[1])\n",
      "Data(edge_index=[2, 34], x=[10, 3], y=[1])\n",
      "Data(edge_index=[2, 48], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 40], x=[10, 3], y=[1])\n",
      "Data(edge_index=[2, 68], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 80], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 188], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 28], x=[7, 3], y=[1])\n",
      "Data(edge_index=[2, 56], x=[16, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 110], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 162], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 178], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 56], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 44], x=[11, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 70], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 46], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 194], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 120], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 124], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 138], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 136], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 76], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 66], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[43, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 66], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 46], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 100], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 114], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 116], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 108], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 78], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 68], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 58], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 130], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 60], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 76], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 82], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 60], x=[17, 3], y=[1])\n",
      "Data(edge_index=[2, 48], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 186], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[13, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 46], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 48], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 52], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 76], x=[20, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 76], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 48], x=[12, 3], y=[1])\n",
      "Data(edge_index=[2, 88], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 160], x=[60, 3], y=[1])\n",
      "Data(edge_index=[2, 144], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 54], x=[15, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 140], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 136], x=[33, 3], y=[1])\n",
      "Data(edge_index=[2, 122], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 156], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 144], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[43, 3], y=[1])\n",
      "Data(edge_index=[2, 160], x=[67, 3], y=[1])\n",
      "Data(edge_index=[2, 146], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 166], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 240], x=[66, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 98], x=[22, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 96], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 130], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 136], x=[30, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 142], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 178], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[34, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[32, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 222], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 132], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 220], x=[58, 3], y=[1])\n",
      "Data(edge_index=[2, 214], x=[57, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 86], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 166], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 240], x=[74, 3], y=[1])\n",
      "Data(edge_index=[2, 170], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 168], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 178], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 176], x=[43, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 184], x=[49, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[84, 3], y=[1])\n",
      "Data(edge_index=[2, 202], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 152], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 154], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[39, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 94], x=[25, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 172], x=[41, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 128], x=[31, 3], y=[1])\n",
      "Data(edge_index=[2, 92], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 96], x=[26, 3], y=[1])\n",
      "Data(edge_index=[2, 198], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 186], x=[50, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 134], x=[37, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 110], x=[29, 3], y=[1])\n",
      "Data(edge_index=[2, 160], x=[48, 3], y=[1])\n",
      "Data(edge_index=[2, 148], x=[40, 3], y=[1])\n",
      "Data(edge_index=[2, 68], x=[19, 3], y=[1])\n",
      "Data(edge_index=[2, 66], x=[14, 3], y=[1])\n",
      "Data(edge_index=[2, 62], x=[13, 3], y=[1])\n",
      "Data(edge_index=[2, 68], x=[13, 3], y=[1])\n",
      "Data(edge_index=[2, 170], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 156], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 158], x=[47, 3], y=[1])\n",
      "Data(edge_index=[2, 164], x=[47, 3], y=[1])\n",
      "Data(edge_index=[2, 180], x=[42, 3], y=[1])\n",
      "Data(edge_index=[2, 220], x=[51, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 104], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 206], x=[60, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[28, 3], y=[1])\n",
      "Data(edge_index=[2, 150], x=[38, 3], y=[1])\n",
      "Data(edge_index=[2, 106], x=[23, 3], y=[1])\n",
      "Data(edge_index=[2, 74], x=[18, 3], y=[1])\n",
      "Data(edge_index=[2, 194], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 90], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 142], x=[35, 3], y=[1])\n",
      "Data(edge_index=[2, 102], x=[24, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 84], x=[21, 3], y=[1])\n",
      "Data(edge_index=[2, 124], x=[31, 3], y=[1])\n",
      "Data(edge_index=[2, 112], x=[27, 3], y=[1])\n",
      "Data(edge_index=[2, 196], x=[51, 3], y=[1])\n",
      "Data(edge_index=[2, 156], x=[36, 3], y=[1])\n",
      "Data(edge_index=[2, 144], x=[46, 3], y=[1])\n",
      "Data(edge_index=[2, 228], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 180], x=[44, 3], y=[1])\n",
      "Data(edge_index=[2, 182], x=[45, 3], y=[1])\n",
      "Data(edge_index=[2, 232], x=[52, 3], y=[1])\n",
      "Data(edge_index=[2, 200], x=[55, 3], y=[1])\n",
      "Data(edge_index=[2, 190], x=[51, 3], y=[1])\n",
      "Data(edge_index=[2, 156], x=[48, 3], y=[1])\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
